{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664b8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Artem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5c5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_tabloids = pd.read_csv(\"Dimensions_texts_Tabloids.csv\")\n",
    "df2_tabloids = pd.read_csv(\"Statistics_texts_Tabloids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db85e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_broadsheets = pd.read_csv(\"Dimensions_texts_Broadsheets.csv\")\n",
    "df2_broadsheets = pd.read_csv(\"Statistics_texts_Broadsheets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e510d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Dimension1', 'Dimension2', 'Dimension3', 'Dimension4',\n",
       "       'Dimension5', 'Dimension6', 'Closest Text Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_tabloids.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6715c2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Tokens', 'AWL', 'TTR', '#', '$', '''', ':', 'AMP', 'ANDC',\n",
       "       'CAUS', 'CC', 'CD', 'CONC', 'COND', 'CONJ', 'DEMO', 'DEMP', 'DPAR',\n",
       "       'DT', 'DWNT', 'EMPH', 'EX', 'FPP1', 'FW', 'GER', 'HDG', 'IN', 'INPR',\n",
       "       'JJ', 'NEMD', 'NN', 'NOMZ', 'OSUB', 'PDT', 'PHC', 'PIN', 'PIT', 'PLACE',\n",
       "       'POMD', 'POS', 'PRED', 'PRMD', 'PRP', 'QUAN', 'QUPR', 'RB', 'RP',\n",
       "       'SPP2', 'SYM', 'SYNE', 'THAC', 'THVC', 'TIME', 'TO', 'TOBJ', 'TPP3',\n",
       "       'TSUB', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VPRT', 'WDT', 'WP', 'WPS',\n",
       "       'XX0', '[BEMA]', '[BYPA]', '[PASS]', '[PASTP]', '[PEAS]', '[PIRE]',\n",
       "       '[PRIV]', '[PROD]', '[PUBV]', '[SERE]', '[SMP]', '[SPAU]', '[SPIN]',\n",
       "       '[SUAV]', '[THATD]', '[WHCL]', '[WHOBJ]', '[WHQU]', '[WHSUB]',\n",
       "       '[WZPAST]', '[WZPRES]', '``', 'Unnamed: 90'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_broadsheets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce94fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_broadsheets = df2_broadsheets.drop(columns = ['Unnamed: 90'])\n",
    "df2_tabloids = df2_tabloids.drop(columns = ['Unnamed: 89'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c6b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tabloids = df1_tabloids['Closest Text Type']\n",
    "y_broadsheets = df1_broadsheets['Closest Text Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03102446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Dimension1</th>\n",
       "      <th>Dimension2</th>\n",
       "      <th>Dimension3</th>\n",
       "      <th>Dimension4</th>\n",
       "      <th>Dimension5</th>\n",
       "      <th>Dimension6</th>\n",
       "      <th>Closest Text Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text_0</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>4.07</td>\n",
       "      <td>7.59</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text_100</td>\n",
       "      <td>-18.97</td>\n",
       "      <td>-5.83</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>0.84</td>\n",
       "      <td>Learned exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text_101</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.91</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>1.70</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text_102</td>\n",
       "      <td>-18.69</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>5.77</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>Learned exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text_103</td>\n",
       "      <td>-15.85</td>\n",
       "      <td>-3.88</td>\n",
       "      <td>1.94</td>\n",
       "      <td>6.77</td>\n",
       "      <td>5.34</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>Scientific exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>text_97</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.48</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>text_98</td>\n",
       "      <td>-13.76</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-3.81</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>text_99</td>\n",
       "      <td>-4.28</td>\n",
       "      <td>4.06</td>\n",
       "      <td>6.07</td>\n",
       "      <td>-1.87</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>text_9</td>\n",
       "      <td>-14.07</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>6.47</td>\n",
       "      <td>6.77</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>texts</td>\n",
       "      <td>-13.60</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>4.76</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>Learned exposition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename  Dimension1  Dimension2  Dimension3  Dimension4  Dimension5  \\\n",
       "0      text_0       -3.75        4.07        7.59       -2.18       -1.74   \n",
       "1    text_100      -18.97       -5.83        0.30       -1.45       -1.95   \n",
       "2    text_101       -2.72       -0.20        1.91       -3.49        1.70   \n",
       "3    text_102      -18.69       -5.26        5.77       -4.90       -0.96   \n",
       "4    text_103      -15.85       -3.88        1.94        6.77        5.34   \n",
       "..        ...         ...         ...         ...         ...         ...   \n",
       "132   text_97      -11.01       -2.96        4.25        1.60       -0.63   \n",
       "133   text_98      -13.76       -2.60        0.69       -3.81        2.51   \n",
       "134   text_99       -4.28        4.06        6.07       -1.87        3.20   \n",
       "135    text_9      -14.07       -1.63        6.47        6.77       -1.32   \n",
       "136     texts      -13.60       -2.96        4.76       -0.88       -1.03   \n",
       "\n",
       "     Dimension6             Closest Text Type  \n",
       "0         -0.41  General narrative exposition  \n",
       "1          0.84            Learned exposition  \n",
       "2         -1.05  General narrative exposition  \n",
       "3         -1.24            Learned exposition  \n",
       "4         -2.12         Scientific exposition  \n",
       "..          ...                           ...  \n",
       "132        0.48  General narrative exposition  \n",
       "133        0.00  General narrative exposition  \n",
       "134        0.73  General narrative exposition  \n",
       "135       -0.39  General narrative exposition  \n",
       "136       -1.00            Learned exposition  \n",
       "\n",
       "[137 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_broadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2363097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tabloids['Closest Text Type'] = df1_tabloids['Closest Text Type']\n",
    "#df3_tabloids['Closest Text Type'] = df1_tabloids['Closest Text Type']\n",
    "df2_broadsheets['Closest Text Type'] = df1_broadsheets['Closest Text Type']\n",
    "#df3_broadsheets['Closest Text Type'] = df1_broadsheets['Closest Text Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd432ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bads = []\n",
    "\n",
    "for l in list(df2_tabloids.columns):\n",
    "    if re.findall('[a-zA-Z]', l) == []:\n",
    "        bads.append(l)\n",
    "\n",
    "for l in list(df2_broadsheets.columns):\n",
    "    if re.findall('[a-zA-Z]', l) == []:\n",
    "        bads.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e88d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RRB-\n"
     ]
    }
   ],
   "source": [
    "for l in list(df2_tabloids.columns):\n",
    "    if l not in df2_broadsheets:\n",
    "        print(l)\n",
    "\n",
    "df2_tabloids = df2_tabloids.drop([\"-RRB-\", '#', '$', \"''\", ':'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70123ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "$\n",
      "''\n",
      ":\n",
      "DPAR\n",
      "``\n"
     ]
    }
   ],
   "source": [
    "for l in list(df2_broadsheets.columns):\n",
    "    if l not in df2_tabloids:\n",
    "        print(l)\n",
    "\n",
    "df2_broadsheets = df2_broadsheets.drop([\"DPAR\", \"``\", '#', '$', \"''\", ':'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df872025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Tokens', 'AWL', 'TTR', 'AMP', 'ANDC', 'CAUS', 'CC', 'CD',\n",
       "       'CONC', 'COND', 'CONJ', 'DEMO', 'DEMP', 'DT', 'DWNT', 'EMPH', 'EX',\n",
       "       'FPP1', 'FW', 'GER', 'HDG', 'IN', 'INPR', 'JJ', 'NEMD', 'NN', 'NOMZ',\n",
       "       'OSUB', 'PDT', 'PHC', 'PIN', 'PIT', 'PLACE', 'POMD', 'POS', 'PRED',\n",
       "       'PRMD', 'PRP', 'QUAN', 'QUPR', 'RB', 'RP', 'SPP2', 'SYM', 'SYNE',\n",
       "       'THAC', 'THVC', 'TIME', 'TO', 'TOBJ', 'TPP3', 'TSUB', 'UH', 'VB', 'VBD',\n",
       "       'VBG', 'VBN', 'VPRT', 'WDT', 'WP', 'WPS', 'XX0', '[BEMA]', '[BYPA]',\n",
       "       '[PASS]', '[PASTP]', '[PEAS]', '[PIRE]', '[PRIV]', '[PROD]', '[PUBV]',\n",
       "       '[SERE]', '[SMP]', '[SPAU]', '[SPIN]', '[SUAV]', '[THATD]', '[WHCL]',\n",
       "       '[WHOBJ]', '[WHQU]', '[WHSUB]', '[WZPAST]', '[WZPRES]',\n",
       "       'Closest Text Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_tabloids.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a15e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Tokens', 'AWL', 'TTR', 'AMP', 'ANDC', 'CAUS', 'CC', 'CD',\n",
       "       'CONC', 'COND', 'CONJ', 'DEMO', 'DEMP', 'DT', 'DWNT', 'EMPH', 'EX',\n",
       "       'FPP1', 'FW', 'GER', 'HDG', 'IN', 'INPR', 'JJ', 'NEMD', 'NN', 'NOMZ',\n",
       "       'OSUB', 'PDT', 'PHC', 'PIN', 'PIT', 'PLACE', 'POMD', 'POS', 'PRED',\n",
       "       'PRMD', 'PRP', 'QUAN', 'QUPR', 'RB', 'RP', 'SPP2', 'SYM', 'SYNE',\n",
       "       'THAC', 'THVC', 'TIME', 'TO', 'TOBJ', 'TPP3', 'TSUB', 'UH', 'VB', 'VBD',\n",
       "       'VBG', 'VBN', 'VPRT', 'WDT', 'WP', 'WPS', 'XX0', '[BEMA]', '[BYPA]',\n",
       "       '[PASS]', '[PASTP]', '[PEAS]', '[PIRE]', '[PRIV]', '[PROD]', '[PUBV]',\n",
       "       '[SERE]', '[SMP]', '[SPAU]', '[SPIN]', '[SUAV]', '[THATD]', '[WHCL]',\n",
       "       '[WHOBJ]', '[WHQU]', '[WHSUB]', '[WZPAST]', '[WZPRES]',\n",
       "       'Closest Text Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_broadsheets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f6712a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df3_tabloids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e999757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3_broadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0dc81a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>AWL</th>\n",
       "      <th>TTR</th>\n",
       "      <th>AMP</th>\n",
       "      <th>ANDC</th>\n",
       "      <th>CAUS</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>CONC</th>\n",
       "      <th>...</th>\n",
       "      <th>[SPIN]</th>\n",
       "      <th>[SUAV]</th>\n",
       "      <th>[THATD]</th>\n",
       "      <th>[WHCL]</th>\n",
       "      <th>[WHOBJ]</th>\n",
       "      <th>[WHQU]</th>\n",
       "      <th>[WHSUB]</th>\n",
       "      <th>[WZPAST]</th>\n",
       "      <th>[WZPRES]</th>\n",
       "      <th>Closest Text Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text_0</td>\n",
       "      <td>1040.00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>169.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text_100</td>\n",
       "      <td>559.00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>203.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Involved persuasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text_101</td>\n",
       "      <td>476.00</td>\n",
       "      <td>3.91</td>\n",
       "      <td>174.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text_102</td>\n",
       "      <td>315.00</td>\n",
       "      <td>4.16</td>\n",
       "      <td>165.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text_103</td>\n",
       "      <td>443.00</td>\n",
       "      <td>4.47</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>text_97</td>\n",
       "      <td>1090.00</td>\n",
       "      <td>4.36</td>\n",
       "      <td>194.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>text_98</td>\n",
       "      <td>428.00</td>\n",
       "      <td>4.44</td>\n",
       "      <td>211.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>text_99</td>\n",
       "      <td>508.00</td>\n",
       "      <td>4.84</td>\n",
       "      <td>174.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Learned exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>text_9</td>\n",
       "      <td>329.00</td>\n",
       "      <td>4.56</td>\n",
       "      <td>165.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Learned exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>texts</td>\n",
       "      <td>725.04</td>\n",
       "      <td>4.37</td>\n",
       "      <td>184.45</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename   Tokens   AWL     TTR   AMP  ANDC  CAUS    CC    CD  CONC  ...  \\\n",
       "0      text_0  1040.00  4.15  169.00  0.29  0.10  0.00  2.02  1.25  0.00  ...   \n",
       "1    text_100   559.00  4.15  203.00  0.36  0.00  0.00  2.15  0.00  0.00  ...   \n",
       "2    text_101   476.00  3.91  174.00  0.00  0.00  0.00  2.73  1.26  0.00  ...   \n",
       "3    text_102   315.00  4.16  165.00  0.32  0.00  0.00  1.59  1.27  0.00  ...   \n",
       "4    text_103   443.00  4.47  181.00  0.23  0.00  0.23  1.35  1.13  0.00  ...   \n",
       "..        ...      ...   ...     ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "130   text_97  1090.00  4.36  194.00  0.00  0.09  0.00  2.39  1.01  0.00  ...   \n",
       "131   text_98   428.00  4.44  211.00  0.00  0.00  0.00  1.87  0.93  0.00  ...   \n",
       "132   text_99   508.00  4.84  174.00  0.00  0.00  0.00  1.38  1.77  0.00  ...   \n",
       "133    text_9   329.00  4.56  165.00  0.00  0.00  0.00  2.13  0.30  0.00  ...   \n",
       "134     texts   725.04  4.37  184.45  0.15  0.06  0.11  2.24  0.84  0.04  ...   \n",
       "\n",
       "     [SPIN]  [SUAV]  [THATD]  [WHCL]  [WHOBJ]  [WHQU]  [WHSUB]  [WZPAST]  \\\n",
       "0      0.00    0.10     0.87    0.00     0.19     0.0     0.77      0.19   \n",
       "1      0.00    0.36     1.07    0.36     0.18     0.0     0.00      0.00   \n",
       "2      0.00    0.21     0.63    0.42     0.21     0.0     0.21      0.21   \n",
       "3      0.00    0.00     2.22    0.00     0.00     0.0     0.63      0.00   \n",
       "4      0.00    0.23     1.13    0.00     0.23     0.0     0.00      0.00   \n",
       "..      ...     ...      ...     ...      ...     ...      ...       ...   \n",
       "130    0.09    0.64     1.56    0.09     0.09     0.0     0.28      0.00   \n",
       "131    0.00    0.00     0.93    0.00     0.00     0.0     0.93      0.00   \n",
       "132    0.00    0.39     0.79    0.20     0.00     0.0     0.39      0.00   \n",
       "133    0.00    0.00     0.00    0.00     0.00     0.0     0.00      0.00   \n",
       "134    0.02    0.32     0.81    0.10     0.05     0.0     0.41      0.04   \n",
       "\n",
       "     [WZPRES]             Closest Text Type  \n",
       "0        0.00  General narrative exposition  \n",
       "1        0.00           Involved persuasion  \n",
       "2        0.21  General narrative exposition  \n",
       "3        0.00  General narrative exposition  \n",
       "4        0.23  General narrative exposition  \n",
       "..        ...                           ...  \n",
       "130      0.00  General narrative exposition  \n",
       "131      0.00  General narrative exposition  \n",
       "132      0.00            Learned exposition  \n",
       "133      0.00            Learned exposition  \n",
       "134      0.07  General narrative exposition  \n",
       "\n",
       "[135 rows x 85 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_tabloids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72eef782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_broadsheets = df1_broadsheets.drop(['Filename'],axis=1)\n",
    "df1_tabloids = df1_tabloids.drop(['Filename'],axis=1)\n",
    "df2_broadsheets = df2_broadsheets.drop(['Filename'],axis=1)\n",
    "df2_tabloids = df2_tabloids.drop(['Filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b9e7c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['General narrative exposition', 'Learned exposition',\n",
       "       'Scientific exposition', 'Involved persuasion'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_broadsheets['Closest Text Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa5c0071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['General narrative exposition', 'Involved persuasion',\n",
       "       'Learned exposition', 'Scientific exposition'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_tabloids['Closest Text Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a250c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_br_types = []\n",
    "\n",
    "for d in df1_broadsheets['Closest Text Type']:\n",
    "    if d == 'General narrative exposition':\n",
    "        df1_br_types.append(0)\n",
    "    elif d == 'Imaginative narrative':\n",
    "        df1_br_types.append(1)\n",
    "    elif d == 'Informational interaction':\n",
    "        df1_br_types.append(2)\n",
    "    elif d == 'Involved persuasion':\n",
    "        df1_br_types.append(3)\n",
    "    elif d == 'Learned exposition':\n",
    "        df1_br_types.append(4)\n",
    "    elif d == 'Scientific exposition':\n",
    "        df1_br_types.append(5)\n",
    "    else:\n",
    "        df1_br_types.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a8b4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_tabl_types = []\n",
    "\n",
    "for d in df1_tabloids['Closest Text Type']:\n",
    "    if d == 'General narrative exposition':\n",
    "        df1_tabl_types.append(0)\n",
    "    elif d == 'Imaginative narrative':\n",
    "        df1_tabl_types.append(1)\n",
    "    elif d == 'Informational interaction':\n",
    "        df1_tabl_types.append(2)\n",
    "    elif d == 'Involved persuasion':\n",
    "        df1_tabl_types.append(3)\n",
    "    elif d == 'Learned exposition':\n",
    "        df1_tabl_types.append(4)\n",
    "    elif d == 'Scientific exposition':\n",
    "        df1_tabl_types.append(5)\n",
    "    else:\n",
    "        df1_tabl_types.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f357e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_br_types = []\n",
    "\n",
    "for d in df2_broadsheets['Closest Text Type']:\n",
    "    if d == 'General narrative exposition':\n",
    "        df2_br_types.append(0)\n",
    "    elif d == 'Imaginative narrative':\n",
    "        df2_br_types.append(1)\n",
    "    elif d == 'Informational interaction':\n",
    "        df2_br_types.append(2)\n",
    "    elif d == 'Involved persuasion':\n",
    "        df2_br_types.append(3)\n",
    "    elif d == 'Learned exposition':\n",
    "        df2_br_types.append(4)\n",
    "    elif d == 'Scientific exposition':\n",
    "        df2_br_types.append(5)\n",
    "    else:\n",
    "        df2_br_types.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a7379c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tabl_types = []\n",
    "\n",
    "for d in df2_tabloids['Closest Text Type']:\n",
    "    if d == 'General narrative exposition':\n",
    "        df2_tabl_types.append(0)\n",
    "    elif d == 'Imaginative narrative':\n",
    "        df2_tabl_types.append(1)\n",
    "    elif d == 'Informational interaction':\n",
    "        df2_tabl_types.append(2)\n",
    "    elif d == 'Involved persuasion':\n",
    "        df2_tabl_types.append(3)\n",
    "    elif d == 'Learned exposition':\n",
    "        df2_tabl_types.append(4)\n",
    "    elif d == 'Scientific exposition':\n",
    "        df2_tabl_types.append(5)\n",
    "    else:\n",
    "        df2_tabl_types.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdee873f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_tabloids['Closest_Text_Type'] = df1_tabl_types\n",
    "df2_tabloids['Closest_Text_Type'] = df2_tabl_types\n",
    "df1_broadsheets['Closest_Text_Type'] = df1_br_types\n",
    "df2_broadsheets['Closest_Text_Type'] = df2_br_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7315fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_broadsheets = df1_broadsheets.drop(['Closest Text Type'],axis=1)\n",
    "df1_tabloids = df1_tabloids.drop(['Closest Text Type'],axis=1)\n",
    "df2_broadsheets = df2_broadsheets.drop(['Closest Text Type'],axis=1)\n",
    "df2_tabloids = df2_tabloids.drop(['Closest Text Type'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7d008",
   "metadata": {},
   "source": [
    "## Features (количественные характеристики): \n",
    "\n",
    "* Tokens – количество токенов.\n",
    "* AWL – средняя длина слова.\n",
    "* TTR – количество тренировочных токенов (400).\n",
    "* AMP – наличие слов-усилителей.\n",
    "* ANDC – управление независимой клаузой.\n",
    "* CAUS – наличие обстоятельств причины по типу «because».\n",
    "* CC – ???.\n",
    "* CD – кардинальное число (элементы множества).\n",
    "* CONC – концессионная обусловленность (наличие слов типа «although», «though» и т.п.)\n",
    "* COND – слова состояния, условности (наличие слов типа «if», «unless» и т.п.)\n",
    "* CONJ – слова-союзы.\n",
    "* DEMO – указательные местоимения, которые не подходят ни к одному из следующих тэгов: DEMP, TOBJ, TSUB, THAC или THVC.\n",
    "* DEMP – указательное местоимение.\n",
    "* DT – слово-определитель.\n",
    "* DWNT – слова, обозначающие незавершённость действия («almost», «hardly», «somewhat», «» и многие другие).\n",
    "* EMPH – слова с эмоциональным оттенком («really», «just», «for sure» и т.п.)\n",
    "* EX – слова с указанием существования чего-либо («there»).\n",
    "* FPP1 – местоимения первого лица («I», «we», «our», «my», «ourselves», «us», «me», «myself»).\n",
    "* FW – ???.\n",
    "* GER – герундий (глаголы с «-ing» на конце).\n",
    "* HDG – показатели неопределённости («more or less», «maybe», «something like» и т.п.)\n",
    "* IN – подчинительные союзы.\n",
    "* INPR – местоимения без точного указания на конкретное лицо («everyone», «anyone», «someone», «something» и т.п.)\n",
    "* JJ – прилагательные.\n",
    "* NEMD – глаголы обязательства («ought», «should», «must»).\n",
    "* NN – существительные.\n",
    "* NOMZ – отглагольные существительные («-tion», «-ness», «-ment» и т.п).\n",
    "* OSUB – слова по типу «since», «while», «whilst», «whereupon», «whereas», «whereby», «such that», «so that».\n",
    "* PDT – слова, стоящие перед определением.\n",
    "* PHC – союз «и».\n",
    "* PIN – предлоги.\n",
    "* PIT – местоимение «it».\n",
    "* PLACE – указатели места («above», «below», «», «» и т.п.).\n",
    "* POMD – модальные глаголы возможности («can», «may», «might», «could»).\n",
    "* PRED – предикативное прилагательное.\n",
    "* PRMD – глаголы с указанием на будущее время («will», «shall», «would»).\n",
    "* PRP – личное местоимение.\n",
    "* QUAN – числительное.\n",
    "* QUPR – числительное местоимение.\n",
    "* RB – наречие.\n",
    "* RP – ???.\n",
    "* SPP2 – местоимения в форме второго лица («you», «your», «yourself», «yourselves», «thy», «thee», «thyself», «thou»).\n",
    "* SYM – ???.\n",
    "* SYNE – конструкции «no» + прилагательное.\n",
    "* THAC – конструкции «that» + прилагательное.\n",
    "* THVC – конструкции «that» + глагол.\n",
    "* TIME – времени («afterwards», «again», «earlier», «early» и другие).\n",
    "* TO – инфинитивы, которые следуют после слова «to».\n",
    "* TOBJ – конструкции по типу «that» + подлежащее + сказуемое; применяется в отношении объекта предложения.\n",
    "* TPP3 – местоимения в форме третьего лица («she», «he», «they», «her», «him», «them», «his», «their», «himself», «herself», «themselves»).\n",
    "* TSUB – конструкции по типу «that» + подлежащее + сказуемое; применяется в отношении субъекта предложения.\n",
    "* UH – ???.\n",
    "* VB – глаголы.\n",
    "* VBD – глаголы в форме прошедшего времени.\n",
    "* VBG – глаголы с формой Present Continuous с «-ing» на конце.\n",
    "* VBN – глаголы с формой Past Continuous с «-ing» на конце.\n",
    "* VPRT – глаголы с формой Present Simple.\n",
    "* WDT – ???.\n",
    "* WP – местоимения, начинающиеся на «wh-».\n",
    "* WPS – местоимения, начинающиеся на «wh-» и имеющие посессивный характер.\n",
    "* XX0 – отрицания; слова «not» и «n’t».\n",
    "* [BEMA] – глагольная фраза с «be».\n",
    "* [BYPA] – фразы в пассивном залоге с «by».\n",
    "* [PASS] – фразы в пассивном залоге без пациенса.\n",
    "* [PEAS] – фразы в перфекте («have» + глагол).\n",
    "* [PIRE] – предикаты сложноподчинённого предложения со словами «who», «whose» или «which»; причём эти слова обозначают субъект из основной части предложения.\n",
    "* [PRIV] – список глаголов по Quirk et al. (1985: 1181–2): «feel», «recall», «accept», «assume», «prove», «believe», «remember», «calculate» и т.п., в т.ч. их словоформы.\n",
    "* [PROD] – использования слова «do» в качестве самостоятельного глагола.\n",
    "* [PUBV] – глаголы по типу «announce», «certify», «say», «write» и т.п.\n",
    "* [SMP] – глаголы «seem» и «appear».\n",
    "* [SPAU] – конструкции типа «вспомогательный глагол + минимум одно наречие + базовая форма глагола».\n",
    "* [SPIN] – конструкции типа «to + минимум одно наречие + базовая форма глагола».\n",
    "* [SUAV] – список глаголов убеждения по Quirk et al. (1985: 1182–3): «ensure», «insist», «order», «propose», «request», «suggest» и т.п.\n",
    "* [THATD] – подчинительные клаузы без «that».\n",
    "* [WHCL] – клаузы с вопросительными словами на «wh-», после которых следует слово, не являющееся вспомогательной частью речи.\n",
    "* [WHOBJ] – определённые придаточные предложения, имеющие вопросительные слова на «wh-» в качестве объекта.\n",
    "* [WHSUB] – определённые придаточные предложения, имеющие вопросительные слова на «wh-» в качестве субъекта.\n",
    "* [WZPAST] – фразы по типу «The solution produced by this process»\n",
    "* [WZPRES] – фразы по типу «the event causing this decline is…»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4b1d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "feature = []\n",
    "score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47e3392e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tokens', 'AWL', 'TTR', 'AMP', 'ANDC', 'CAUS', 'CC', 'CD', 'CONC',\n",
       "       'COND', 'CONJ', 'DEMO', 'DEMP', 'DT', 'DWNT', 'EMPH', 'EX', 'FPP1',\n",
       "       'FW', 'GER', 'HDG', 'IN', 'INPR', 'JJ', 'NEMD', 'NN', 'NOMZ', 'OSUB',\n",
       "       'PDT', 'PHC', 'PIN', 'PIT', 'PLACE', 'POMD', 'POS', 'PRED', 'PRMD',\n",
       "       'PRP', 'QUAN', 'QUPR', 'RB', 'RP', 'SPP2', 'SYM', 'SYNE', 'THAC',\n",
       "       'THVC', 'TIME', 'TO', 'TOBJ', 'TPP3', 'TSUB', 'UH', 'VB', 'VBD', 'VBG',\n",
       "       'VBN', 'VPRT', 'WDT', 'WP', 'WPS', 'XX0', '[BEMA]', '[BYPA]', '[PASS]',\n",
       "       '[PASTP]', '[PEAS]', '[PIRE]', '[PRIV]', '[PROD]', '[PUBV]', '[SERE]',\n",
       "       '[SMP]', '[SPAU]', '[SPIN]', '[SUAV]', '[THATD]', '[WHCL]', '[WHOBJ]',\n",
       "       '[WHQU]', '[WHSUB]', '[WZPAST]', '[WZPRES]', 'Closest_Text_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_broadsheets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb357cad",
   "metadata": {},
   "source": [
    "### Корреляция по broadsheets (dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0aad8e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметр</th>\n",
       "      <th>Корреляция</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dimension1</td>\n",
       "      <td>-0.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dimension2</td>\n",
       "      <td>-0.410130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dimension4</td>\n",
       "      <td>-0.173493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dimension6</td>\n",
       "      <td>-0.030158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dimension5</td>\n",
       "      <td>0.015463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dimension3</td>\n",
       "      <td>0.332876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Параметр  Корреляция\n",
       "0  Dimension1   -0.515000\n",
       "1  Dimension2   -0.410130\n",
       "2  Dimension4   -0.173493\n",
       "3  Dimension6   -0.030158\n",
       "4  Dimension5    0.015463\n",
       "5  Dimension3    0.332876"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df1_broadsheets.corr()['Closest_Text_Type'][df1_broadsheets.corr()['Closest_Text_Type'] != 1].sort_values(ascending=True)\n",
    "feature = correl.index\n",
    "score = correl.values\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Параметр'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b210dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметр</th>\n",
       "      <th>Корреляция</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dimension3</td>\n",
       "      <td>0.332876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dimension5</td>\n",
       "      <td>0.015463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dimension6</td>\n",
       "      <td>-0.030158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dimension4</td>\n",
       "      <td>-0.173493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dimension2</td>\n",
       "      <td>-0.410130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Параметр  Корреляция\n",
       "0  Dimension3    0.332876\n",
       "1  Dimension5    0.015463\n",
       "2  Dimension6   -0.030158\n",
       "3  Dimension4   -0.173493\n",
       "4  Dimension2   -0.410130"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df1_broadsheets.corr()['Closest_Text_Type'][df1_broadsheets.corr()['Closest_Text_Type'] != 1].sort_values(ascending=False).head()\n",
    "feature = correl.index\n",
    "score = correl.values\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Параметр'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03592c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=-0.514999592795047, pvalue=1.205634754338842e-10)\n",
      "PearsonRResult(statistic=-0.4101304697638328, pvalue=6.450551314705333e-07)\n",
      "PearsonRResult(statistic=-0.17349292647152822, pvalue=0.04261350108114917)\n",
      "PearsonRResult(statistic=-0.03015793066054716, pvalue=0.726462669530383)\n",
      "PearsonRResult(statistic=0.01546297645947228, pvalue=0.857669264971359)\n",
      "PearsonRResult(statistic=0.332876018813791, pvalue=7.053622033389623e-05)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension1'], df1_broadsheets['Closest_Text_Type']))\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension2'], df1_broadsheets['Closest_Text_Type']))\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension4'], df1_broadsheets['Closest_Text_Type']))\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension6'], df1_broadsheets['Closest_Text_Type']))\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension5'], df1_broadsheets['Closest_Text_Type']))\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension3'], df1_broadsheets['Closest_Text_Type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318cd798",
   "metadata": {},
   "source": [
    "### Корреляция по broadsheets (Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8cff2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_broadsheets = df2_broadsheets.loc[:,~df2_broadsheets.columns.duplicated()].copy()\n",
    "df2_tabloids = df2_tabloids.loc[:,~df2_tabloids.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1dc479c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FPP1</td>\n",
       "      <td>-0.387537</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TPP3</td>\n",
       "      <td>-0.358187</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VB</td>\n",
       "      <td>-0.345953</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XX0</td>\n",
       "      <td>-0.328693</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIT</td>\n",
       "      <td>-0.324777</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Correlation   P-value\n",
       "0    FPP1    -0.387537  0.000003\n",
       "1    TPP3    -0.358187  0.000017\n",
       "2      VB    -0.345953  0.000035\n",
       "3     XX0    -0.328693  0.000088\n",
       "4     PIT    -0.324777  0.000108"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df2_broadsheets.corr()['Closest_Text_Type'][df2_broadsheets.corr()['Closest_Text_Type'] != 1].sort_values(ascending=True).head()\n",
    "feature = correl.index\n",
    "feature1 = feature\n",
    "score = correl.values\n",
    "correlation = pd.DataFrame()\n",
    "pearsonr = []\n",
    "for f in feature:\n",
    "    pearsonr.append(stats.pearsonr(df2_broadsheets[f], df2_broadsheets['Closest_Text_Type'])[1])\n",
    "\n",
    "correlation['Feature'] = feature\n",
    "correlation['Correlation'] = score\n",
    "correlation['P-value'] = pearsonr\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6bf9747b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметр</th>\n",
       "      <th>Корреляция</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AWL</td>\n",
       "      <td>0.426358</td>\n",
       "      <td>2.049407e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHC</td>\n",
       "      <td>0.408147</td>\n",
       "      <td>7.390863e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.348608</td>\n",
       "      <td>2.983818e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JJ</td>\n",
       "      <td>0.326417</td>\n",
       "      <td>9.909812e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIN</td>\n",
       "      <td>0.259640</td>\n",
       "      <td>2.184848e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Параметр  Корреляция       P-value\n",
       "0      AWL    0.426358  2.049407e-07\n",
       "1      PHC    0.408147  7.390863e-07\n",
       "2       NN    0.348608  2.983818e-05\n",
       "3       JJ    0.326417  9.909812e-05\n",
       "4      PIN    0.259640  2.184848e-03"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df2_broadsheets.corr()['Closest_Text_Type'][df2_broadsheets.corr()['Closest_Text_Type'] != 1].sort_values(ascending=False).head()\n",
    "feature = correl.index\n",
    "feature2 = feature\n",
    "score = correl.values\n",
    "\n",
    "pearsonr = []\n",
    "for f in feature:\n",
    "    pearsonr.append(stats.pearsonr(df2_broadsheets[f], df2_broadsheets['Closest_Text_Type'])[1])\n",
    "\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Параметр'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "correlation['P-value'] = pearsonr\n",
    "\n",
    "    \n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038381cb",
   "metadata": {},
   "source": [
    "### Корреляция по tabloids (dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e399b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Корреляция</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dimension3</td>\n",
       "      <td>0.269407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dimension5</td>\n",
       "      <td>0.227036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dimension4</td>\n",
       "      <td>-0.053711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dimension6</td>\n",
       "      <td>-0.114513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dimension1</td>\n",
       "      <td>-0.158765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dimension  Корреляция\n",
       "0  Dimension3    0.269407\n",
       "1  Dimension5    0.227036\n",
       "2  Dimension4   -0.053711\n",
       "3  Dimension6   -0.114513\n",
       "4  Dimension1   -0.158765"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df1_tabloids.corr()['Closest_Text_Type'][df1_tabloids.corr()['Closest_Text_Type'] != 1].sort_values(ascending=False).head()\n",
    "feature = correl.index\n",
    "score = correl.values\n",
    "\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Dimension'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78c512aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correl = df1_tabloids.corr()['Closest_Text_Type'][df1_tabloids.corr()['Closest_Text_Type'] != 1].sort_values(ascending=True)\n",
    "#feature = correl.index\n",
    "#score = correl.values\n",
    "\n",
    "#pearsonr = []\n",
    "#for f in feature:\n",
    "#    pearsonr.append(stats.pearsonr(df1_tabloids[f], df1_tabloids['Closest_Text_Type'])[1])\n",
    "\n",
    "#correlation = pd.DataFrame()\n",
    "#correlation['Параметр'] = feature\n",
    "#correlation['Корреляция'] = score\n",
    "#correlation['P-value'] = pearsonr\n",
    "\n",
    "#correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd1bba",
   "metadata": {},
   "source": [
    "### Корреляция по tabloids (основные параметры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "31162d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметр</th>\n",
       "      <th>Корреляция</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPP3</td>\n",
       "      <td>-0.243757</td>\n",
       "      <td>0.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYNE</td>\n",
       "      <td>-0.226020</td>\n",
       "      <td>0.008391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIME</td>\n",
       "      <td>-0.223909</td>\n",
       "      <td>0.009037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tokens</td>\n",
       "      <td>-0.202692</td>\n",
       "      <td>0.018389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOBJ</td>\n",
       "      <td>-0.185198</td>\n",
       "      <td>0.031521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Параметр  Корреляция   P-value\n",
       "0     TPP3   -0.243757  0.004386\n",
       "1     SYNE   -0.226020  0.008391\n",
       "2     TIME   -0.223909  0.009037\n",
       "3   Tokens   -0.202692  0.018389\n",
       "4     TOBJ   -0.185198  0.031521"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df2_tabloids.corr()['Closest_Text_Type'][df2_tabloids.corr()['Closest_Text_Type'] != 1].sort_values(ascending=True).head()\n",
    "feature = correl.index\n",
    "feature3 = feature\n",
    "score = correl.values\n",
    "\n",
    "pearsonr = []\n",
    "for f in feature:\n",
    "    pearsonr.append(stats.pearsonr(df2_tabloids[f], df2_tabloids['Closest_Text_Type'])[1])\n",
    "\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Параметр'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "correlation['P-value'] = pearsonr\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9e83f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметр</th>\n",
       "      <th>Корреляция</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AWL</td>\n",
       "      <td>0.242714</td>\n",
       "      <td>0.004563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JJ</td>\n",
       "      <td>0.238583</td>\n",
       "      <td>0.005325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOMZ</td>\n",
       "      <td>0.184365</td>\n",
       "      <td>0.032306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GER</td>\n",
       "      <td>0.179405</td>\n",
       "      <td>0.037339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHC</td>\n",
       "      <td>0.171176</td>\n",
       "      <td>0.047137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Параметр  Корреляция   P-value\n",
       "0      AWL    0.242714  0.004563\n",
       "1       JJ    0.238583  0.005325\n",
       "2     NOMZ    0.184365  0.032306\n",
       "3      GER    0.179405  0.037339\n",
       "4      PHC    0.171176  0.047137"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df2_tabloids.corr()['Closest_Text_Type'][df2_tabloids.corr()['Closest_Text_Type'] != 1].sort_values(ascending=False).head()\n",
    "feature = correl.index\n",
    "feature4 = feature\n",
    "score = correl.values\n",
    "\n",
    "pearsonr = []\n",
    "for f in feature:\n",
    "    pearsonr.append(stats.pearsonr(df2_tabloids[f], df2_tabloids['Closest_Text_Type'])[1])\n",
    "\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Параметр'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "correlation['P-value'] = pearsonr\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bd95ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AWL',\n",
       " 'FPP1',\n",
       " 'GER',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NOMZ',\n",
       " 'PHC',\n",
       " 'PIN',\n",
       " 'PIT',\n",
       " 'SYNE',\n",
       " 'TIME',\n",
       " 'TOBJ',\n",
       " 'TPP3',\n",
       " 'Tokens',\n",
       " 'VB',\n",
       " 'XX0'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1_broadsheets\n",
    "\n",
    "features_full = feature1.to_list() + feature2.to_list() + feature3.to_list() + feature4.to_list()\n",
    "set(features_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d6d2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tabloids = df2_tabloids[[\n",
    "                                         'AWL',\n",
    "                                         'FPP1',\n",
    "                                         'GER',\n",
    "                                         'JJ',\n",
    "                                         'NN',\n",
    "                                         'NOMZ',\n",
    "                                         'PHC',\n",
    "                                         'PIN',\n",
    "                                         'PIT',\n",
    "                                         'SYNE',\n",
    "                                         'TIME',\n",
    "                                         'TOBJ',\n",
    "                                         'TPP3',\n",
    "                                         'Tokens',\n",
    "                                         'VB',\n",
    "                                         'XX0',\n",
    "                                         'Closest_Text_Type']]\n",
    "\n",
    "df2_broadsheets = df2_broadsheets[[\n",
    "                                         'AWL',\n",
    "                                         'FPP1',\n",
    "                                         'GER',\n",
    "                                         'JJ',\n",
    "                                         'NN',\n",
    "                                         'NOMZ',\n",
    "                                         'PHC',\n",
    "                                         'PIN',\n",
    "                                         'PIT',\n",
    "                                         'SYNE',\n",
    "                                         'TIME',\n",
    "                                         'TOBJ',\n",
    "                                         'TPP3',\n",
    "                                         'Tokens',\n",
    "                                         'VB',\n",
    "                                         'XX0',\n",
    "                                         'Closest_Text_Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e35e743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1t_train = df1_tabloids[:72]\n",
    "df2t_train = df2_tabloids[:72]\n",
    "df1b_train = df1_broadsheets[:73]\n",
    "df2b_train = df2_broadsheets[:73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50ce004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1t_test = df1_tabloids[72:]\n",
    "df2t_test = df2_tabloids[72:]\n",
    "df1b_test = df1_broadsheets[73:]\n",
    "df2b_test = df2_broadsheets[73:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22823fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_tabloids.to_csv('tabloids_dimensions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22756b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tabloids.to_csv('tabloids_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0428b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_broadsheets.to_csv('broadsheets_dimensions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b991eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_broadsheets.to_csv('broadsheets_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1aa43c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1_t = df1t_train['Closest_Text_Type']\n",
    "y_test1_t = df1t_test['Closest_Text_Type']\n",
    "\n",
    "x_train1_t = df1t_train.drop(['Closest_Text_Type'], axis=1)\n",
    "x_test1_t = df1t_test.drop(['Closest_Text_Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc128969",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1_b = df1b_train['Closest_Text_Type']\n",
    "y_test1_b = df1b_test['Closest_Text_Type']\n",
    "\n",
    "x_train1_b = df1b_train.drop(['Closest_Text_Type'], axis=1)\n",
    "x_test1_b = df1b_test.drop(['Closest_Text_Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4438ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2_t = df2t_train['Closest_Text_Type']\n",
    "y_test2_t = df2t_test['Closest_Text_Type']\n",
    "\n",
    "x_train2_t = df2t_train.drop(['Closest_Text_Type'], axis=1)\n",
    "x_test2_t = df2t_test.drop(['Closest_Text_Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4345f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2_b = df2b_train['Closest_Text_Type']\n",
    "y_test2_b = df2b_test['Closest_Text_Type']\n",
    "\n",
    "x_train2_b = df2b_train.drop(['Closest_Text_Type'], axis=1)\n",
    "x_test2_b = df2b_test.drop(['Closest_Text_Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "996617bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWL</th>\n",
       "      <th>FPP1</th>\n",
       "      <th>GER</th>\n",
       "      <th>JJ</th>\n",
       "      <th>NN</th>\n",
       "      <th>NOMZ</th>\n",
       "      <th>PHC</th>\n",
       "      <th>PIN</th>\n",
       "      <th>PIT</th>\n",
       "      <th>SYNE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>TOBJ</th>\n",
       "      <th>TPP3</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>VB</th>\n",
       "      <th>XX0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10.46</td>\n",
       "      <td>23.11</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.73</td>\n",
       "      <td>11.92</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.14</td>\n",
       "      <td>411.0</td>\n",
       "      <td>9.98</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.06</td>\n",
       "      <td>32.12</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>17.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.03</td>\n",
       "      <td>165.0</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.22</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.59</td>\n",
       "      <td>22.99</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.46</td>\n",
       "      <td>6.67</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>5.06</td>\n",
       "      <td>435.0</td>\n",
       "      <td>12.64</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.51</td>\n",
       "      <td>30.66</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.46</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.62</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.91</td>\n",
       "      <td>31.78</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.87</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>343.0</td>\n",
       "      <td>10.79</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4.41</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.87</td>\n",
       "      <td>8.23</td>\n",
       "      <td>30.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.26</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.46</td>\n",
       "      <td>231.0</td>\n",
       "      <td>11.26</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4.31</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>7.17</td>\n",
       "      <td>23.77</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.29</td>\n",
       "      <td>669.0</td>\n",
       "      <td>10.91</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4.37</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.12</td>\n",
       "      <td>23.62</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>10.26</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.42</td>\n",
       "      <td>614.0</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4.81</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10.03</td>\n",
       "      <td>33.01</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.97</td>\n",
       "      <td>12.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.94</td>\n",
       "      <td>309.0</td>\n",
       "      <td>7.12</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4.52</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.43</td>\n",
       "      <td>27.18</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.51</td>\n",
       "      <td>15.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AWL  FPP1   GER     JJ     NN  NOMZ   PHC    PIN   PIT  SYNE  TIME  TOBJ  \\\n",
       "0   4.51  0.49  0.24  10.46  23.11  4.38  0.73  11.92  1.22  0.73  0.24  0.00   \n",
       "1   4.38  0.00  0.00   6.06  32.12  1.82  0.61  17.58  0.00  0.00  1.21  0.00   \n",
       "2   4.22  4.14  0.00   7.59  22.99  2.76  0.46   6.67  1.38  0.23  1.15  0.46   \n",
       "3   4.79  0.85  0.43   9.51  30.66  1.07  1.50  11.00  0.96  0.00  0.53  0.11   \n",
       "4   4.62  2.92  0.00   9.91  31.78  0.29  0.87   9.62  1.75  0.00  0.00  0.00   \n",
       "..   ...   ...   ...    ...    ...   ...   ...    ...   ...   ...   ...   ...   \n",
       "68  4.41  2.16  0.87   8.23  30.30  0.00  0.00  11.26  0.87  0.00  0.43  0.00   \n",
       "69  4.31  2.54  0.60   7.17  23.77  1.79  0.75   8.67  1.20  0.00  0.30  0.00   \n",
       "70  4.37  2.44  0.49   9.12  23.62  2.61  0.81  10.26  0.81  0.49  0.49  0.00   \n",
       "71  4.81  0.97  0.65  10.03  33.01  3.24  0.97  12.30  0.65  0.00  0.32  0.65   \n",
       "72  4.52  0.71  0.10   9.43  27.18  3.35  0.51  15.82  0.61  0.51  0.51  0.20   \n",
       "\n",
       "    TPP3  Tokens     VB   XX0  \n",
       "0   4.14   411.0   9.98  0.49  \n",
       "1   3.03   165.0   9.70  0.00  \n",
       "2   5.06   435.0  12.64  1.38  \n",
       "3   2.46   936.0   7.69  0.75  \n",
       "4   0.58   343.0  10.79  0.58  \n",
       "..   ...     ...    ...   ...  \n",
       "68  3.46   231.0  11.26  0.43  \n",
       "69  3.29   669.0  10.91  1.49  \n",
       "70  3.42   614.0  13.36  0.81  \n",
       "71  1.94   309.0   7.12  0.32  \n",
       "72  0.61   986.0   9.03  0.20  \n",
       "\n",
       "[73 rows x 16 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6fed51",
   "metadata": {},
   "source": [
    "# Нейросеть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b477b8",
   "metadata": {},
   "source": [
    "### Нейросеть: Tabloids (Dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a29d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "algorithms = []\n",
    "datasets = []\n",
    "features = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48285f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 141ms/step - loss: 1.1080 - accuracy: 0.2778 - val_loss: 2.3744 - val_accuracy: 0.1944\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.5886 - accuracy: 0.3056 - val_loss: 1.5179 - val_accuracy: 0.1944\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.6207 - accuracy: 0.3889 - val_loss: 0.9767 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.4105 - accuracy: 0.4444 - val_loss: 1.7872 - val_accuracy: 0.1389\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0770 - accuracy: 0.2500 - val_loss: 1.4385 - val_accuracy: 0.1389\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.8047 - accuracy: 0.2778 - val_loss: 1.0091 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3820 - accuracy: 0.4444 - val_loss: 0.9849 - val_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1498 - accuracy: 0.4444 - val_loss: 1.9919 - val_accuracy: 0.1944\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.8945 - accuracy: 0.3056 - val_loss: 1.8093 - val_accuracy: 0.1944\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.7329 - accuracy: 0.3056 - val_loss: 1.0206 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.4041 - accuracy: 0.4444 - val_loss: 1.0562 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.6633 - accuracy: 0.4444 - val_loss: 0.9994 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.5121 - accuracy: 0.4444 - val_loss: 1.2544 - val_accuracy: 0.1389\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.4683 - accuracy: 0.2500 - val_loss: 1.8331 - val_accuracy: 0.1389\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7674 - accuracy: 0.2500 - val_loss: 1.7529 - val_accuracy: 0.1389\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.5765 - accuracy: 0.2500 - val_loss: 1.3356 - val_accuracy: 0.1389\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.2099 - accuracy: 0.2778 - val_loss: 1.1555 - val_accuracy: 0.1944\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1578 - accuracy: 0.3056 - val_loss: 1.1113 - val_accuracy: 0.1944\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1981 - accuracy: 0.3056 - val_loss: 0.9962 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2312 - accuracy: 0.4444 - val_loss: 0.9313 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.3176 - accuracy: 0.4444 - val_loss: 0.9194 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3494 - accuracy: 0.4444 - val_loss: 0.8909 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2387 - accuracy: 0.4444 - val_loss: 0.9070 - val_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0905 - accuracy: 0.4444 - val_loss: 1.0443 - val_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0890 - accuracy: 0.4167 - val_loss: 1.2401 - val_accuracy: 0.1389\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1610 - accuracy: 0.2500 - val_loss: 1.2854 - val_accuracy: 0.1389\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1734 - accuracy: 0.2500 - val_loss: 1.1202 - val_accuracy: 0.1389\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1078 - accuracy: 0.2778 - val_loss: 0.9432 - val_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0651 - accuracy: 0.4444 - val_loss: 0.8839 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0904 - accuracy: 0.4444 - val_loss: 0.8719 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1453 - accuracy: 0.4444 - val_loss: 0.8728 - val_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1603 - accuracy: 0.4444 - val_loss: 0.8778 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1188 - accuracy: 0.4444 - val_loss: 0.9271 - val_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0815 - accuracy: 0.4444 - val_loss: 1.0066 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0691 - accuracy: 0.4444 - val_loss: 1.0239 - val_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0689 - accuracy: 0.4444 - val_loss: 1.0401 - val_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0946 - accuracy: 0.3611 - val_loss: 1.0592 - val_accuracy: 0.1389\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1192 - accuracy: 0.2222 - val_loss: 1.0408 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1030 - accuracy: 0.4444 - val_loss: 1.0486 - val_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0830 - accuracy: 0.4444 - val_loss: 1.0917 - val_accuracy: 0.5833\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0899 - accuracy: 0.6389 - val_loss: 1.1362 - val_accuracy: 0.1944\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1072 - accuracy: 0.3056 - val_loss: 1.1438 - val_accuracy: 0.1944\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1058 - accuracy: 0.3056 - val_loss: 1.1399 - val_accuracy: 0.1944\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1050 - accuracy: 0.3056 - val_loss: 1.1154 - val_accuracy: 0.2500\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0925 - accuracy: 0.5000 - val_loss: 1.0467 - val_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0711 - accuracy: 0.4444 - val_loss: 0.9468 - val_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0786 - accuracy: 0.4444 - val_loss: 0.8962 - val_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0977 - accuracy: 0.4444 - val_loss: 0.8823 - val_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1023 - accuracy: 0.4444 - val_loss: 0.8828 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0864 - accuracy: 0.4444 - val_loss: 0.9046 - val_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0732 - accuracy: 0.4444 - val_loss: 0.9318 - val_accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0666 - accuracy: 0.4444 - val_loss: 0.9689 - val_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0779 - accuracy: 0.5000 - val_loss: 1.0422 - val_accuracy: 0.1944\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1105 - accuracy: 0.3056 - val_loss: 1.0801 - val_accuracy: 0.1944\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1200 - accuracy: 0.3056 - val_loss: 1.0032 - val_accuracy: 0.5833\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0731 - accuracy: 0.6389 - val_loss: 0.8970 - val_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0678 - accuracy: 0.4444 - val_loss: 0.8727 - val_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1317 - accuracy: 0.4444 - val_loss: 0.8971 - val_accuracy: 0.6667\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1821 - accuracy: 0.4444 - val_loss: 0.9225 - val_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1795 - accuracy: 0.4444 - val_loss: 0.9562 - val_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1426 - accuracy: 0.4444 - val_loss: 1.0115 - val_accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1030 - accuracy: 0.4444 - val_loss: 1.0861 - val_accuracy: 0.1944\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0814 - accuracy: 0.2778 - val_loss: 1.1903 - val_accuracy: 0.1944\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1262 - accuracy: 0.3056 - val_loss: 1.2903 - val_accuracy: 0.1944\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1783 - accuracy: 0.3056 - val_loss: 1.2675 - val_accuracy: 0.1944\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1685 - accuracy: 0.3056 - val_loss: 1.1868 - val_accuracy: 0.1944\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1200 - accuracy: 0.3056 - val_loss: 1.1245 - val_accuracy: 0.1944\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0951 - accuracy: 0.3333 - val_loss: 1.0511 - val_accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0693 - accuracy: 0.4444 - val_loss: 0.9740 - val_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0500 - accuracy: 0.4444 - val_loss: 0.9045 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0694 - accuracy: 0.4444 - val_loss: 0.8679 - val_accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1098 - accuracy: 0.4444 - val_loss: 0.8610 - val_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1505 - accuracy: 0.4444 - val_loss: 0.8627 - val_accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1446 - accuracy: 0.4444 - val_loss: 0.8767 - val_accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0927 - accuracy: 0.4444 - val_loss: 0.9309 - val_accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0587 - accuracy: 0.4444 - val_loss: 1.0306 - val_accuracy: 0.6944\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0686 - accuracy: 0.5833 - val_loss: 1.1152 - val_accuracy: 0.1944\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0950 - accuracy: 0.3056 - val_loss: 1.1621 - val_accuracy: 0.1944\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1184 - accuracy: 0.3056 - val_loss: 1.1700 - val_accuracy: 0.1944\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1295 - accuracy: 0.3056 - val_loss: 1.1208 - val_accuracy: 0.1944\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1163 - accuracy: 0.3056 - val_loss: 1.0288 - val_accuracy: 0.1944\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1024 - accuracy: 0.2778 - val_loss: 0.9476 - val_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0919 - accuracy: 0.4444 - val_loss: 0.9115 - val_accuracy: 0.6667\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0876 - accuracy: 0.4444 - val_loss: 0.8934 - val_accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0885 - accuracy: 0.4444 - val_loss: 0.8841 - val_accuracy: 0.6667\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0892 - accuracy: 0.4444 - val_loss: 0.8876 - val_accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0705 - accuracy: 0.4444 - val_loss: 0.9179 - val_accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0530 - accuracy: 0.4444 - val_loss: 0.9917 - val_accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0743 - accuracy: 0.4444 - val_loss: 1.0899 - val_accuracy: 0.1389\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0984 - accuracy: 0.2500 - val_loss: 1.1639 - val_accuracy: 0.1389\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1100 - accuracy: 0.2500 - val_loss: 1.1802 - val_accuracy: 0.1944\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1111 - accuracy: 0.3333 - val_loss: 1.1687 - val_accuracy: 0.1944\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1147 - accuracy: 0.3056 - val_loss: 1.1150 - val_accuracy: 0.1944\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0947 - accuracy: 0.3056 - val_loss: 1.0026 - val_accuracy: 0.6944\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0710 - accuracy: 0.5833 - val_loss: 0.9204 - val_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0589 - accuracy: 0.4444 - val_loss: 0.8863 - val_accuracy: 0.6667\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0774 - accuracy: 0.4444 - val_loss: 0.8777 - val_accuracy: 0.6667\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0808 - accuracy: 0.4444 - val_loss: 0.8836 - val_accuracy: 0.6667\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0722 - accuracy: 0.4444 - val_loss: 0.8972 - val_accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0623 - accuracy: 0.4444 - val_loss: 0.9182 - val_accuracy: 0.6667\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(x_train1_t)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(X_scale,\n",
    "    y_train1_t, test_size=0.5, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(6,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = testY.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Tabloids (обучающая выборка)')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd4976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd27226d",
   "metadata": {},
   "source": [
    "### Нейросеть: Tabloids (основные параметры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa6d0d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 1.4030 - accuracy: 0.3333 - val_loss: 1.3296 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.2239 - accuracy: 0.3889 - val_loss: 1.4893 - val_accuracy: 0.1944\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0035 - accuracy: 0.2778 - val_loss: 1.0726 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2933 - accuracy: 0.3889 - val_loss: 1.3720 - val_accuracy: 0.1389\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3493 - accuracy: 0.2500 - val_loss: 1.5528 - val_accuracy: 0.1389\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6315 - accuracy: 0.2778 - val_loss: 1.0385 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.5163 - accuracy: 0.4444 - val_loss: 0.8779 - val_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1547 - accuracy: 0.4444 - val_loss: 1.3071 - val_accuracy: 0.1944\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2500 - accuracy: 0.3056 - val_loss: 1.4789 - val_accuracy: 0.1944\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3143 - accuracy: 0.3056 - val_loss: 1.0248 - val_accuracy: 0.4444\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0608 - accuracy: 0.4722 - val_loss: 0.8852 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1645 - accuracy: 0.4444 - val_loss: 0.9012 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2338 - accuracy: 0.4444 - val_loss: 0.8873 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1242 - accuracy: 0.4444 - val_loss: 0.9250 - val_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0516 - accuracy: 0.4444 - val_loss: 1.0834 - val_accuracy: 0.1944\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0842 - accuracy: 0.3056 - val_loss: 1.1843 - val_accuracy: 0.1944\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1117 - accuracy: 0.3056 - val_loss: 1.0749 - val_accuracy: 0.7778\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0766 - accuracy: 0.7778 - val_loss: 0.9341 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0708 - accuracy: 0.4444 - val_loss: 0.8742 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0722 - accuracy: 0.4444 - val_loss: 0.8916 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0659 - accuracy: 0.4444 - val_loss: 0.9696 - val_accuracy: 0.6944\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0830 - accuracy: 0.6389 - val_loss: 1.0532 - val_accuracy: 0.1944\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1002 - accuracy: 0.3056 - val_loss: 1.0681 - val_accuracy: 0.1944\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0757 - accuracy: 0.3056 - val_loss: 1.0858 - val_accuracy: 0.3611\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0677 - accuracy: 0.5556 - val_loss: 1.1280 - val_accuracy: 0.1389\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0943 - accuracy: 0.2500 - val_loss: 0.9971 - val_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0640 - accuracy: 0.4444 - val_loss: 0.8951 - val_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0465 - accuracy: 0.4444 - val_loss: 0.8685 - val_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0527 - accuracy: 0.4444 - val_loss: 0.8451 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1172 - accuracy: 0.4444 - val_loss: 0.8434 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1131 - accuracy: 0.4444 - val_loss: 0.9077 - val_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0695 - accuracy: 0.4444 - val_loss: 0.9196 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0496 - accuracy: 0.4444 - val_loss: 0.8553 - val_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0789 - accuracy: 0.4444 - val_loss: 0.8481 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0568 - accuracy: 0.4444 - val_loss: 0.9447 - val_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0246 - accuracy: 0.4444 - val_loss: 1.1175 - val_accuracy: 0.1389\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0781 - accuracy: 0.2500 - val_loss: 1.0809 - val_accuracy: 0.1389\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0708 - accuracy: 0.3056 - val_loss: 0.9147 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0166 - accuracy: 0.4444 - val_loss: 0.9061 - val_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0523 - accuracy: 0.3889 - val_loss: 1.0093 - val_accuracy: 0.1944\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0807 - accuracy: 0.3056 - val_loss: 0.9702 - val_accuracy: 0.5833\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0159 - accuracy: 0.6111 - val_loss: 0.9259 - val_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0143 - accuracy: 0.4444 - val_loss: 0.9599 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0556 - accuracy: 0.4444 - val_loss: 0.9244 - val_accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0444 - accuracy: 0.4444 - val_loss: 0.8784 - val_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0148 - accuracy: 0.4444 - val_loss: 0.8796 - val_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.9857 - accuracy: 0.4444 - val_loss: 0.9067 - val_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.9757 - accuracy: 0.4444 - val_loss: 0.9611 - val_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.9845 - accuracy: 0.5000 - val_loss: 0.9710 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9711 - accuracy: 0.5278 - val_loss: 0.8645 - val_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.9750 - accuracy: 0.4444 - val_loss: 0.8308 - val_accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0187 - accuracy: 0.4444 - val_loss: 0.8536 - val_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0320 - accuracy: 0.4444 - val_loss: 0.8342 - val_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0004 - accuracy: 0.4444 - val_loss: 0.8585 - val_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9536 - accuracy: 0.4444 - val_loss: 0.9820 - val_accuracy: 0.7222\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9441 - accuracy: 0.7222 - val_loss: 1.2846 - val_accuracy: 0.1944\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0967 - accuracy: 0.3333 - val_loss: 1.4702 - val_accuracy: 0.1944\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1930 - accuracy: 0.3333 - val_loss: 1.2782 - val_accuracy: 0.2500\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0739 - accuracy: 0.4167 - val_loss: 0.9690 - val_accuracy: 0.8056\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9257 - accuracy: 0.8611 - val_loss: 0.8478 - val_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9989 - accuracy: 0.4444 - val_loss: 0.8177 - val_accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0530 - accuracy: 0.4444 - val_loss: 0.7918 - val_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9832 - accuracy: 0.4444 - val_loss: 0.8129 - val_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8959 - accuracy: 0.5000 - val_loss: 0.9919 - val_accuracy: 0.3611\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9262 - accuracy: 0.4722 - val_loss: 1.2025 - val_accuracy: 0.2778\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0079 - accuracy: 0.4722 - val_loss: 1.2449 - val_accuracy: 0.3056\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0032 - accuracy: 0.5556 - val_loss: 1.0863 - val_accuracy: 0.1944\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9542 - accuracy: 0.4444 - val_loss: 0.8763 - val_accuracy: 0.6944\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9647 - accuracy: 0.5000 - val_loss: 0.7822 - val_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9771 - accuracy: 0.4444 - val_loss: 0.7606 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9409 - accuracy: 0.4722 - val_loss: 0.8694 - val_accuracy: 0.7222\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9563 - accuracy: 0.6389 - val_loss: 0.9273 - val_accuracy: 0.3611\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9270 - accuracy: 0.4444 - val_loss: 0.8580 - val_accuracy: 0.7222\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8492 - accuracy: 0.6111 - val_loss: 0.8405 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8171 - accuracy: 0.7222 - val_loss: 0.8511 - val_accuracy: 0.7222\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8445 - accuracy: 0.6389 - val_loss: 0.8398 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8518 - accuracy: 0.5278 - val_loss: 0.7948 - val_accuracy: 0.6944\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8259 - accuracy: 0.5000 - val_loss: 0.7808 - val_accuracy: 0.6944\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8038 - accuracy: 0.5278 - val_loss: 0.7799 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7761 - accuracy: 0.6944 - val_loss: 0.8329 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7967 - accuracy: 0.6389 - val_loss: 0.8734 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7686 - accuracy: 0.7500 - val_loss: 1.0063 - val_accuracy: 0.2778\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8360 - accuracy: 0.5556 - val_loss: 1.0491 - val_accuracy: 0.2500\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8522 - accuracy: 0.4722 - val_loss: 0.8467 - val_accuracy: 0.7222\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7371 - accuracy: 0.8611 - val_loss: 0.7342 - val_accuracy: 0.7222\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7348 - accuracy: 0.7222 - val_loss: 0.6892 - val_accuracy: 0.7222\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7837 - accuracy: 0.6389 - val_loss: 0.6733 - val_accuracy: 0.7222\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7637 - accuracy: 0.6111 - val_loss: 0.6824 - val_accuracy: 0.7222\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6979 - accuracy: 0.6667 - val_loss: 0.7678 - val_accuracy: 0.7778\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6859 - accuracy: 0.8056 - val_loss: 0.8849 - val_accuracy: 0.4444\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7277 - accuracy: 0.6944 - val_loss: 0.8573 - val_accuracy: 0.5556\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6930 - accuracy: 0.7778 - val_loss: 0.7075 - val_accuracy: 0.8056\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6446 - accuracy: 0.7500 - val_loss: 0.6369 - val_accuracy: 0.7222\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6930 - accuracy: 0.6389 - val_loss: 0.6360 - val_accuracy: 0.7222\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7290 - accuracy: 0.6389 - val_loss: 0.6327 - val_accuracy: 0.7222\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6533 - accuracy: 0.6944 - val_loss: 0.7392 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6213 - accuracy: 0.8889 - val_loss: 0.9302 - val_accuracy: 0.4167\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7117 - accuracy: 0.6667 - val_loss: 0.9156 - val_accuracy: 0.4722\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6873 - accuracy: 0.6667 - val_loss: 0.7710 - val_accuracy: 0.7222\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6314 - accuracy: 0.7222 - val_loss: 0.6670 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(x_train2_t)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(X_scale,\n",
    "    y_train2_t, test_size=0.5, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(16,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = testY.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Tabloids (обучающая выборка)')\n",
    "features.append('Features')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb970805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 68ms/step - loss: 1.5419 - accuracy: 0.3611 - val_loss: 1.1526 - val_accuracy: 0.7460\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1145 - accuracy: 0.4583 - val_loss: 0.9020 - val_accuracy: 0.3810\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.0490 - accuracy: 0.2917 - val_loss: 0.6890 - val_accuracy: 0.6984\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7325 - accuracy: 0.6389 - val_loss: 0.7099 - val_accuracy: 0.7460\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7779 - accuracy: 0.6389 - val_loss: 0.5797 - val_accuracy: 0.7302\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5975 - accuracy: 0.6667 - val_loss: 0.5807 - val_accuracy: 0.7302\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6216 - accuracy: 0.7083 - val_loss: 0.5614 - val_accuracy: 0.6984\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5642 - accuracy: 0.7639 - val_loss: 0.4226 - val_accuracy: 0.8254\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4836 - accuracy: 0.7500 - val_loss: 0.4520 - val_accuracy: 0.7619\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4861 - accuracy: 0.7639 - val_loss: 0.3736 - val_accuracy: 0.9524\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3913 - accuracy: 0.9583 - val_loss: 0.3444 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3630 - accuracy: 0.8472 - val_loss: 0.3529 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3509 - accuracy: 0.8750 - val_loss: 0.3236 - val_accuracy: 0.9524\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3486 - accuracy: 0.9167 - val_loss: 0.2869 - val_accuracy: 0.9524\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3085 - accuracy: 0.9167 - val_loss: 0.2813 - val_accuracy: 0.8413\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2787 - accuracy: 0.9028 - val_loss: 0.2682 - val_accuracy: 0.9524\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2787 - accuracy: 0.9306 - val_loss: 0.2655 - val_accuracy: 0.9524\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2669 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9683\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2312 - accuracy: 0.9722 - val_loss: 0.2167 - val_accuracy: 0.9524\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2249 - accuracy: 0.9722 - val_loss: 0.2080 - val_accuracy: 0.9683\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2124 - accuracy: 0.9583 - val_loss: 0.2026 - val_accuracy: 0.9683\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2053 - accuracy: 0.9722 - val_loss: 0.2065 - val_accuracy: 0.9683\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1976 - accuracy: 0.9861 - val_loss: 0.2115 - val_accuracy: 0.9524\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1911 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9683\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1766 - accuracy: 0.9861 - val_loss: 0.1819 - val_accuracy: 0.9683\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1756 - accuracy: 0.9861 - val_loss: 0.1747 - val_accuracy: 0.9683\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1611 - accuracy: 0.9722 - val_loss: 0.1719 - val_accuracy: 0.9683\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1534 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9683\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1513 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9683\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1467 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9683\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1440 - accuracy: 0.9861 - val_loss: 0.1539 - val_accuracy: 0.9683\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1392 - accuracy: 0.9861 - val_loss: 0.1551 - val_accuracy: 0.9524\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1350 - accuracy: 0.9722 - val_loss: 0.1551 - val_accuracy: 0.9683\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1467 - accuracy: 0.9444 - val_loss: 0.1648 - val_accuracy: 0.9683\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1328 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9365\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1521 - accuracy: 0.9722 - val_loss: 0.1422 - val_accuracy: 0.9524\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1227 - accuracy: 0.9861 - val_loss: 0.1623 - val_accuracy: 0.9524\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1436 - accuracy: 0.9444 - val_loss: 0.1347 - val_accuracy: 0.9841\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1220 - accuracy: 0.9722 - val_loss: 0.1741 - val_accuracy: 0.9524\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1206 - accuracy: 0.9861 - val_loss: 0.1514 - val_accuracy: 0.9683\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1085 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9524\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1191 - accuracy: 0.9722 - val_loss: 0.1260 - val_accuracy: 0.9524\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1002 - accuracy: 0.9861 - val_loss: 0.1438 - val_accuracy: 0.9524\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1035 - accuracy: 0.9861 - val_loss: 0.1353 - val_accuracy: 0.9524\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9206\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1165 - accuracy: 0.9722 - val_loss: 0.1287 - val_accuracy: 0.9524\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0927 - accuracy: 0.9861 - val_loss: 0.1469 - val_accuracy: 0.9524\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1069 - accuracy: 0.9722 - val_loss: 0.1193 - val_accuracy: 0.9524\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9683\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9683\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9524\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9683\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9524\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0882 - accuracy: 0.9861 - val_loss: 0.1313 - val_accuracy: 0.9683\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9683\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9524\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9524\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0775 - accuracy: 0.9861 - val_loss: 0.1088 - val_accuracy: 0.9524\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9524\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9365\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9524\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0706 - accuracy: 0.9861 - val_loss: 0.1171 - val_accuracy: 0.9524\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0713 - accuracy: 0.9861 - val_loss: 0.1079 - val_accuracy: 0.9683\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9524\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9206\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0685 - accuracy: 0.9861 - val_loss: 0.1447 - val_accuracy: 0.9206\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9683\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9524\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0548 - accuracy: 0.9861 - val_loss: 0.1067 - val_accuracy: 0.9524\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0548 - accuracy: 0.9861 - val_loss: 0.1003 - val_accuracy: 0.9524\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9524\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9524\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9524\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9683\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9524\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9524\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9683\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9524\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9683\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9683\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9683\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9683\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9683\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9524\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9683\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9524\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9683\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9524\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9683\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9524\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9683\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9683\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9524\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9683\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 0.9524\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9524\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9524\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9524\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9524\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9524\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train1_t)\n",
    "y_test = lb.transform(y_test1_t)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(6,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(x_train1_t, y_train, validation_data=(x_test1_t, y_test),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(x_test1_t, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = y_test.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Tabloids (тестовая выборка)')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8742b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 67ms/step - loss: 1.4797 - accuracy: 0.3889 - val_loss: 0.9938 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1350 - accuracy: 0.4167 - val_loss: 1.0885 - val_accuracy: 0.2063\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9684 - accuracy: 0.5278 - val_loss: 1.1994 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2621 - accuracy: 0.5556 - val_loss: 1.0562 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9857 - accuracy: 0.5833 - val_loss: 1.1416 - val_accuracy: 0.2540\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1696 - accuracy: 0.2917 - val_loss: 1.1678 - val_accuracy: 0.1905\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0955 - accuracy: 0.2917 - val_loss: 0.9603 - val_accuracy: 0.5556\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9565 - accuracy: 0.5694 - val_loss: 1.0703 - val_accuracy: 0.5397\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.0362 - accuracy: 0.5556 - val_loss: 1.0021 - val_accuracy: 0.5397\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9169 - accuracy: 0.5694 - val_loss: 1.0395 - val_accuracy: 0.5397\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0006 - accuracy: 0.5694 - val_loss: 0.9716 - val_accuracy: 0.5238\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9218 - accuracy: 0.5833 - val_loss: 1.0396 - val_accuracy: 0.5397\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9563 - accuracy: 0.5139 - val_loss: 0.9678 - val_accuracy: 0.5397\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8847 - accuracy: 0.5833 - val_loss: 0.9713 - val_accuracy: 0.5397\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9234 - accuracy: 0.5694 - val_loss: 0.9489 - val_accuracy: 0.5556\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8919 - accuracy: 0.5417 - val_loss: 0.9726 - val_accuracy: 0.5238\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9109 - accuracy: 0.5556 - val_loss: 0.9233 - val_accuracy: 0.5397\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9161 - accuracy: 0.5694 - val_loss: 0.9132 - val_accuracy: 0.5397\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8893 - accuracy: 0.5694 - val_loss: 0.9868 - val_accuracy: 0.4444\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9249 - accuracy: 0.5000 - val_loss: 0.8834 - val_accuracy: 0.5397\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8816 - accuracy: 0.6250 - val_loss: 0.8763 - val_accuracy: 0.5556\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8371 - accuracy: 0.5833 - val_loss: 0.9368 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8770 - accuracy: 0.5278 - val_loss: 0.8638 - val_accuracy: 0.5556\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8112 - accuracy: 0.6250 - val_loss: 0.9147 - val_accuracy: 0.6349\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8675 - accuracy: 0.6111 - val_loss: 0.9215 - val_accuracy: 0.6190\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8296 - accuracy: 0.6528 - val_loss: 0.8821 - val_accuracy: 0.5556\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8279 - accuracy: 0.5694 - val_loss: 0.8853 - val_accuracy: 0.5873\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7949 - accuracy: 0.5833 - val_loss: 0.8724 - val_accuracy: 0.5556\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7924 - accuracy: 0.6389 - val_loss: 0.8411 - val_accuracy: 0.5397\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7976 - accuracy: 0.6389 - val_loss: 0.8068 - val_accuracy: 0.6349\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8186 - accuracy: 0.5972 - val_loss: 0.8022 - val_accuracy: 0.6508\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7308 - accuracy: 0.6528 - val_loss: 0.9018 - val_accuracy: 0.5556\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7915 - accuracy: 0.5972 - val_loss: 0.7548 - val_accuracy: 0.6825\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6911 - accuracy: 0.6806 - val_loss: 0.8052 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7036 - accuracy: 0.6250 - val_loss: 0.7228 - val_accuracy: 0.6190\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6354 - accuracy: 0.6667 - val_loss: 0.7778 - val_accuracy: 0.6349\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7896 - accuracy: 0.6250 - val_loss: 0.6877 - val_accuracy: 0.6508\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6136 - accuracy: 0.7083 - val_loss: 0.7211 - val_accuracy: 0.6032\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6318 - accuracy: 0.7222 - val_loss: 0.6653 - val_accuracy: 0.7460\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6088 - accuracy: 0.7222 - val_loss: 0.6567 - val_accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6009 - accuracy: 0.7361 - val_loss: 0.6496 - val_accuracy: 0.7778\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6485 - accuracy: 0.6944 - val_loss: 0.6207 - val_accuracy: 0.7302\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6108 - accuracy: 0.7222 - val_loss: 0.7815 - val_accuracy: 0.6190\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7233 - accuracy: 0.6528 - val_loss: 0.6644 - val_accuracy: 0.6984\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5833 - accuracy: 0.7361 - val_loss: 0.7103 - val_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6330 - accuracy: 0.7083 - val_loss: 0.5965 - val_accuracy: 0.7460\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5613 - accuracy: 0.7361 - val_loss: 0.7300 - val_accuracy: 0.5714\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6062 - accuracy: 0.6528 - val_loss: 0.5954 - val_accuracy: 0.7460\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5065 - accuracy: 0.8194 - val_loss: 0.7379 - val_accuracy: 0.5714\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6468 - accuracy: 0.7222 - val_loss: 0.6752 - val_accuracy: 0.6984\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7312 - accuracy: 0.7083 - val_loss: 0.7175 - val_accuracy: 0.5873\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6813 - accuracy: 0.6389 - val_loss: 0.8263 - val_accuracy: 0.4762\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6567 - accuracy: 0.6944 - val_loss: 0.9613 - val_accuracy: 0.6032\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7300 - accuracy: 0.6667 - val_loss: 0.6782 - val_accuracy: 0.7143\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5335 - accuracy: 0.8194 - val_loss: 0.6716 - val_accuracy: 0.6349\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5600 - accuracy: 0.7361 - val_loss: 0.6282 - val_accuracy: 0.6825\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4814 - accuracy: 0.8194 - val_loss: 0.6253 - val_accuracy: 0.7302\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4849 - accuracy: 0.7639 - val_loss: 0.6372 - val_accuracy: 0.7460\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5074 - accuracy: 0.7917 - val_loss: 0.5841 - val_accuracy: 0.7302\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.5658 - val_accuracy: 0.7460\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4297 - accuracy: 0.8472 - val_loss: 0.5393 - val_accuracy: 0.7619\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4564 - accuracy: 0.8056 - val_loss: 0.5438 - val_accuracy: 0.7778\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4483 - accuracy: 0.8056 - val_loss: 0.5587 - val_accuracy: 0.7302\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4417 - accuracy: 0.8056 - val_loss: 0.5818 - val_accuracy: 0.7143\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4322 - accuracy: 0.8333 - val_loss: 0.5350 - val_accuracy: 0.7619\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4293 - accuracy: 0.8056 - val_loss: 0.5505 - val_accuracy: 0.7778\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4267 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7619\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4020 - accuracy: 0.8333 - val_loss: 0.6052 - val_accuracy: 0.6984\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.5279 - val_accuracy: 0.7778\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4148 - accuracy: 0.8056 - val_loss: 0.5366 - val_accuracy: 0.7619\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3932 - accuracy: 0.8611 - val_loss: 0.6449 - val_accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5376 - accuracy: 0.7222 - val_loss: 0.5931 - val_accuracy: 0.7302\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5268 - accuracy: 0.7778 - val_loss: 0.6152 - val_accuracy: 0.7143\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.7529 - val_accuracy: 0.5556\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5721 - accuracy: 0.7361 - val_loss: 0.5652 - val_accuracy: 0.7778\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.5308 - val_accuracy: 0.7619\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4512 - accuracy: 0.7639 - val_loss: 0.5119 - val_accuracy: 0.7778\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4241 - accuracy: 0.8194 - val_loss: 0.5048 - val_accuracy: 0.7460\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4515 - accuracy: 0.8056 - val_loss: 0.6635 - val_accuracy: 0.5714\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4922 - accuracy: 0.7500 - val_loss: 0.6062 - val_accuracy: 0.7460\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4361 - accuracy: 0.8194 - val_loss: 0.6490 - val_accuracy: 0.6984\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4841 - accuracy: 0.7500 - val_loss: 0.5283 - val_accuracy: 0.7302\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4080 - accuracy: 0.8333 - val_loss: 0.5793 - val_accuracy: 0.7460\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3948 - accuracy: 0.7778 - val_loss: 0.6397 - val_accuracy: 0.6825\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3874 - accuracy: 0.8333 - val_loss: 0.5701 - val_accuracy: 0.7302\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5700 - accuracy: 0.7222 - val_loss: 0.5148 - val_accuracy: 0.7619\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3341 - accuracy: 0.8472 - val_loss: 0.5991 - val_accuracy: 0.6984\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4649 - accuracy: 0.8056 - val_loss: 0.5941 - val_accuracy: 0.7460\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4647 - accuracy: 0.8056 - val_loss: 0.6251 - val_accuracy: 0.7460\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4917 - accuracy: 0.7917 - val_loss: 0.7055 - val_accuracy: 0.5873\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4640 - accuracy: 0.7917 - val_loss: 0.5297 - val_accuracy: 0.7619\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4451 - accuracy: 0.8056 - val_loss: 0.5975 - val_accuracy: 0.6825\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.5403 - val_accuracy: 0.7778\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4524 - accuracy: 0.8194 - val_loss: 0.5234 - val_accuracy: 0.7937\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3737 - accuracy: 0.8472 - val_loss: 0.6577 - val_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3903 - accuracy: 0.8194 - val_loss: 0.6111 - val_accuracy: 0.7778\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5414 - accuracy: 0.7639 - val_loss: 0.5260 - val_accuracy: 0.7460\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3754 - accuracy: 0.8194 - val_loss: 0.6772 - val_accuracy: 0.6508\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4037 - accuracy: 0.7917 - val_loss: 0.6453 - val_accuracy: 0.7619\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5001 - accuracy: 0.7917 - val_loss: 0.5523 - val_accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train2_t)\n",
    "y_test = lb.transform(y_test2_t)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(16,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(x_train2_t, y_train, validation_data=(x_test2_t, y_test),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(x_test2_t, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = y_test.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Tabloids (тестовая выборка)')\n",
    "features.append('Features')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da35249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9c08229",
   "metadata": {},
   "source": [
    "### Нейросеть: Broadsheets (Dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79dc8b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 1.0328 - accuracy: 0.6389 - val_loss: 1.3259 - val_accuracy: 0.5405\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1411 - accuracy: 0.6389 - val_loss: 1.5795 - val_accuracy: 0.4054\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.7023 - accuracy: 0.3056 - val_loss: 1.2802 - val_accuracy: 0.5405\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.2700 - accuracy: 0.6389 - val_loss: 1.6560 - val_accuracy: 0.5405\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.4790 - accuracy: 0.6389 - val_loss: 1.2883 - val_accuracy: 0.5405\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1829 - accuracy: 0.6389 - val_loss: 1.2802 - val_accuracy: 0.4054\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.4116 - accuracy: 0.3056 - val_loss: 1.1427 - val_accuracy: 0.4054\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1598 - accuracy: 0.4167 - val_loss: 1.2177 - val_accuracy: 0.5405\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1426 - accuracy: 0.6389 - val_loss: 1.5518 - val_accuracy: 0.5405\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3347 - accuracy: 0.6389 - val_loss: 1.3173 - val_accuracy: 0.5405\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1488 - accuracy: 0.6389 - val_loss: 0.9573 - val_accuracy: 0.5405\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8852 - accuracy: 0.6389 - val_loss: 0.8350 - val_accuracy: 0.5405\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8099 - accuracy: 0.6389 - val_loss: 0.8363 - val_accuracy: 0.5405\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8181 - accuracy: 0.6389 - val_loss: 0.8372 - val_accuracy: 0.5405\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8117 - accuracy: 0.6389 - val_loss: 0.8272 - val_accuracy: 0.5405\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8116 - accuracy: 0.6389 - val_loss: 0.8308 - val_accuracy: 0.5405\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8302 - accuracy: 0.6389 - val_loss: 0.8417 - val_accuracy: 0.5405\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8316 - accuracy: 0.6389 - val_loss: 0.8688 - val_accuracy: 0.5405\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8317 - accuracy: 0.6389 - val_loss: 0.8684 - val_accuracy: 0.5405\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8385 - accuracy: 0.6389 - val_loss: 0.8626 - val_accuracy: 0.5405\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8404 - accuracy: 0.6389 - val_loss: 0.8722 - val_accuracy: 0.5405\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8442 - accuracy: 0.6389 - val_loss: 0.8561 - val_accuracy: 0.5405\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8340 - accuracy: 0.6389 - val_loss: 0.8427 - val_accuracy: 0.5405\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8452 - accuracy: 0.6389 - val_loss: 0.8505 - val_accuracy: 0.5405\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8123 - accuracy: 0.6389 - val_loss: 0.9672 - val_accuracy: 0.5405\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8839 - accuracy: 0.6389 - val_loss: 0.9251 - val_accuracy: 0.5405\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8411 - accuracy: 0.6389 - val_loss: 0.8251 - val_accuracy: 0.5405\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8287 - accuracy: 0.6389 - val_loss: 0.8248 - val_accuracy: 0.5405\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8427 - accuracy: 0.6389 - val_loss: 0.8230 - val_accuracy: 0.5405\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8028 - accuracy: 0.6389 - val_loss: 0.8440 - val_accuracy: 0.5405\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8733 - accuracy: 0.5278 - val_loss: 0.8677 - val_accuracy: 0.5405\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8573 - accuracy: 0.6389 - val_loss: 0.9144 - val_accuracy: 0.5405\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8489 - accuracy: 0.6389 - val_loss: 1.0006 - val_accuracy: 0.5405\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8864 - accuracy: 0.6389 - val_loss: 1.0093 - val_accuracy: 0.5405\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8898 - accuracy: 0.6389 - val_loss: 0.9595 - val_accuracy: 0.5405\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8564 - accuracy: 0.6389 - val_loss: 0.8674 - val_accuracy: 0.5405\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8100 - accuracy: 0.6389 - val_loss: 0.8317 - val_accuracy: 0.5405\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8143 - accuracy: 0.6389 - val_loss: 0.8348 - val_accuracy: 0.5405\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8268 - accuracy: 0.6389 - val_loss: 0.8376 - val_accuracy: 0.5405\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8088 - accuracy: 0.6389 - val_loss: 0.8759 - val_accuracy: 0.5405\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8058 - accuracy: 0.6389 - val_loss: 1.0061 - val_accuracy: 0.5405\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8863 - accuracy: 0.6389 - val_loss: 1.1135 - val_accuracy: 0.5405\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.9702 - accuracy: 0.6389 - val_loss: 0.9943 - val_accuracy: 0.5405\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8677 - accuracy: 0.6389 - val_loss: 0.8450 - val_accuracy: 0.5405\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8722 - accuracy: 0.5278 - val_loss: 0.8769 - val_accuracy: 0.4054\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9195 - accuracy: 0.3056 - val_loss: 0.8207 - val_accuracy: 0.5405\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8464 - accuracy: 0.6389 - val_loss: 0.8551 - val_accuracy: 0.5405\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7969 - accuracy: 0.6389 - val_loss: 0.9429 - val_accuracy: 0.5405\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8637 - accuracy: 0.6389 - val_loss: 0.9536 - val_accuracy: 0.5405\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8523 - accuracy: 0.6389 - val_loss: 0.8577 - val_accuracy: 0.5405\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7956 - accuracy: 0.6389 - val_loss: 0.8184 - val_accuracy: 0.5405\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8081 - accuracy: 0.6389 - val_loss: 0.8405 - val_accuracy: 0.4054\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8730 - accuracy: 0.3056 - val_loss: 0.8370 - val_accuracy: 0.5405\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8573 - accuracy: 0.3889 - val_loss: 0.8255 - val_accuracy: 0.5405\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8016 - accuracy: 0.6389 - val_loss: 0.8989 - val_accuracy: 0.5405\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8344 - accuracy: 0.6389 - val_loss: 0.9554 - val_accuracy: 0.5405\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8645 - accuracy: 0.6389 - val_loss: 0.9508 - val_accuracy: 0.5405\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8600 - accuracy: 0.6389 - val_loss: 0.9093 - val_accuracy: 0.5405\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8339 - accuracy: 0.6389 - val_loss: 0.8414 - val_accuracy: 0.5405\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8123 - accuracy: 0.6389 - val_loss: 0.8213 - val_accuracy: 0.5405\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8189 - accuracy: 0.6389 - val_loss: 0.8205 - val_accuracy: 0.5405\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8286 - accuracy: 0.6389 - val_loss: 0.8190 - val_accuracy: 0.5405\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8264 - accuracy: 0.6389 - val_loss: 0.8159 - val_accuracy: 0.5405\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8141 - accuracy: 0.6389 - val_loss: 0.8160 - val_accuracy: 0.5405\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8029 - accuracy: 0.6389 - val_loss: 0.8185 - val_accuracy: 0.5405\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7992 - accuracy: 0.6389 - val_loss: 0.8207 - val_accuracy: 0.5405\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7947 - accuracy: 0.6389 - val_loss: 0.8293 - val_accuracy: 0.5405\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7916 - accuracy: 0.6389 - val_loss: 0.8436 - val_accuracy: 0.5405\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7950 - accuracy: 0.6389 - val_loss: 0.8558 - val_accuracy: 0.5405\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8005 - accuracy: 0.6389 - val_loss: 0.8637 - val_accuracy: 0.5405\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8034 - accuracy: 0.6389 - val_loss: 0.8480 - val_accuracy: 0.5405\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7960 - accuracy: 0.6389 - val_loss: 0.8252 - val_accuracy: 0.5405\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7898 - accuracy: 0.6389 - val_loss: 0.8212 - val_accuracy: 0.5405\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7903 - accuracy: 0.6389 - val_loss: 0.8432 - val_accuracy: 0.5405\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8065 - accuracy: 0.6389 - val_loss: 0.8642 - val_accuracy: 0.5405\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8048 - accuracy: 0.6389 - val_loss: 0.8433 - val_accuracy: 0.5405\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7956 - accuracy: 0.6389 - val_loss: 0.8312 - val_accuracy: 0.5405\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7919 - accuracy: 0.6389 - val_loss: 0.8326 - val_accuracy: 0.5405\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7914 - accuracy: 0.6389 - val_loss: 0.8339 - val_accuracy: 0.5405\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7888 - accuracy: 0.6389 - val_loss: 0.8265 - val_accuracy: 0.5405\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7876 - accuracy: 0.6389 - val_loss: 0.8284 - val_accuracy: 0.5405\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7862 - accuracy: 0.6389 - val_loss: 0.8536 - val_accuracy: 0.5405\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7974 - accuracy: 0.6389 - val_loss: 0.8793 - val_accuracy: 0.5405\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8028 - accuracy: 0.6389 - val_loss: 0.8265 - val_accuracy: 0.5405\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7800 - accuracy: 0.6389 - val_loss: 0.8176 - val_accuracy: 0.6757\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8405 - accuracy: 0.6667 - val_loss: 0.8432 - val_accuracy: 0.4054\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8849 - accuracy: 0.3333 - val_loss: 0.8223 - val_accuracy: 0.7297\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8383 - accuracy: 0.8333 - val_loss: 0.8098 - val_accuracy: 0.5405\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7990 - accuracy: 0.6389 - val_loss: 0.8397 - val_accuracy: 0.5405\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7916 - accuracy: 0.6389 - val_loss: 0.8470 - val_accuracy: 0.5405\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7879 - accuracy: 0.6389 - val_loss: 0.8123 - val_accuracy: 0.5405\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7849 - accuracy: 0.6389 - val_loss: 0.8059 - val_accuracy: 0.5405\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8023 - accuracy: 0.6389 - val_loss: 0.8225 - val_accuracy: 0.5405\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8029 - accuracy: 0.6389 - val_loss: 0.8622 - val_accuracy: 0.5405\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8065 - accuracy: 0.6389 - val_loss: 0.8947 - val_accuracy: 0.5405\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8247 - accuracy: 0.6389 - val_loss: 0.9040 - val_accuracy: 0.5405\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8227 - accuracy: 0.6389 - val_loss: 0.8847 - val_accuracy: 0.5405\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8045 - accuracy: 0.6389 - val_loss: 0.8577 - val_accuracy: 0.5405\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7958 - accuracy: 0.6389 - val_loss: 0.8306 - val_accuracy: 0.5405\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7796 - accuracy: 0.6389 - val_loss: 0.8209 - val_accuracy: 0.5405\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000149294FC9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "0.5405405405405406\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(x_train1_b)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(X_scale,\n",
    "    y_train1_b, test_size=0.5, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(6,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = testY.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Broadsheets (обучающая выборка)')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76e32f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 64ms/step - loss: 1.2842 - accuracy: 0.2603 - val_loss: 2.0574 - val_accuracy: 0.5469\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.6344 - accuracy: 0.5890 - val_loss: 1.3726 - val_accuracy: 0.7344\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.3824 - accuracy: 0.5479 - val_loss: 1.7180 - val_accuracy: 0.3594\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.3311 - accuracy: 0.5342 - val_loss: 1.4282 - val_accuracy: 0.5469\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1817 - accuracy: 0.5890 - val_loss: 1.3889 - val_accuracy: 0.5469\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0539 - accuracy: 0.5890 - val_loss: 1.1287 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9487 - accuracy: 0.7671 - val_loss: 1.1293 - val_accuracy: 0.5781\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8238 - accuracy: 0.8493 - val_loss: 0.8679 - val_accuracy: 0.7031\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6565 - accuracy: 0.7397 - val_loss: 0.7931 - val_accuracy: 0.6250\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6096 - accuracy: 0.6986 - val_loss: 0.6993 - val_accuracy: 0.7031\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5645 - accuracy: 0.8356 - val_loss: 0.7252 - val_accuracy: 0.8125\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5588 - accuracy: 0.9178 - val_loss: 0.6593 - val_accuracy: 0.8438\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4689 - accuracy: 0.9041 - val_loss: 0.6576 - val_accuracy: 0.6875\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4928 - accuracy: 0.7671 - val_loss: 0.6587 - val_accuracy: 0.6875\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4712 - accuracy: 0.7945 - val_loss: 0.5866 - val_accuracy: 0.7812\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4117 - accuracy: 0.8904 - val_loss: 0.5628 - val_accuracy: 0.8594\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3935 - accuracy: 0.9315 - val_loss: 0.5297 - val_accuracy: 0.8125\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3698 - accuracy: 0.8904 - val_loss: 0.5019 - val_accuracy: 0.7812\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3507 - accuracy: 0.9041 - val_loss: 0.4969 - val_accuracy: 0.8125\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3246 - accuracy: 0.9315 - val_loss: 0.4674 - val_accuracy: 0.8125\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3082 - accuracy: 0.9041 - val_loss: 0.4667 - val_accuracy: 0.7812\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3066 - accuracy: 0.8904 - val_loss: 0.4520 - val_accuracy: 0.8281\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2879 - accuracy: 0.9315 - val_loss: 0.4501 - val_accuracy: 0.8281\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2770 - accuracy: 0.9452 - val_loss: 0.4097 - val_accuracy: 0.8750\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2458 - accuracy: 0.9589 - val_loss: 0.4002 - val_accuracy: 0.8281\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2410 - accuracy: 0.9452 - val_loss: 0.3969 - val_accuracy: 0.8125\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2318 - accuracy: 0.9589 - val_loss: 0.3915 - val_accuracy: 0.8438\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2260 - accuracy: 0.9452 - val_loss: 0.3966 - val_accuracy: 0.8438\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2155 - accuracy: 0.9452 - val_loss: 0.3751 - val_accuracy: 0.8438\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2079 - accuracy: 0.9589 - val_loss: 0.3814 - val_accuracy: 0.8281\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2077 - accuracy: 0.9452 - val_loss: 0.3558 - val_accuracy: 0.8750\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1913 - accuracy: 0.9726 - val_loss: 0.3716 - val_accuracy: 0.9062\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2065 - accuracy: 0.9863 - val_loss: 0.3597 - val_accuracy: 0.9062\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1781 - accuracy: 0.9863 - val_loss: 0.3403 - val_accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1744 - accuracy: 0.9589 - val_loss: 0.3571 - val_accuracy: 0.8281\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1677 - accuracy: 0.9589 - val_loss: 0.3370 - val_accuracy: 0.8594\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1496 - accuracy: 0.9589 - val_loss: 0.3291 - val_accuracy: 0.8750\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1446 - accuracy: 0.9726 - val_loss: 0.3519 - val_accuracy: 0.9062\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1684 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.8906\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1450 - accuracy: 0.9863 - val_loss: 0.3255 - val_accuracy: 0.8906\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1270 - accuracy: 0.9726 - val_loss: 0.3326 - val_accuracy: 0.8438\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1336 - accuracy: 0.9589 - val_loss: 0.3313 - val_accuracy: 0.8438\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1271 - accuracy: 0.9589 - val_loss: 0.3282 - val_accuracy: 0.8438\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1225 - accuracy: 0.9726 - val_loss: 0.3148 - val_accuracy: 0.8750\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1085 - accuracy: 0.9726 - val_loss: 0.3315 - val_accuracy: 0.9062\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1175 - accuracy: 0.9726 - val_loss: 0.3262 - val_accuracy: 0.9219\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1072 - accuracy: 0.9726 - val_loss: 0.3064 - val_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1010 - accuracy: 0.9863 - val_loss: 0.3077 - val_accuracy: 0.8594\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0944 - accuracy: 0.9863 - val_loss: 0.3096 - val_accuracy: 0.8906\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0989 - accuracy: 0.9589 - val_loss: 0.3124 - val_accuracy: 0.8906\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0953 - accuracy: 0.9589 - val_loss: 0.2981 - val_accuracy: 0.8750\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0890 - accuracy: 0.9863 - val_loss: 0.3156 - val_accuracy: 0.8594\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0960 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8906\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.9219\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0938 - accuracy: 0.9589 - val_loss: 0.2967 - val_accuracy: 0.9062\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0860 - accuracy: 0.9863 - val_loss: 0.3012 - val_accuracy: 0.8594\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0801 - accuracy: 0.9863 - val_loss: 0.2898 - val_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.8750\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.8750\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0720 - accuracy: 0.9863 - val_loss: 0.2884 - val_accuracy: 0.8906\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.8906\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9062\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9062\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9062\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0649 - accuracy: 0.9863 - val_loss: 0.2931 - val_accuracy: 0.9062\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0688 - accuracy: 0.9863 - val_loss: 0.3152 - val_accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.8594\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9062\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0743 - accuracy: 0.9863 - val_loss: 0.2916 - val_accuracy: 0.9062\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.8594\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.8281\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9062\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9219\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9062\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.8750\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.8594\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9062\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9062\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9219\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9062\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9062\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9062\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0450 - accuracy: 0.9863 - val_loss: 0.2643 - val_accuracy: 0.9062\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.8906\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.8906\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9062\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.8906\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9062\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9062\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 0.9062\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.8750\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.8750\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9062\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.8906\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9062\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9062\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.8906\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.8906\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001492BD24700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "0.890625\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train1_b)\n",
    "y_test = lb.transform(y_test1_b)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(6,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(x_train1_b, y_train, validation_data=(x_test1_b, y_test),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(x_test1_b, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = y_test.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Broadsheets (тестовая выборка)')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7971d",
   "metadata": {},
   "source": [
    "### Нейросеть: Broadsheets (основные параметры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3157037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 1.3914 - accuracy: 0.2500 - val_loss: 1.1634 - val_accuracy: 0.5405\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0300 - accuracy: 0.5833 - val_loss: 1.1020 - val_accuracy: 0.4054\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2103 - accuracy: 0.3056 - val_loss: 0.9287 - val_accuracy: 0.4054\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9863 - accuracy: 0.2500 - val_loss: 0.8648 - val_accuracy: 0.5405\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8430 - accuracy: 0.6389 - val_loss: 0.8350 - val_accuracy: 0.5405\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8479 - accuracy: 0.6389 - val_loss: 0.8337 - val_accuracy: 0.5405\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8243 - accuracy: 0.6389 - val_loss: 0.8751 - val_accuracy: 0.5405\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8132 - accuracy: 0.6389 - val_loss: 0.8662 - val_accuracy: 0.5405\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8139 - accuracy: 0.6389 - val_loss: 0.8241 - val_accuracy: 0.5405\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8218 - accuracy: 0.6667 - val_loss: 0.8350 - val_accuracy: 0.5676\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8466 - accuracy: 0.6944 - val_loss: 0.8489 - val_accuracy: 0.5405\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8220 - accuracy: 0.6389 - val_loss: 0.8888 - val_accuracy: 0.5405\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8168 - accuracy: 0.6389 - val_loss: 0.8343 - val_accuracy: 0.5405\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7988 - accuracy: 0.6389 - val_loss: 0.8208 - val_accuracy: 0.5405\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8189 - accuracy: 0.6389 - val_loss: 0.8262 - val_accuracy: 0.6486\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8374 - accuracy: 0.7500 - val_loss: 0.8590 - val_accuracy: 0.5405\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8013 - accuracy: 0.6389 - val_loss: 1.1392 - val_accuracy: 0.5405\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9905 - accuracy: 0.6389 - val_loss: 1.1710 - val_accuracy: 0.5405\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9893 - accuracy: 0.6389 - val_loss: 0.8925 - val_accuracy: 0.5405\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8027 - accuracy: 0.6389 - val_loss: 0.9162 - val_accuracy: 0.4054\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9709 - accuracy: 0.3056 - val_loss: 0.9730 - val_accuracy: 0.4054\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0821 - accuracy: 0.3056 - val_loss: 0.8459 - val_accuracy: 0.4054\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8824 - accuracy: 0.3333 - val_loss: 0.8035 - val_accuracy: 0.5405\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7713 - accuracy: 0.6389 - val_loss: 0.9313 - val_accuracy: 0.5405\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8462 - accuracy: 0.6389 - val_loss: 1.0619 - val_accuracy: 0.5405\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9197 - accuracy: 0.6389 - val_loss: 0.9116 - val_accuracy: 0.5405\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8034 - accuracy: 0.6389 - val_loss: 0.7979 - val_accuracy: 0.5676\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7966 - accuracy: 0.6667 - val_loss: 0.8927 - val_accuracy: 0.4054\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.9567 - accuracy: 0.3056 - val_loss: 0.8044 - val_accuracy: 0.7838\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8257 - accuracy: 0.8611 - val_loss: 0.8505 - val_accuracy: 0.5405\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7867 - accuracy: 0.6389 - val_loss: 0.8670 - val_accuracy: 0.5405\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7845 - accuracy: 0.6389 - val_loss: 0.8035 - val_accuracy: 0.5405\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7621 - accuracy: 0.6389 - val_loss: 0.7846 - val_accuracy: 0.5405\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7661 - accuracy: 0.6389 - val_loss: 0.7856 - val_accuracy: 0.5405\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7637 - accuracy: 0.6389 - val_loss: 0.7895 - val_accuracy: 0.5405\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7567 - accuracy: 0.6389 - val_loss: 0.7914 - val_accuracy: 0.5405\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7628 - accuracy: 0.6389 - val_loss: 0.7859 - val_accuracy: 0.5405\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7480 - accuracy: 0.6389 - val_loss: 0.7707 - val_accuracy: 0.5676\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7490 - accuracy: 0.6667 - val_loss: 0.7767 - val_accuracy: 0.6757\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7731 - accuracy: 0.7778 - val_loss: 0.7842 - val_accuracy: 0.5405\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7523 - accuracy: 0.6389 - val_loss: 0.8682 - val_accuracy: 0.5405\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7857 - accuracy: 0.6389 - val_loss: 0.9215 - val_accuracy: 0.5405\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8183 - accuracy: 0.6389 - val_loss: 0.8493 - val_accuracy: 0.5405\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7749 - accuracy: 0.6389 - val_loss: 0.7844 - val_accuracy: 0.5676\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7530 - accuracy: 0.6944 - val_loss: 0.7713 - val_accuracy: 0.5676\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7398 - accuracy: 0.6667 - val_loss: 0.7952 - val_accuracy: 0.5405\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7360 - accuracy: 0.6389 - val_loss: 0.7852 - val_accuracy: 0.5405\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7136 - accuracy: 0.6389 - val_loss: 0.7398 - val_accuracy: 0.7568\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7450 - accuracy: 0.8056 - val_loss: 0.7312 - val_accuracy: 0.6216\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6872 - accuracy: 0.7222 - val_loss: 0.9300 - val_accuracy: 0.5405\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8039 - accuracy: 0.6389 - val_loss: 1.1122 - val_accuracy: 0.5405\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9265 - accuracy: 0.6389 - val_loss: 0.8946 - val_accuracy: 0.5405\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7660 - accuracy: 0.6389 - val_loss: 0.7131 - val_accuracy: 0.6757\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7069 - accuracy: 0.7500 - val_loss: 0.7119 - val_accuracy: 0.7568\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7153 - accuracy: 0.7500 - val_loss: 0.7157 - val_accuracy: 0.5946\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6713 - accuracy: 0.6944 - val_loss: 0.7022 - val_accuracy: 0.6757\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6717 - accuracy: 0.7778 - val_loss: 0.7009 - val_accuracy: 0.6216\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6612 - accuracy: 0.6944 - val_loss: 0.7072 - val_accuracy: 0.5946\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6485 - accuracy: 0.6667 - val_loss: 0.6878 - val_accuracy: 0.6757\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6482 - accuracy: 0.7778 - val_loss: 0.6907 - val_accuracy: 0.7838\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6773 - accuracy: 0.8889 - val_loss: 0.6886 - val_accuracy: 0.7297\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6726 - accuracy: 0.8889 - val_loss: 0.6891 - val_accuracy: 0.7027\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6490 - accuracy: 0.7778 - val_loss: 0.7046 - val_accuracy: 0.5946\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6340 - accuracy: 0.6667 - val_loss: 0.7251 - val_accuracy: 0.5676\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6359 - accuracy: 0.6667 - val_loss: 0.6536 - val_accuracy: 0.7027\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5984 - accuracy: 0.8056 - val_loss: 0.7523 - val_accuracy: 0.6216\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7806 - accuracy: 0.5556 - val_loss: 0.6811 - val_accuracy: 0.7568\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6659 - accuracy: 0.8056 - val_loss: 0.7135 - val_accuracy: 0.5946\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6163 - accuracy: 0.6667 - val_loss: 0.9164 - val_accuracy: 0.5405\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7478 - accuracy: 0.6389 - val_loss: 0.7612 - val_accuracy: 0.5676\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6213 - accuracy: 0.6667 - val_loss: 0.6509 - val_accuracy: 0.7568\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6545 - accuracy: 0.8056 - val_loss: 0.7088 - val_accuracy: 0.7568\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7078 - accuracy: 0.6944 - val_loss: 0.6457 - val_accuracy: 0.6216\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6236 - accuracy: 0.7222 - val_loss: 0.6566 - val_accuracy: 0.6216\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5478 - accuracy: 0.7778 - val_loss: 0.6631 - val_accuracy: 0.7568\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6846 - accuracy: 0.6944 - val_loss: 0.6226 - val_accuracy: 0.7568\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5983 - accuracy: 0.7500 - val_loss: 0.6974 - val_accuracy: 0.5946\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5888 - accuracy: 0.6667 - val_loss: 0.7778 - val_accuracy: 0.5676\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6209 - accuracy: 0.6667 - val_loss: 0.6074 - val_accuracy: 0.6757\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5143 - accuracy: 0.7778 - val_loss: 0.5864 - val_accuracy: 0.7568\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5510 - accuracy: 0.8889 - val_loss: 0.6145 - val_accuracy: 0.7568\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5925 - accuracy: 0.7778 - val_loss: 0.5685 - val_accuracy: 0.7568\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5317 - accuracy: 0.8889 - val_loss: 0.5876 - val_accuracy: 0.7568\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5001 - accuracy: 0.8056 - val_loss: 0.5709 - val_accuracy: 0.7297\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5098 - accuracy: 0.8889 - val_loss: 0.5763 - val_accuracy: 0.7838\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5255 - accuracy: 0.9167 - val_loss: 0.5746 - val_accuracy: 0.7568\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4982 - accuracy: 0.8056 - val_loss: 0.6267 - val_accuracy: 0.6486\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5070 - accuracy: 0.7778 - val_loss: 0.5705 - val_accuracy: 0.7027\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4717 - accuracy: 0.8056 - val_loss: 0.5345 - val_accuracy: 0.7568\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4577 - accuracy: 0.8889 - val_loss: 0.5318 - val_accuracy: 0.7297\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4434 - accuracy: 0.8889 - val_loss: 0.5669 - val_accuracy: 0.7027\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4543 - accuracy: 0.7778 - val_loss: 0.5586 - val_accuracy: 0.7027\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4433 - accuracy: 0.8056 - val_loss: 0.5188 - val_accuracy: 0.7297\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4377 - accuracy: 0.8889 - val_loss: 0.5195 - val_accuracy: 0.7568\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4269 - accuracy: 0.8611 - val_loss: 0.5682 - val_accuracy: 0.7027\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4514 - accuracy: 0.7778 - val_loss: 0.5472 - val_accuracy: 0.7568\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4291 - accuracy: 0.8056 - val_loss: 0.5158 - val_accuracy: 0.7838\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4438 - accuracy: 0.8611 - val_loss: 0.5104 - val_accuracy: 0.8108\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4451 - accuracy: 0.9167 - val_loss: 0.5030 - val_accuracy: 0.7568\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4104 - accuracy: 0.8889 - val_loss: 0.5032 - val_accuracy: 0.7297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "0.7297297297297297\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(x_train2_b)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(X_scale,\n",
    "    y_train2_b, test_size=0.5, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(16,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = testY.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Broadsheets (обучающая выборка)')\n",
    "features.append('Features')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5862c319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 68ms/step - loss: 1.3400 - accuracy: 0.3425 - val_loss: 1.2694 - val_accuracy: 0.5469\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.2010 - accuracy: 0.5890 - val_loss: 1.4107 - val_accuracy: 0.5469\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.2368 - accuracy: 0.4384 - val_loss: 1.3983 - val_accuracy: 0.5469\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1697 - accuracy: 0.5890 - val_loss: 1.3150 - val_accuracy: 0.5469\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0590 - accuracy: 0.5890 - val_loss: 1.1128 - val_accuracy: 0.4531\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9869 - accuracy: 0.4521 - val_loss: 0.9955 - val_accuracy: 0.5469\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9689 - accuracy: 0.5890 - val_loss: 1.0526 - val_accuracy: 0.5469\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9463 - accuracy: 0.5890 - val_loss: 1.0404 - val_accuracy: 0.4375\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9615 - accuracy: 0.4795 - val_loss: 1.0620 - val_accuracy: 0.4375\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9277 - accuracy: 0.5342 - val_loss: 1.0352 - val_accuracy: 0.5469\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9090 - accuracy: 0.5890 - val_loss: 1.0452 - val_accuracy: 0.5469\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9115 - accuracy: 0.5616 - val_loss: 0.9925 - val_accuracy: 0.5469\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8695 - accuracy: 0.5890 - val_loss: 0.9857 - val_accuracy: 0.5469\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8635 - accuracy: 0.5890 - val_loss: 0.9589 - val_accuracy: 0.5938\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8523 - accuracy: 0.6575 - val_loss: 0.9499 - val_accuracy: 0.5938\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8499 - accuracy: 0.7123 - val_loss: 0.9433 - val_accuracy: 0.5469\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8449 - accuracy: 0.5890 - val_loss: 0.9565 - val_accuracy: 0.5469\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8457 - accuracy: 0.5890 - val_loss: 0.9580 - val_accuracy: 0.5625\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9301 - accuracy: 0.4658 - val_loss: 0.9343 - val_accuracy: 0.5781\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8750 - accuracy: 0.5753 - val_loss: 1.0096 - val_accuracy: 0.5469\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8558 - accuracy: 0.6164 - val_loss: 0.9640 - val_accuracy: 0.5469\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8689 - accuracy: 0.5616 - val_loss: 0.9361 - val_accuracy: 0.5781\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8185 - accuracy: 0.6301 - val_loss: 1.0614 - val_accuracy: 0.5469\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9104 - accuracy: 0.5890 - val_loss: 0.9369 - val_accuracy: 0.6094\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8333 - accuracy: 0.5890 - val_loss: 1.0455 - val_accuracy: 0.4531\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9134 - accuracy: 0.5068 - val_loss: 0.9164 - val_accuracy: 0.5469\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8843 - accuracy: 0.5890 - val_loss: 0.9954 - val_accuracy: 0.5469\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8589 - accuracy: 0.6164 - val_loss: 0.9132 - val_accuracy: 0.5781\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8104 - accuracy: 0.6164 - val_loss: 0.9121 - val_accuracy: 0.6094\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7898 - accuracy: 0.6438 - val_loss: 0.9637 - val_accuracy: 0.5469\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8324 - accuracy: 0.5890 - val_loss: 0.9763 - val_accuracy: 0.5469\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8077 - accuracy: 0.6575 - val_loss: 0.9354 - val_accuracy: 0.5938\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7917 - accuracy: 0.6301 - val_loss: 0.9150 - val_accuracy: 0.5781\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7810 - accuracy: 0.6301 - val_loss: 0.8883 - val_accuracy: 0.5781\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7310 - accuracy: 0.7397 - val_loss: 0.9062 - val_accuracy: 0.5781\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8119 - accuracy: 0.5890 - val_loss: 0.8664 - val_accuracy: 0.5938\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7715 - accuracy: 0.6438 - val_loss: 0.9356 - val_accuracy: 0.5469\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7518 - accuracy: 0.6301 - val_loss: 0.8718 - val_accuracy: 0.6094\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8142 - accuracy: 0.5753 - val_loss: 0.8494 - val_accuracy: 0.6719\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7089 - accuracy: 0.6986 - val_loss: 0.9232 - val_accuracy: 0.5781\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7135 - accuracy: 0.7123 - val_loss: 0.8634 - val_accuracy: 0.6250\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7382 - accuracy: 0.6164 - val_loss: 0.8858 - val_accuracy: 0.5938\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8128 - accuracy: 0.6301 - val_loss: 0.9889 - val_accuracy: 0.5469\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7344 - accuracy: 0.6986 - val_loss: 0.9092 - val_accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7820 - accuracy: 0.6027 - val_loss: 0.8028 - val_accuracy: 0.6094\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7013 - accuracy: 0.6575 - val_loss: 0.8488 - val_accuracy: 0.5938\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6997 - accuracy: 0.7123 - val_loss: 0.7835 - val_accuracy: 0.7344\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6193 - accuracy: 0.7671 - val_loss: 0.8095 - val_accuracy: 0.6719\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6427 - accuracy: 0.6986 - val_loss: 0.7663 - val_accuracy: 0.7188\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6205 - accuracy: 0.7808 - val_loss: 0.7390 - val_accuracy: 0.7656\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5594 - accuracy: 0.8082 - val_loss: 0.7863 - val_accuracy: 0.6406\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5828 - accuracy: 0.7534 - val_loss: 0.7765 - val_accuracy: 0.6875\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6395 - accuracy: 0.7671 - val_loss: 0.7115 - val_accuracy: 0.7031\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5409 - accuracy: 0.7808 - val_loss: 0.7339 - val_accuracy: 0.7031\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5396 - accuracy: 0.8082 - val_loss: 0.7512 - val_accuracy: 0.7031\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5293 - accuracy: 0.8082 - val_loss: 0.7042 - val_accuracy: 0.7344\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4912 - accuracy: 0.7945 - val_loss: 0.7616 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6293 - accuracy: 0.6849 - val_loss: 0.7354 - val_accuracy: 0.7031\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5293 - accuracy: 0.7808 - val_loss: 0.6860 - val_accuracy: 0.7344\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4953 - accuracy: 0.8219 - val_loss: 0.7403 - val_accuracy: 0.7188\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5414 - accuracy: 0.8082 - val_loss: 0.7191 - val_accuracy: 0.7031\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5149 - accuracy: 0.8082 - val_loss: 0.7012 - val_accuracy: 0.7031\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4817 - accuracy: 0.7945 - val_loss: 0.6673 - val_accuracy: 0.7188\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4686 - accuracy: 0.8082 - val_loss: 0.7270 - val_accuracy: 0.7031\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4856 - accuracy: 0.8082 - val_loss: 0.6629 - val_accuracy: 0.7344\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4689 - accuracy: 0.7945 - val_loss: 0.7665 - val_accuracy: 0.7031\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5209 - accuracy: 0.7808 - val_loss: 0.7175 - val_accuracy: 0.6875\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5413 - accuracy: 0.7808 - val_loss: 0.8090 - val_accuracy: 0.7031\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5570 - accuracy: 0.7397 - val_loss: 0.7509 - val_accuracy: 0.7188\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6115 - accuracy: 0.7123 - val_loss: 0.7256 - val_accuracy: 0.7188\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5434 - accuracy: 0.7671 - val_loss: 0.8184 - val_accuracy: 0.7188\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4801 - accuracy: 0.8082 - val_loss: 0.8389 - val_accuracy: 0.6250\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5547 - accuracy: 0.7671 - val_loss: 0.8459 - val_accuracy: 0.6719\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5425 - accuracy: 0.7260 - val_loss: 0.6694 - val_accuracy: 0.7031\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4590 - accuracy: 0.7945 - val_loss: 0.6524 - val_accuracy: 0.7188\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4594 - accuracy: 0.8219 - val_loss: 0.7619 - val_accuracy: 0.7031\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4674 - accuracy: 0.8219 - val_loss: 0.6413 - val_accuracy: 0.7344\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4099 - accuracy: 0.8356 - val_loss: 0.6961 - val_accuracy: 0.7188\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4497 - accuracy: 0.8219 - val_loss: 0.6348 - val_accuracy: 0.7031\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4076 - accuracy: 0.8082 - val_loss: 0.6293 - val_accuracy: 0.7031\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3932 - accuracy: 0.8082 - val_loss: 0.6284 - val_accuracy: 0.7344\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4033 - accuracy: 0.8082 - val_loss: 0.6658 - val_accuracy: 0.7656\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4114 - accuracy: 0.8082 - val_loss: 0.6703 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4089 - accuracy: 0.8219 - val_loss: 0.6607 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4499 - accuracy: 0.7945 - val_loss: 0.7159 - val_accuracy: 0.7188\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4220 - accuracy: 0.8356 - val_loss: 0.6637 - val_accuracy: 0.7031\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3972 - accuracy: 0.8630 - val_loss: 0.6663 - val_accuracy: 0.7031\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3934 - accuracy: 0.8356 - val_loss: 0.6377 - val_accuracy: 0.7188\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3885 - accuracy: 0.8356 - val_loss: 0.6751 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3829 - accuracy: 0.8493 - val_loss: 0.6778 - val_accuracy: 0.7656\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3817 - accuracy: 0.8630 - val_loss: 0.6247 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3974 - accuracy: 0.8219 - val_loss: 0.6517 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3880 - accuracy: 0.8356 - val_loss: 0.6498 - val_accuracy: 0.7344\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3557 - accuracy: 0.8219 - val_loss: 0.6539 - val_accuracy: 0.7344\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4621 - accuracy: 0.7808 - val_loss: 0.9142 - val_accuracy: 0.7031\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0324 - accuracy: 0.6849 - val_loss: 0.9304 - val_accuracy: 0.6875\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6788 - accuracy: 0.7123 - val_loss: 1.1844 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6883 - accuracy: 0.6849 - val_loss: 1.0351 - val_accuracy: 0.6719\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7749 - accuracy: 0.6986 - val_loss: 0.8600 - val_accuracy: 0.7031\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4609 - accuracy: 0.8356 - val_loss: 0.8864 - val_accuracy: 0.6094\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "0.609375\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train2_b)\n",
    "y_test = lb.transform(y_test2_b)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(16,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(x_train2_b, y_train, validation_data=(x_test2_b, y_test),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(x_test2_b, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = y_test.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Broadsheets (тестовая выборка)')\n",
    "features.append('Features')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a6b6f8",
   "metadata": {},
   "source": [
    "# Пайплайн"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eff1a9",
   "metadata": {},
   "source": [
    "### Пайплайн: Tabloids (Dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a066d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9365079365079365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), \n",
    "                 ('classifier', RandomForestClassifier(random_state = 42, n_estimators = 1500)),\n",
    "             ]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "print(pipe.fit(x_train1_t, y_train1_t).score(x_test1_t, y_test1_t))\n",
    "\n",
    "algorithms.append('Пайплайн')\n",
    "datasets.append('Tabloids')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(pipe.fit(x_train1_t, y_train1_t).score(x_test1_t, y_test1_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f1a02",
   "metadata": {},
   "source": [
    "### Пайплайн: Tabloids (Основные параметры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a32b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e4ed7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), \n",
    "                 ('classifier', RandomForestClassifier(random_state = 42, n_estimators = 1500)),\n",
    "             ]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "print(pipe.fit(x_train2_t, y_train2_t).score(x_test2_t, y_test2_t))\n",
    "\n",
    "algorithms.append('Пайплайн')\n",
    "datasets.append('Tabloids')\n",
    "features.append('Features')\n",
    "accuracies.append(pipe.fit(x_train2_t, y_train2_t).score(x_test2_t, y_test2_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f28e95b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     AWL  FPP1   GER     JJ     NN  NOMZ   PHC    PIN   PIT  SYNE  TIME  TOBJ  \\\n",
       " 64  4.61  0.00  0.00   7.00  28.01  1.68  1.12  11.20  1.12  0.00  1.40  0.00   \n",
       " 3   4.16  2.22  0.00  10.16  31.11  0.63  0.00  12.06  0.00  0.00  0.32  0.00   \n",
       " 17  4.51  1.87  0.75   7.12  23.97  1.87  0.19  10.11  2.25  0.37  0.75  0.19   \n",
       " 38  4.53  0.00  2.51   6.53  36.18  2.01  1.51  13.57  0.00  0.50  0.00  0.00   \n",
       " 8   4.87  0.59  1.07   9.24  26.90  3.79  0.59  10.66  0.95  0.00  1.18  0.00   \n",
       " 57  4.43  2.37  0.64   6.03  26.38  1.45  0.97  10.74  0.97  0.36  1.77  0.08   \n",
       " 6   4.89  0.00  0.64   9.13  38.85  2.12  1.06  12.53  0.21  0.00  0.21  0.00   \n",
       " 36  4.45  1.07  0.64   4.51  32.62  1.29  0.64  11.16  1.93  0.00  0.64  0.43   \n",
       " 66  4.23  2.66  0.42   5.88  21.71  3.78  0.00   9.52  2.10  0.00  1.26  0.00   \n",
       " 53  4.42  1.18  0.77   6.59  28.68  1.47  1.12  11.65  1.18  0.25  0.73  0.00   \n",
       " 70  4.09  2.53  0.42   4.21  27.37  1.26  1.05   8.21  1.26  0.21  0.63  0.21   \n",
       " 15  4.30  3.10  0.00   4.28  25.66  1.47  0.88  11.95  1.33  0.15  0.88  0.15   \n",
       " 27  4.88  0.00  0.45   8.54  33.03  2.70  2.02  11.69  1.57  0.00  1.12  0.45   \n",
       " 41  4.15  3.63  0.67   5.06  24.64  1.34  1.05   9.74  0.96  0.10  0.57  0.19   \n",
       " 26  4.47  1.39  0.00   5.54  32.96  3.88  0.28  11.91  0.00  0.00  0.55  0.00   \n",
       " 48  4.43  2.79  0.19   5.88  22.25  2.02  0.48   9.06  1.54  0.00  0.48  0.00   \n",
       " 24  4.65  1.92  0.58   5.58  30.19  1.73  0.38  11.35  0.77  0.00  1.35  0.19   \n",
       " 61  4.36  1.50  0.09   6.19  26.28  1.42  0.80   9.38  0.88  0.18  0.53  0.09   \n",
       " 65  4.43  0.00  0.00   8.70  26.00  2.35  1.08  10.85  0.10  0.10  0.49  0.10   \n",
       " 11  4.13  2.13  0.11   4.36  22.42  2.02  0.74   9.14  0.53  0.11  0.21  0.32   \n",
       " 32  4.05  1.52  0.38   5.50  29.79  2.47  1.14  13.09  0.57  0.19  0.76  0.19   \n",
       " 68  4.63  0.18  1.60   6.41  25.62  4.27  0.53  10.85  1.78  0.18  0.71  0.18   \n",
       " 63  4.79  0.84  1.12   9.52  36.13  1.12  2.52  12.61  0.00  0.00  0.00  0.00   \n",
       " 37  4.45  0.00  0.17   5.69  34.31  1.90  0.17  11.72  0.69  0.17  0.34  0.00   \n",
       " 29  4.56  0.00  0.00   8.89  28.33  2.96  0.74  12.59  0.74  0.00  0.19  0.00   \n",
       " 43  4.74  0.78  0.50   8.53  35.28  1.71  1.64  11.74  0.78  0.07  0.43  0.00   \n",
       " 67  4.54  0.62  0.11   7.89  26.58  2.73  1.02  11.30  0.85  0.62  0.68  0.23   \n",
       " 1   4.15  2.50  0.18   4.47  27.37  1.25  0.36   9.30  1.25  0.00  0.72  0.00   \n",
       " 52  4.18  2.32  0.46   7.88  22.72  3.71  1.39   8.96  0.62  0.15  1.39  0.62   \n",
       " 21  4.08  2.71  0.29   6.02  23.11  0.88  1.10   9.17  1.61  0.00  1.39  0.15   \n",
       " 2   3.91  0.42  0.63   5.04  25.00  0.63  0.21  10.50  2.31  0.00  0.21  0.21   \n",
       " 23  4.14  4.51  1.73   4.68  17.50  1.73  0.52   9.53  0.69  0.00  0.35  0.17   \n",
       " 20  3.92  5.49  0.42   4.64  21.10  0.84  0.21   8.02  1.27  0.21  0.63  0.21   \n",
       " 60  4.92  1.21  0.17  10.36  28.32  4.32  1.38  11.40  0.86  0.00  0.00  0.17   \n",
       " 14  4.47  0.00  2.01   7.02  30.08  0.75  1.75  13.78  0.25  0.00  0.25  0.25   \n",
       " 51  4.00  3.86  1.13   6.11  19.94  0.32  0.48   8.36  2.41  0.32  0.00  0.16   \n",
       " \n",
       "     TPP3  Tokens     VB   XX0  \n",
       " 64  0.84   357.0  14.57  0.56  \n",
       " 3   5.71   315.0   6.35  0.00  \n",
       " 17  3.00   534.0   9.74  0.75  \n",
       " 38  0.50   199.0   6.53  0.00  \n",
       " 8   1.30   844.0   9.48  0.12  \n",
       " 57  2.25  2487.0  13.91  0.72  \n",
       " 6   0.42   471.0   6.58  0.21  \n",
       " 36  4.08   466.0  10.30  0.43  \n",
       " 66  1.96   714.0  10.36  1.82  \n",
       " 53  1.43  4825.0  10.94  0.39  \n",
       " 70  6.32   475.0  11.16  1.26  \n",
       " 15  5.01   678.0  12.54  0.59  \n",
       " 27  1.12   445.0   8.99  0.22  \n",
       " 41  4.49  1047.0  12.61  1.43  \n",
       " 26  2.77   361.0  10.53  0.00  \n",
       " 48  4.34  1038.0  13.87  1.16  \n",
       " 24  4.04   520.0   8.46  0.38  \n",
       " 61  7.08  1130.0  11.50  0.44  \n",
       " 65  6.45  1023.0  10.75  0.00  \n",
       " 11  7.44   941.0  12.86  1.91  \n",
       " 32  6.64   527.0   8.35  0.38  \n",
       " 68  1.42   562.0  10.68  0.36  \n",
       " 63  0.00   357.0   9.52  0.28  \n",
       " 37  3.62   580.0  10.17  0.34  \n",
       " 29  0.37   540.0  11.67  0.56  \n",
       " 43  1.64  1406.0   7.61  0.50  \n",
       " 67  3.07  1761.0   9.48  0.80  \n",
       " 1   4.11   559.0  13.60  0.54  \n",
       " 52  3.09   647.0  10.97  0.46  \n",
       " 21  6.02  1363.0  10.64  0.73  \n",
       " 2   3.78   476.0  10.29  0.42  \n",
       " 23  8.49   577.0  11.61  1.21  \n",
       " 20  4.85   474.0  11.60  0.84  \n",
       " 60  0.52   579.0  10.02  0.69  \n",
       " 14  0.25   399.0  12.03  0.00  \n",
       " 51  6.43   622.0  11.58  0.32  ,\n",
       "      AWL  FPP1   GER     JJ     NN  NOMZ   PHC    PIN   PIT  SYNE  TIME  TOBJ  \\\n",
       " 4   4.47  1.13  1.58   8.13  30.02  1.35  1.35  12.87  2.26  0.00  0.45  0.68   \n",
       " 62  4.19  2.75  0.22   4.30  20.37  2.86  0.33   8.37  2.31  0.00  0.22  0.11   \n",
       " 18  4.10  2.67  0.16   5.50  25.00  0.47  0.94   8.49  5.03  0.00  0.00  0.31   \n",
       " 0   4.15  0.87  0.38   4.71  27.02  0.38  0.19  10.38  0.67  0.29  0.38  0.29   \n",
       " 28  4.47  1.77  0.10   5.90  23.40  1.87  0.79   9.83  0.88  0.00  1.08  0.49   \n",
       " 50  4.64  0.73  0.28   7.49  25.86  2.11  0.64   9.74  1.01  0.23  0.60  0.18   \n",
       " 10  4.40  0.00  0.68   7.69  26.24  0.68  0.90   9.05  0.45  0.23  0.23  0.00   \n",
       " 34  4.81  0.00  0.84  10.32  34.74  1.68  2.53   7.16  0.00  0.00  0.63  0.00   \n",
       " 12  4.44  1.68  0.37   5.42  28.22  2.43  1.12  12.90  0.93  0.00  0.19  0.00   \n",
       " 54  4.05  4.81  0.00  10.98  20.14  0.46  1.37  10.76  3.43  0.00  0.00  0.23   \n",
       " 47  4.39  2.38  0.10   7.10  25.70  1.76  1.40   9.84  1.40  0.10  0.47  0.00   \n",
       " 31  4.02  5.07  0.00   9.01  23.26  0.75  0.94  10.51  0.75  0.00  1.31  0.00   \n",
       " 9   4.65  0.95  0.38   6.43  30.43  1.70  1.13   9.07  1.70  0.19  0.95  0.19   \n",
       " 45  4.46  0.88  0.00   3.52  32.39  1.58  2.11  10.39  0.70  0.53  0.18  0.35   \n",
       " 5   4.52  1.23  0.14  10.11  27.87  2.46  0.82  11.75  1.37  0.14  0.68  0.14   \n",
       " 22  4.01  3.70  0.00   8.83  26.78  2.56  0.28  12.25  2.85  0.00  0.00  0.28   \n",
       " 56  4.21  1.31  0.00   5.91  23.48  2.30  0.49  10.67  1.48  0.00  0.99  0.49   \n",
       " 49  4.18  3.02  0.14   6.80  24.95  3.02  1.51  10.65  1.86  0.07  0.62  0.21   \n",
       " 33  4.31  2.57  0.59   7.52  31.29  0.99  0.20   9.11  0.59  0.20  0.79  0.00   \n",
       " 39  4.39  1.04  0.50   6.86  28.75  1.51  0.93  12.13  1.62  0.18  0.68  0.07   \n",
       " 59  4.51  0.97  0.49   9.00  27.49  1.70  0.97   8.27  0.97  0.00  2.43  0.49   \n",
       " 16  4.18  2.71  0.24   7.54  21.79  1.06  0.94   8.48  2.94  0.12  0.71  0.00   \n",
       " 35  4.35  1.04  0.15   8.63  25.15  0.89  0.60  11.90  1.93  0.15  0.15  0.00   \n",
       " 44  3.96  1.25  0.00   3.58  23.79  0.72  1.25  10.91  0.00  0.00  1.25  0.00   \n",
       " 69  4.37  0.00  0.56   3.63  32.68  0.56  0.00   9.22  0.84  0.56  0.56  0.56   \n",
       " 7   4.17  2.70  0.21   6.44  30.98  1.66  1.04  10.19  0.62  0.00  1.04  0.21   \n",
       " 55  4.28  0.86  1.18   6.66  29.97  0.86  1.18  13.86  1.07  0.00  0.32  0.11   \n",
       " 42  4.28  2.06  0.06   7.07  25.39  1.75  1.19  10.07  1.44  0.13  0.44  0.00   \n",
       " 30  4.33  1.42  0.24   8.53  29.86  1.18  0.95  12.32  0.95  0.24  0.95  0.00   \n",
       " 46  4.53  1.83  1.16   6.18  26.83  1.83  1.64   9.75  1.25  0.00  0.39  0.00   \n",
       " 71  4.30  2.17  0.35   5.90  26.97  1.56  0.87  11.19  1.47  0.17  0.52  0.09   \n",
       " 19  4.48  0.25  0.25  11.70  28.24  0.51  0.51   6.87  1.78  0.25  1.27  0.25   \n",
       " 58  4.73  0.00  0.81   8.53  33.69  1.35  0.81  12.99  1.62  0.00  0.68  0.14   \n",
       " 25  4.40  0.36  0.36   9.55  31.89  0.72  1.26  11.35  1.62  0.36  0.00  0.00   \n",
       " 40  4.37  1.88  0.27   6.97  30.83  1.61  1.61   9.65  1.34  0.00  0.00  0.00   \n",
       " 13  4.23  3.41  0.00   5.12  25.37  1.71  0.24   9.51  0.98  0.00  0.49  0.00   \n",
       " \n",
       "     TPP3  Tokens     VB   XX0  \n",
       " 4   2.26   443.0   7.45  0.90  \n",
       " 62  4.96   908.0  14.21  2.20  \n",
       " 18  2.20   636.0  13.36  0.47  \n",
       " 0   6.06  1040.0  14.52  0.48  \n",
       " 28  5.31  1017.0  14.95  0.49  \n",
       " 50  5.51  2177.0  10.52  0.37  \n",
       " 10  6.33   442.0  11.54  0.90  \n",
       " 34  1.89   475.0  10.95  0.21  \n",
       " 12  2.06   535.0  10.84  0.37  \n",
       " 54  0.69   437.0   9.84  2.06  \n",
       " 47  2.28  1930.0  10.73  1.19  \n",
       " 31  3.00   533.0   8.63  0.75  \n",
       " 9   2.27   529.0   9.45  0.57  \n",
       " 45  4.40   568.0  10.39  0.53  \n",
       " 5   0.68   732.0  10.52  0.41  \n",
       " 22  1.99   351.0   7.69  0.00  \n",
       " 56  9.20   609.0   8.21  0.16  \n",
       " 49  2.96  1455.0  10.45  0.41  \n",
       " 33  5.94   505.0   7.72  0.40  \n",
       " 39  1.69  2786.0  10.19  0.47  \n",
       " 59  1.70   411.0   7.06  0.97  \n",
       " 16  2.00   849.0  10.60  1.18  \n",
       " 35  0.30   672.0  11.16  1.34  \n",
       " 44  5.72   559.0  13.77  1.07  \n",
       " 69  6.98   358.0  11.73  0.84  \n",
       " 7   2.29   481.0   7.07  0.42  \n",
       " 55  0.43   931.0  10.74  0.00  \n",
       " 42  2.38  1599.0  10.82  1.13  \n",
       " 30  5.21   422.0   9.72  0.47  \n",
       " 46  5.98  1036.0   8.30  0.58  \n",
       " 71  5.29  1153.0   9.19  0.95  \n",
       " 19  1.02   393.0  11.70  1.78  \n",
       " 58  0.95   739.0   6.90  0.00  \n",
       " 25  0.36   555.0   8.11  0.72  \n",
       " 40  0.80   373.0   8.58  0.00  \n",
       " 13  5.37   410.0  10.49  0.73  ]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(x_train2_t, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ee368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c078db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c96443a1",
   "metadata": {},
   "source": [
    "### Пайплайн: Broadsheets (Dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69b19645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), \n",
    "                 ('classifier', RandomForestClassifier(random_state = 42, n_estimators = 1500)),\n",
    "             ]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "print(pipe.fit(x_train1_b, y_train1_b).score(x_test1_b, y_test1_b))\n",
    "\n",
    "algorithms.append('Пайплайн')\n",
    "datasets.append('Broadsheets')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(pipe.fit(x_train1_b, y_train1_b).score(x_test1_b, y_test1_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295236ec",
   "metadata": {},
   "source": [
    "### Пайплайн: Broadsheets (основные параметры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8812cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), \n",
    "                 ('classifier', RandomForestClassifier(random_state = 42, n_estimators = 1500)),\n",
    "             ]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "print(pipe.fit(x_train2_b, y_train2_b).score(x_test2_b, y_test2_b))\n",
    "\n",
    "algorithms.append('Пайплайн')\n",
    "datasets.append('Broadsheets')\n",
    "features.append('Features')\n",
    "accuracies.append(pipe.fit(x_train2_b, y_train2_b).score(x_test2_b, y_test2_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da94bbd",
   "metadata": {},
   "source": [
    "### Таблица сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2d68ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame()\n",
    "comparison['Алгоритм'] = algorithms\n",
    "comparison['Датасет'] = datasets\n",
    "comparison['Параметры'] = features\n",
    "comparison['Точность'] = accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e4a8363",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Алгоритм</th>\n",
       "      <th>Датасет</th>\n",
       "      <th>Параметры</th>\n",
       "      <th>Точность</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Tabloids (обучающая выборка)</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Tabloids (обучающая выборка)</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Tabloids (тестовая выборка)</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Tabloids (тестовая выборка)</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Broadsheets (обучающая выборка)</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Broadsheets (тестовая выборка)</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Broadsheets (обучающая выборка)</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.729730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Broadsheets (тестовая выборка)</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Пайплайн</td>\n",
       "      <td>Tabloids</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.936508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Пайплайн</td>\n",
       "      <td>Tabloids</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Пайплайн</td>\n",
       "      <td>Broadsheets</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Пайплайн</td>\n",
       "      <td>Broadsheets</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Алгоритм                          Датасет   Параметры  Точность\n",
       "0   Нейросеть     Tabloids (обучающая выборка)  Dimensions  0.666667\n",
       "1   Нейросеть     Tabloids (обучающая выборка)    Features  0.750000\n",
       "2   Нейросеть      Tabloids (тестовая выборка)  Dimensions  0.952381\n",
       "3   Нейросеть      Tabloids (тестовая выборка)    Features  0.761905\n",
       "4   Нейросеть  Broadsheets (обучающая выборка)  Dimensions  0.540541\n",
       "5   Нейросеть   Broadsheets (тестовая выборка)  Dimensions  0.890625\n",
       "6   Нейросеть  Broadsheets (обучающая выборка)    Features  0.729730\n",
       "7   Нейросеть   Broadsheets (тестовая выборка)    Features  0.609375\n",
       "8    Пайплайн                         Tabloids  Dimensions  0.936508\n",
       "9    Пайплайн                         Tabloids    Features  0.777778\n",
       "10   Пайплайн                      Broadsheets  Dimensions  0.843750\n",
       "11   Пайплайн                      Broadsheets    Features  0.734375"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb79a2",
   "metadata": {},
   "source": [
    "### Можно сделать следующие выводы:\n",
    "* Нейросеть даёт высокую точность как на Tabloids, так и на Broadsheets, и в целом справляется с этой задачей лучше, чем пайплайн.\n",
    "* Пайплайн лучше обрабатывает датасеты Tabloids, чем Broadsheets, и при этом даёт более высокий результат на параметрах Dimensions. То же самое можно сказать и о нейросети.\n",
    "* При обработке датасетов через нейросеть можно проследить одну особенность: обработка Tabloids через Dimensions на обучающей выборке даёт меньшую точность, чем при обработке тестовой выборки, однако при обработке тех же данных через Features даёт совершенно противоположную картину: точность на обучающей выборке получилась выше, чем на тестовой. Это можно объяснить тем, что в одной выборке могут быть типы текстов по Байберу, которых нет в другой. Также есть вероятность, что большое количество документов и характеристик по ним может значительно повлиять на качество работы модели, если прослеживается преобладание какого-то одного типа текстов, установленных Байбером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328fbee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
