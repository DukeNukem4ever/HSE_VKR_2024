{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664b8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Artem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5c5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_tabloids = pd.read_csv(\"Dimensions_texts_Tabloids.csv\")\n",
    "df2_tabloids = pd.read_csv(\"Statistics_texts_Tabloids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db85e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_broadsheets = pd.read_csv(\"Dimensions_texts_Broadsheets.csv\")\n",
    "df2_broadsheets = pd.read_csv(\"Statistics_texts_Broadsheets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e510d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Dimension1', 'Dimension2', 'Dimension3', 'Dimension4',\n",
       "       'Dimension5', 'Dimension6', 'Closest Text Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_tabloids.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6715c2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Tokens', 'AWL', 'TTR', '#', '$', '''', ':', 'AMP', 'ANDC',\n",
       "       'CAUS', 'CC', 'CD', 'CONC', 'COND', 'CONJ', 'DEMO', 'DEMP', 'DPAR',\n",
       "       'DT', 'DWNT', 'EMPH', 'EX', 'FPP1', 'FW', 'GER', 'HDG', 'IN', 'INPR',\n",
       "       'JJ', 'NEMD', 'NN', 'NOMZ', 'OSUB', 'PDT', 'PHC', 'PIN', 'PIT', 'PLACE',\n",
       "       'POMD', 'POS', 'PRED', 'PRMD', 'PRP', 'QUAN', 'QUPR', 'RB', 'RP',\n",
       "       'SPP2', 'SYM', 'SYNE', 'THAC', 'THVC', 'TIME', 'TO', 'TOBJ', 'TPP3',\n",
       "       'TSUB', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VPRT', 'WDT', 'WP', 'WPS',\n",
       "       'XX0', '[BEMA]', '[BYPA]', '[PASS]', '[PASTP]', '[PEAS]', '[PIRE]',\n",
       "       '[PRIV]', '[PROD]', '[PUBV]', '[SERE]', '[SMP]', '[SPAU]', '[SPIN]',\n",
       "       '[SUAV]', '[THATD]', '[WHCL]', '[WHOBJ]', '[WHQU]', '[WHSUB]',\n",
       "       '[WZPAST]', '[WZPRES]', '``', 'Unnamed: 90'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_broadsheets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce94fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_broadsheets = df2_broadsheets.drop(columns = ['Unnamed: 90'])\n",
    "df2_tabloids = df2_tabloids.drop(columns = ['Unnamed: 89'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c6b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tabloids = df1_tabloids['Closest Text Type']\n",
    "y_broadsheets = df1_broadsheets['Closest Text Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03102446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Dimension1</th>\n",
       "      <th>Dimension2</th>\n",
       "      <th>Dimension3</th>\n",
       "      <th>Dimension4</th>\n",
       "      <th>Dimension5</th>\n",
       "      <th>Dimension6</th>\n",
       "      <th>Closest Text Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text_0</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>4.07</td>\n",
       "      <td>7.59</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text_100</td>\n",
       "      <td>-18.97</td>\n",
       "      <td>-5.83</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>0.84</td>\n",
       "      <td>Learned exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text_101</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.91</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>1.70</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text_102</td>\n",
       "      <td>-18.69</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>5.77</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>Learned exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text_103</td>\n",
       "      <td>-15.85</td>\n",
       "      <td>-3.88</td>\n",
       "      <td>1.94</td>\n",
       "      <td>6.77</td>\n",
       "      <td>5.34</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>Scientific exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>text_97</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.48</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>text_98</td>\n",
       "      <td>-13.76</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-3.81</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>text_99</td>\n",
       "      <td>-4.28</td>\n",
       "      <td>4.06</td>\n",
       "      <td>6.07</td>\n",
       "      <td>-1.87</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>text_9</td>\n",
       "      <td>-14.07</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>6.47</td>\n",
       "      <td>6.77</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>texts</td>\n",
       "      <td>-13.60</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>4.76</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>Learned exposition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename  Dimension1  Dimension2  Dimension3  Dimension4  Dimension5  \\\n",
       "0      text_0       -3.75        4.07        7.59       -2.18       -1.74   \n",
       "1    text_100      -18.97       -5.83        0.30       -1.45       -1.95   \n",
       "2    text_101       -2.72       -0.20        1.91       -3.49        1.70   \n",
       "3    text_102      -18.69       -5.26        5.77       -4.90       -0.96   \n",
       "4    text_103      -15.85       -3.88        1.94        6.77        5.34   \n",
       "..        ...         ...         ...         ...         ...         ...   \n",
       "132   text_97      -11.01       -2.96        4.25        1.60       -0.63   \n",
       "133   text_98      -13.76       -2.60        0.69       -3.81        2.51   \n",
       "134   text_99       -4.28        4.06        6.07       -1.87        3.20   \n",
       "135    text_9      -14.07       -1.63        6.47        6.77       -1.32   \n",
       "136     texts      -13.60       -2.96        4.76       -0.88       -1.03   \n",
       "\n",
       "     Dimension6             Closest Text Type  \n",
       "0         -0.41  General narrative exposition  \n",
       "1          0.84            Learned exposition  \n",
       "2         -1.05  General narrative exposition  \n",
       "3         -1.24            Learned exposition  \n",
       "4         -2.12         Scientific exposition  \n",
       "..          ...                           ...  \n",
       "132        0.48  General narrative exposition  \n",
       "133        0.00  General narrative exposition  \n",
       "134        0.73  General narrative exposition  \n",
       "135       -0.39  General narrative exposition  \n",
       "136       -1.00            Learned exposition  \n",
       "\n",
       "[137 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_broadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2363097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tabloids['Closest Text Type'] = df1_tabloids['Closest Text Type']\n",
    "df2_broadsheets['Closest Text Type'] = df1_broadsheets['Closest Text Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd432ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bads = []\n",
    "\n",
    "for l in list(df2_tabloids.columns):\n",
    "    if re.findall('[a-zA-Z]', l) == []:\n",
    "        bads.append(l)\n",
    "\n",
    "for l in list(df2_broadsheets.columns):\n",
    "    if re.findall('[a-zA-Z]', l) == []:\n",
    "        bads.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e88d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RRB-\n"
     ]
    }
   ],
   "source": [
    "for l in list(df2_tabloids.columns):\n",
    "    if l not in df2_broadsheets:\n",
    "        print(l)\n",
    "\n",
    "df2_tabloids = df2_tabloids.drop([\"-RRB-\", '#', '$', \"''\", ':'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70123ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "$\n",
      "''\n",
      ":\n",
      "DPAR\n",
      "``\n"
     ]
    }
   ],
   "source": [
    "for l in list(df2_broadsheets.columns):\n",
    "    if l not in df2_tabloids:\n",
    "        print(l)\n",
    "\n",
    "df2_broadsheets = df2_broadsheets.drop([\"DPAR\", \"``\", '#', '$', \"''\", ':'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df872025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Tokens', 'AWL', 'TTR', 'AMP', 'ANDC', 'CAUS', 'CC', 'CD',\n",
       "       'CONC', 'COND', 'CONJ', 'DEMO', 'DEMP', 'DT', 'DWNT', 'EMPH', 'EX',\n",
       "       'FPP1', 'FW', 'GER', 'HDG', 'IN', 'INPR', 'JJ', 'NEMD', 'NN', 'NOMZ',\n",
       "       'OSUB', 'PDT', 'PHC', 'PIN', 'PIT', 'PLACE', 'POMD', 'POS', 'PRED',\n",
       "       'PRMD', 'PRP', 'QUAN', 'QUPR', 'RB', 'RP', 'SPP2', 'SYM', 'SYNE',\n",
       "       'THAC', 'THVC', 'TIME', 'TO', 'TOBJ', 'TPP3', 'TSUB', 'UH', 'VB', 'VBD',\n",
       "       'VBG', 'VBN', 'VPRT', 'WDT', 'WP', 'WPS', 'XX0', '[BEMA]', '[BYPA]',\n",
       "       '[PASS]', '[PASTP]', '[PEAS]', '[PIRE]', '[PRIV]', '[PROD]', '[PUBV]',\n",
       "       '[SERE]', '[SMP]', '[SPAU]', '[SPIN]', '[SUAV]', '[THATD]', '[WHCL]',\n",
       "       '[WHOBJ]', '[WHQU]', '[WHSUB]', '[WZPAST]', '[WZPRES]',\n",
       "       'Closest Text Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_tabloids.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a15e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Tokens', 'AWL', 'TTR', 'AMP', 'ANDC', 'CAUS', 'CC', 'CD',\n",
       "       'CONC', 'COND', 'CONJ', 'DEMO', 'DEMP', 'DT', 'DWNT', 'EMPH', 'EX',\n",
       "       'FPP1', 'FW', 'GER', 'HDG', 'IN', 'INPR', 'JJ', 'NEMD', 'NN', 'NOMZ',\n",
       "       'OSUB', 'PDT', 'PHC', 'PIN', 'PIT', 'PLACE', 'POMD', 'POS', 'PRED',\n",
       "       'PRMD', 'PRP', 'QUAN', 'QUPR', 'RB', 'RP', 'SPP2', 'SYM', 'SYNE',\n",
       "       'THAC', 'THVC', 'TIME', 'TO', 'TOBJ', 'TPP3', 'TSUB', 'UH', 'VB', 'VBD',\n",
       "       'VBG', 'VBN', 'VPRT', 'WDT', 'WP', 'WPS', 'XX0', '[BEMA]', '[BYPA]',\n",
       "       '[PASS]', '[PASTP]', '[PEAS]', '[PIRE]', '[PRIV]', '[PROD]', '[PUBV]',\n",
       "       '[SERE]', '[SMP]', '[SPAU]', '[SPIN]', '[SUAV]', '[THATD]', '[WHCL]',\n",
       "       '[WHOBJ]', '[WHQU]', '[WHSUB]', '[WZPAST]', '[WZPRES]',\n",
       "       'Closest Text Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_broadsheets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0dc81a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>AWL</th>\n",
       "      <th>TTR</th>\n",
       "      <th>AMP</th>\n",
       "      <th>ANDC</th>\n",
       "      <th>CAUS</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>CONC</th>\n",
       "      <th>...</th>\n",
       "      <th>[SPIN]</th>\n",
       "      <th>[SUAV]</th>\n",
       "      <th>[THATD]</th>\n",
       "      <th>[WHCL]</th>\n",
       "      <th>[WHOBJ]</th>\n",
       "      <th>[WHQU]</th>\n",
       "      <th>[WHSUB]</th>\n",
       "      <th>[WZPAST]</th>\n",
       "      <th>[WZPRES]</th>\n",
       "      <th>Closest Text Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text_0</td>\n",
       "      <td>1040.00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>169.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text_100</td>\n",
       "      <td>559.00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>203.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Involved persuasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text_101</td>\n",
       "      <td>476.00</td>\n",
       "      <td>3.91</td>\n",
       "      <td>174.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text_102</td>\n",
       "      <td>315.00</td>\n",
       "      <td>4.16</td>\n",
       "      <td>165.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text_103</td>\n",
       "      <td>443.00</td>\n",
       "      <td>4.47</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>text_97</td>\n",
       "      <td>1090.00</td>\n",
       "      <td>4.36</td>\n",
       "      <td>194.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>text_98</td>\n",
       "      <td>428.00</td>\n",
       "      <td>4.44</td>\n",
       "      <td>211.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>text_99</td>\n",
       "      <td>508.00</td>\n",
       "      <td>4.84</td>\n",
       "      <td>174.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Learned exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>text_9</td>\n",
       "      <td>329.00</td>\n",
       "      <td>4.56</td>\n",
       "      <td>165.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Learned exposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>texts</td>\n",
       "      <td>725.04</td>\n",
       "      <td>4.37</td>\n",
       "      <td>184.45</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>General narrative exposition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename   Tokens   AWL     TTR   AMP  ANDC  CAUS    CC    CD  CONC  ...  \\\n",
       "0      text_0  1040.00  4.15  169.00  0.29  0.10  0.00  2.02  1.25  0.00  ...   \n",
       "1    text_100   559.00  4.15  203.00  0.36  0.00  0.00  2.15  0.00  0.00  ...   \n",
       "2    text_101   476.00  3.91  174.00  0.00  0.00  0.00  2.73  1.26  0.00  ...   \n",
       "3    text_102   315.00  4.16  165.00  0.32  0.00  0.00  1.59  1.27  0.00  ...   \n",
       "4    text_103   443.00  4.47  181.00  0.23  0.00  0.23  1.35  1.13  0.00  ...   \n",
       "..        ...      ...   ...     ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "130   text_97  1090.00  4.36  194.00  0.00  0.09  0.00  2.39  1.01  0.00  ...   \n",
       "131   text_98   428.00  4.44  211.00  0.00  0.00  0.00  1.87  0.93  0.00  ...   \n",
       "132   text_99   508.00  4.84  174.00  0.00  0.00  0.00  1.38  1.77  0.00  ...   \n",
       "133    text_9   329.00  4.56  165.00  0.00  0.00  0.00  2.13  0.30  0.00  ...   \n",
       "134     texts   725.04  4.37  184.45  0.15  0.06  0.11  2.24  0.84  0.04  ...   \n",
       "\n",
       "     [SPIN]  [SUAV]  [THATD]  [WHCL]  [WHOBJ]  [WHQU]  [WHSUB]  [WZPAST]  \\\n",
       "0      0.00    0.10     0.87    0.00     0.19     0.0     0.77      0.19   \n",
       "1      0.00    0.36     1.07    0.36     0.18     0.0     0.00      0.00   \n",
       "2      0.00    0.21     0.63    0.42     0.21     0.0     0.21      0.21   \n",
       "3      0.00    0.00     2.22    0.00     0.00     0.0     0.63      0.00   \n",
       "4      0.00    0.23     1.13    0.00     0.23     0.0     0.00      0.00   \n",
       "..      ...     ...      ...     ...      ...     ...      ...       ...   \n",
       "130    0.09    0.64     1.56    0.09     0.09     0.0     0.28      0.00   \n",
       "131    0.00    0.00     0.93    0.00     0.00     0.0     0.93      0.00   \n",
       "132    0.00    0.39     0.79    0.20     0.00     0.0     0.39      0.00   \n",
       "133    0.00    0.00     0.00    0.00     0.00     0.0     0.00      0.00   \n",
       "134    0.02    0.32     0.81    0.10     0.05     0.0     0.41      0.04   \n",
       "\n",
       "     [WZPRES]             Closest Text Type  \n",
       "0        0.00  General narrative exposition  \n",
       "1        0.00           Involved persuasion  \n",
       "2        0.21  General narrative exposition  \n",
       "3        0.00  General narrative exposition  \n",
       "4        0.23  General narrative exposition  \n",
       "..        ...                           ...  \n",
       "130      0.00  General narrative exposition  \n",
       "131      0.00  General narrative exposition  \n",
       "132      0.00            Learned exposition  \n",
       "133      0.00            Learned exposition  \n",
       "134      0.07  General narrative exposition  \n",
       "\n",
       "[135 rows x 85 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_tabloids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72eef782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_broadsheets = df1_broadsheets.drop(['Filename'],axis=1)\n",
    "df1_tabloids = df1_tabloids.drop(['Filename'],axis=1)\n",
    "df2_broadsheets = df2_broadsheets.drop(['Filename'],axis=1)\n",
    "df2_tabloids = df2_tabloids.drop(['Filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b9e7c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['General narrative exposition', 'Learned exposition',\n",
       "       'Scientific exposition', 'Involved persuasion'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_broadsheets['Closest Text Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa5c0071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['General narrative exposition', 'Involved persuasion',\n",
       "       'Learned exposition', 'Scientific exposition'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_tabloids['Closest Text Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a250c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_br_types = []\n",
    "\n",
    "for d in df1_broadsheets['Closest Text Type']:\n",
    "    if d == 'General narrative exposition':\n",
    "        df1_br_types.append(0)\n",
    "    elif d == 'Imaginative narrative':\n",
    "        df1_br_types.append(1)\n",
    "    elif d == 'Informational interaction':\n",
    "        df1_br_types.append(2)\n",
    "    elif d == 'Involved persuasion':\n",
    "        df1_br_types.append(3)\n",
    "    elif d == 'Learned exposition':\n",
    "        df1_br_types.append(4)\n",
    "    elif d == 'Scientific exposition':\n",
    "        df1_br_types.append(5)\n",
    "    else:\n",
    "        df1_br_types.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a8b4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_tabl_types = []\n",
    "\n",
    "for d in df1_tabloids['Closest Text Type']:\n",
    "    if d == 'General narrative exposition':\n",
    "        df1_tabl_types.append(0)\n",
    "    elif d == 'Imaginative narrative':\n",
    "        df1_tabl_types.append(1)\n",
    "    elif d == 'Informational interaction':\n",
    "        df1_tabl_types.append(2)\n",
    "    elif d == 'Involved persuasion':\n",
    "        df1_tabl_types.append(3)\n",
    "    elif d == 'Learned exposition':\n",
    "        df1_tabl_types.append(4)\n",
    "    elif d == 'Scientific exposition':\n",
    "        df1_tabl_types.append(5)\n",
    "    else:\n",
    "        df1_tabl_types.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f357e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_br_types = []\n",
    "\n",
    "for d in df2_broadsheets['Closest Text Type']:\n",
    "    if d == 'General narrative exposition':\n",
    "        df2_br_types.append(0)\n",
    "    elif d == 'Imaginative narrative':\n",
    "        df2_br_types.append(1)\n",
    "    elif d == 'Informational interaction':\n",
    "        df2_br_types.append(2)\n",
    "    elif d == 'Involved persuasion':\n",
    "        df2_br_types.append(3)\n",
    "    elif d == 'Learned exposition':\n",
    "        df2_br_types.append(4)\n",
    "    elif d == 'Scientific exposition':\n",
    "        df2_br_types.append(5)\n",
    "    else:\n",
    "        df2_br_types.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a7379c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tabl_types = []\n",
    "\n",
    "for d in df2_tabloids['Closest Text Type']:\n",
    "    if d == 'General narrative exposition':\n",
    "        df2_tabl_types.append(0)\n",
    "    elif d == 'Imaginative narrative':\n",
    "        df2_tabl_types.append(1)\n",
    "    elif d == 'Informational interaction':\n",
    "        df2_tabl_types.append(2)\n",
    "    elif d == 'Involved persuasion':\n",
    "        df2_tabl_types.append(3)\n",
    "    elif d == 'Learned exposition':\n",
    "        df2_tabl_types.append(4)\n",
    "    elif d == 'Scientific exposition':\n",
    "        df2_tabl_types.append(5)\n",
    "    else:\n",
    "        df2_tabl_types.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdee873f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_tabloids['Closest_Text_Type'] = df1_tabl_types\n",
    "df2_tabloids['Closest_Text_Type'] = df2_tabl_types\n",
    "df1_broadsheets['Closest_Text_Type'] = df1_br_types\n",
    "df2_broadsheets['Closest_Text_Type'] = df2_br_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7315fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_broadsheets = df1_broadsheets.drop(['Closest Text Type'],axis=1)\n",
    "df1_tabloids = df1_tabloids.drop(['Closest Text Type'],axis=1)\n",
    "df2_broadsheets = df2_broadsheets.drop(['Closest Text Type'],axis=1)\n",
    "df2_tabloids = df2_tabloids.drop(['Closest Text Type'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7d008",
   "metadata": {},
   "source": [
    "## Features (количественные характеристики): \n",
    "\n",
    "* Tokens – количество токенов.\n",
    "* AWL – средняя длина слова.\n",
    "* TTR – количество тренировочных токенов (400).\n",
    "* AMP – наличие слов-усилителей.\n",
    "* ANDC – управление независимой клаузой.\n",
    "* CAUS – наличие обстоятельств причины по типу «because».\n",
    "* CC – ???.\n",
    "* CD – кардинальное число (элементы множества).\n",
    "* CONC – концессионная обусловленность (наличие слов типа «although», «though» и т.п.)\n",
    "* COND – слова состояния, условности (наличие слов типа «if», «unless» и т.п.)\n",
    "* CONJ – слова-союзы.\n",
    "* DEMO – указательные местоимения, которые не подходят ни к одному из следующих тэгов: DEMP, TOBJ, TSUB, THAC или THVC.\n",
    "* DEMP – указательное местоимение.\n",
    "* DT – слово-определитель.\n",
    "* DWNT – слова, обозначающие незавершённость действия («almost», «hardly», «somewhat», «» и многие другие).\n",
    "* EMPH – слова с эмоциональным оттенком («really», «just», «for sure» и т.п.)\n",
    "* EX – слова с указанием существования чего-либо («there»).\n",
    "* FPP1 – местоимения первого лица («I», «we», «our», «my», «ourselves», «us», «me», «myself»).\n",
    "* FW – ???.\n",
    "* GER – герундий (глаголы с «-ing» на конце).\n",
    "* HDG – показатели неопределённости («more or less», «maybe», «something like» и т.п.)\n",
    "* IN – подчинительные союзы.\n",
    "* INPR – местоимения без точного указания на конкретное лицо («everyone», «anyone», «someone», «something» и т.п.)\n",
    "* JJ – прилагательные.\n",
    "* NEMD – глаголы обязательства («ought», «should», «must»).\n",
    "* NN – существительные.\n",
    "* NOMZ – отглагольные существительные («-tion», «-ness», «-ment» и т.п).\n",
    "* OSUB – слова по типу «since», «while», «whilst», «whereupon», «whereas», «whereby», «such that», «so that».\n",
    "* PDT – слова, стоящие перед определением.\n",
    "* PHC – союз «и».\n",
    "* PIN – предлоги.\n",
    "* PIT – местоимение «it».\n",
    "* PLACE – указатели места («above», «below», «», «» и т.п.).\n",
    "* POMD – модальные глаголы возможности («can», «may», «might», «could»).\n",
    "* PRED – предикативное прилагательное.\n",
    "* PRMD – глаголы с указанием на будущее время («will», «shall», «would»).\n",
    "* PRP – личное местоимение.\n",
    "* QUAN – числительное.\n",
    "* QUPR – числительное местоимение.\n",
    "* RB – наречие.\n",
    "* RP – ???.\n",
    "* SPP2 – местоимения в форме второго лица («you», «your», «yourself», «yourselves», «thy», «thee», «thyself», «thou»).\n",
    "* SYM – ???.\n",
    "* SYNE – конструкции «no» + прилагательное.\n",
    "* THAC – конструкции «that» + прилагательное.\n",
    "* THVC – конструкции «that» + глагол.\n",
    "* TIME – времени («afterwards», «again», «earlier», «early» и другие).\n",
    "* TO – инфинитивы, которые следуют после слова «to».\n",
    "* TOBJ – конструкции по типу «that» + подлежащее + сказуемое; применяется в отношении объекта предложения.\n",
    "* TPP3 – местоимения в форме третьего лица («she», «he», «they», «her», «him», «them», «his», «their», «himself», «herself», «themselves»).\n",
    "* TSUB – конструкции по типу «that» + подлежащее + сказуемое; применяется в отношении субъекта предложения.\n",
    "* UH – ???.\n",
    "* VB – глаголы.\n",
    "* VBD – глаголы в форме прошедшего времени.\n",
    "* VBG – глаголы с формой Present Continuous с «-ing» на конце.\n",
    "* VBN – глаголы с формой Past Continuous с «-ing» на конце.\n",
    "* VPRT – глаголы с формой Present Simple.\n",
    "* WDT – ???.\n",
    "* WP – местоимения, начинающиеся на «wh-».\n",
    "* WPS – местоимения, начинающиеся на «wh-» и имеющие посессивный характер.\n",
    "* XX0 – отрицания; слова «not» и «n’t».\n",
    "* [BEMA] – глагольная фраза с «be».\n",
    "* [BYPA] – фразы в пассивном залоге с «by».\n",
    "* [PASS] – фразы в пассивном залоге без пациенса.\n",
    "* [PEAS] – фразы в перфекте («have» + глагол).\n",
    "* [PIRE] – предикаты сложноподчинённого предложения со словами «who», «whose» или «which»; причём эти слова обозначают субъект из основной части предложения.\n",
    "* [PRIV] – список глаголов по Quirk et al. (1985: 1181–2): «feel», «recall», «accept», «assume», «prove», «believe», «remember», «calculate» и т.п., в т.ч. их словоформы.\n",
    "* [PROD] – использования слова «do» в качестве самостоятельного глагола.\n",
    "* [PUBV] – глаголы по типу «announce», «certify», «say», «write» и т.п.\n",
    "* [SMP] – глаголы «seem» и «appear».\n",
    "* [SPAU] – конструкции типа «вспомогательный глагол + минимум одно наречие + базовая форма глагола».\n",
    "* [SPIN] – конструкции типа «to + минимум одно наречие + базовая форма глагола».\n",
    "* [SUAV] – список глаголов убеждения по Quirk et al. (1985: 1182–3): «ensure», «insist», «order», «propose», «request», «suggest» и т.п.\n",
    "* [THATD] – подчинительные клаузы без «that».\n",
    "* [WHCL] – клаузы с вопросительными словами на «wh-», после которых следует слово, не являющееся вспомогательной частью речи.\n",
    "* [WHOBJ] – определённые придаточные предложения, имеющие вопросительные слова на «wh-» в качестве объекта.\n",
    "* [WHSUB] – определённые придаточные предложения, имеющие вопросительные слова на «wh-» в качестве субъекта.\n",
    "* [WZPAST] – фразы по типу «The solution produced by this process»\n",
    "* [WZPRES] – фразы по типу «the event causing this decline is…»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4b1d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "feature = []\n",
    "score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47e3392e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tokens', 'AWL', 'TTR', 'AMP', 'ANDC', 'CAUS', 'CC', 'CD', 'CONC',\n",
       "       'COND', 'CONJ', 'DEMO', 'DEMP', 'DT', 'DWNT', 'EMPH', 'EX', 'FPP1',\n",
       "       'FW', 'GER', 'HDG', 'IN', 'INPR', 'JJ', 'NEMD', 'NN', 'NOMZ', 'OSUB',\n",
       "       'PDT', 'PHC', 'PIN', 'PIT', 'PLACE', 'POMD', 'POS', 'PRED', 'PRMD',\n",
       "       'PRP', 'QUAN', 'QUPR', 'RB', 'RP', 'SPP2', 'SYM', 'SYNE', 'THAC',\n",
       "       'THVC', 'TIME', 'TO', 'TOBJ', 'TPP3', 'TSUB', 'UH', 'VB', 'VBD', 'VBG',\n",
       "       'VBN', 'VPRT', 'WDT', 'WP', 'WPS', 'XX0', '[BEMA]', '[BYPA]', '[PASS]',\n",
       "       '[PASTP]', '[PEAS]', '[PIRE]', '[PRIV]', '[PROD]', '[PUBV]', '[SERE]',\n",
       "       '[SMP]', '[SPAU]', '[SPIN]', '[SUAV]', '[THATD]', '[WHCL]', '[WHOBJ]',\n",
       "       '[WHQU]', '[WHSUB]', '[WZPAST]', '[WZPRES]', 'Closest_Text_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_broadsheets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb357cad",
   "metadata": {},
   "source": [
    "### Корреляция по broadsheets (dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0aad8e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметр</th>\n",
       "      <th>Корреляция</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dimension1</td>\n",
       "      <td>-0.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dimension2</td>\n",
       "      <td>-0.410130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dimension4</td>\n",
       "      <td>-0.173493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dimension6</td>\n",
       "      <td>-0.030158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dimension5</td>\n",
       "      <td>0.015463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dimension3</td>\n",
       "      <td>0.332876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Параметр  Корреляция\n",
       "0  Dimension1   -0.515000\n",
       "1  Dimension2   -0.410130\n",
       "2  Dimension4   -0.173493\n",
       "3  Dimension6   -0.030158\n",
       "4  Dimension5    0.015463\n",
       "5  Dimension3    0.332876"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df1_broadsheets.corr()['Closest_Text_Type'][df1_broadsheets.corr()['Closest_Text_Type'] != 1].sort_values(ascending=True)\n",
    "feature = correl.index\n",
    "score = correl.values\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Параметр'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b210dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметр</th>\n",
       "      <th>Корреляция</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dimension3</td>\n",
       "      <td>0.332876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dimension5</td>\n",
       "      <td>0.015463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dimension6</td>\n",
       "      <td>-0.030158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dimension4</td>\n",
       "      <td>-0.173493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dimension2</td>\n",
       "      <td>-0.410130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Параметр  Корреляция\n",
       "0  Dimension3    0.332876\n",
       "1  Dimension5    0.015463\n",
       "2  Dimension6   -0.030158\n",
       "3  Dimension4   -0.173493\n",
       "4  Dimension2   -0.410130"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df1_broadsheets.corr()['Closest_Text_Type'][df1_broadsheets.corr()['Closest_Text_Type'] != 1].sort_values(ascending=False).head()\n",
    "feature = correl.index\n",
    "score = correl.values\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Параметр'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0345ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=-0.514999592795047, pvalue=1.205634754338842e-10)\n",
      "PearsonRResult(statistic=-0.4101304697638328, pvalue=6.450551314705333e-07)\n",
      "PearsonRResult(statistic=-0.17349292647152822, pvalue=0.04261350108114917)\n",
      "PearsonRResult(statistic=-0.03015793066054716, pvalue=0.726462669530383)\n",
      "PearsonRResult(statistic=0.01546297645947228, pvalue=0.857669264971359)\n",
      "PearsonRResult(statistic=0.332876018813791, pvalue=7.053622033389623e-05)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension1'], df1_broadsheets['Closest_Text_Type']))\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension2'], df1_broadsheets['Closest_Text_Type']))\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension4'], df1_broadsheets['Closest_Text_Type']))\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension6'], df1_broadsheets['Closest_Text_Type']))\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension5'], df1_broadsheets['Closest_Text_Type']))\n",
    "print(stats.pearsonr(df1_broadsheets['Dimension3'], df1_broadsheets['Closest_Text_Type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318cd798",
   "metadata": {},
   "source": [
    "### Корреляция по broadsheets (Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8cff2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_broadsheets = df2_broadsheets.loc[:,~df2_broadsheets.columns.duplicated()].copy()\n",
    "df2_tabloids = df2_tabloids.loc[:,~df2_tabloids.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dc479c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FPP1</td>\n",
       "      <td>-0.387537</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TPP3</td>\n",
       "      <td>-0.358187</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VB</td>\n",
       "      <td>-0.345953</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XX0</td>\n",
       "      <td>-0.328693</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIT</td>\n",
       "      <td>-0.324777</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Correlation   P-value\n",
       "0    FPP1    -0.387537  0.000003\n",
       "1    TPP3    -0.358187  0.000017\n",
       "2      VB    -0.345953  0.000035\n",
       "3     XX0    -0.328693  0.000088\n",
       "4     PIT    -0.324777  0.000108"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df2_broadsheets.corr()['Closest_Text_Type'][df2_broadsheets.corr()['Closest_Text_Type'] != 1].sort_values(ascending=True).head()\n",
    "feature = correl.index\n",
    "feature1 = feature\n",
    "score = correl.values\n",
    "correlation = pd.DataFrame()\n",
    "pearsonr = []\n",
    "for f in feature:\n",
    "    pearsonr.append(stats.pearsonr(df2_broadsheets[f], df2_broadsheets['Closest_Text_Type'])[1])\n",
    "\n",
    "correlation['Feature'] = feature\n",
    "correlation['Correlation'] = score\n",
    "correlation['P-value'] = pearsonr\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bf9747b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметр</th>\n",
       "      <th>Корреляция</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AWL</td>\n",
       "      <td>0.426358</td>\n",
       "      <td>2.049407e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHC</td>\n",
       "      <td>0.408147</td>\n",
       "      <td>7.390863e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.348608</td>\n",
       "      <td>2.983818e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JJ</td>\n",
       "      <td>0.326417</td>\n",
       "      <td>9.909812e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIN</td>\n",
       "      <td>0.259640</td>\n",
       "      <td>2.184848e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Параметр  Корреляция       P-value\n",
       "0      AWL    0.426358  2.049407e-07\n",
       "1      PHC    0.408147  7.390863e-07\n",
       "2       NN    0.348608  2.983818e-05\n",
       "3       JJ    0.326417  9.909812e-05\n",
       "4      PIN    0.259640  2.184848e-03"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df2_broadsheets.corr()['Closest_Text_Type'][df2_broadsheets.corr()['Closest_Text_Type'] != 1].sort_values(ascending=False).head()\n",
    "feature = correl.index\n",
    "feature2 = feature\n",
    "score = correl.values\n",
    "\n",
    "pearsonr = []\n",
    "for f in feature:\n",
    "    pearsonr.append(stats.pearsonr(df2_broadsheets[f], df2_broadsheets['Closest_Text_Type'])[1])\n",
    "\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Параметр'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "correlation['P-value'] = pearsonr\n",
    "\n",
    "    \n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038381cb",
   "metadata": {},
   "source": [
    "### Корреляция по tabloids (dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e399b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Корреляция</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dimension3</td>\n",
       "      <td>0.269407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dimension5</td>\n",
       "      <td>0.227036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dimension4</td>\n",
       "      <td>-0.053711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dimension6</td>\n",
       "      <td>-0.114513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dimension1</td>\n",
       "      <td>-0.158765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dimension  Корреляция\n",
       "0  Dimension3    0.269407\n",
       "1  Dimension5    0.227036\n",
       "2  Dimension4   -0.053711\n",
       "3  Dimension6   -0.114513\n",
       "4  Dimension1   -0.158765"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df1_tabloids.corr()['Closest_Text_Type'][df1_tabloids.corr()['Closest_Text_Type'] != 1].sort_values(ascending=False).head()\n",
    "feature = correl.index\n",
    "score = correl.values\n",
    "\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Dimension'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd1bba",
   "metadata": {},
   "source": [
    "### Корреляция по tabloids (основные параметры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31162d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметр</th>\n",
       "      <th>Корреляция</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPP3</td>\n",
       "      <td>-0.243757</td>\n",
       "      <td>0.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYNE</td>\n",
       "      <td>-0.226020</td>\n",
       "      <td>0.008391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIME</td>\n",
       "      <td>-0.223909</td>\n",
       "      <td>0.009037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tokens</td>\n",
       "      <td>-0.202692</td>\n",
       "      <td>0.018389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOBJ</td>\n",
       "      <td>-0.185198</td>\n",
       "      <td>0.031521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Параметр  Корреляция   P-value\n",
       "0     TPP3   -0.243757  0.004386\n",
       "1     SYNE   -0.226020  0.008391\n",
       "2     TIME   -0.223909  0.009037\n",
       "3   Tokens   -0.202692  0.018389\n",
       "4     TOBJ   -0.185198  0.031521"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df2_tabloids.corr()['Closest_Text_Type'][df2_tabloids.corr()['Closest_Text_Type'] != 1].sort_values(ascending=True).head()\n",
    "feature = correl.index\n",
    "feature3 = feature\n",
    "score = correl.values\n",
    "\n",
    "pearsonr = []\n",
    "for f in feature:\n",
    "    pearsonr.append(stats.pearsonr(df2_tabloids[f], df2_tabloids['Closest_Text_Type'])[1])\n",
    "\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Параметр'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "correlation['P-value'] = pearsonr\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9e83f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Параметр</th>\n",
       "      <th>Корреляция</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AWL</td>\n",
       "      <td>0.242714</td>\n",
       "      <td>0.004563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JJ</td>\n",
       "      <td>0.238583</td>\n",
       "      <td>0.005325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOMZ</td>\n",
       "      <td>0.184365</td>\n",
       "      <td>0.032306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GER</td>\n",
       "      <td>0.179405</td>\n",
       "      <td>0.037339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHC</td>\n",
       "      <td>0.171176</td>\n",
       "      <td>0.047137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Параметр  Корреляция   P-value\n",
       "0      AWL    0.242714  0.004563\n",
       "1       JJ    0.238583  0.005325\n",
       "2     NOMZ    0.184365  0.032306\n",
       "3      GER    0.179405  0.037339\n",
       "4      PHC    0.171176  0.047137"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl = df2_tabloids.corr()['Closest_Text_Type'][df2_tabloids.corr()['Closest_Text_Type'] != 1].sort_values(ascending=False).head()\n",
    "feature = correl.index\n",
    "feature4 = feature\n",
    "score = correl.values\n",
    "\n",
    "pearsonr = []\n",
    "for f in feature:\n",
    "    pearsonr.append(stats.pearsonr(df2_tabloids[f], df2_tabloids['Closest_Text_Type'])[1])\n",
    "\n",
    "correlation = pd.DataFrame()\n",
    "correlation['Параметр'] = feature\n",
    "correlation['Корреляция'] = score\n",
    "correlation['P-value'] = pearsonr\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bd95ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AWL',\n",
       " 'FPP1',\n",
       " 'GER',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NOMZ',\n",
       " 'PHC',\n",
       " 'PIN',\n",
       " 'PIT',\n",
       " 'SYNE',\n",
       " 'TIME',\n",
       " 'TOBJ',\n",
       " 'TPP3',\n",
       " 'Tokens',\n",
       " 'VB',\n",
       " 'XX0'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_full = feature1.to_list() + feature2.to_list() + feature3.to_list() + feature4.to_list()\n",
    "set(features_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d6d2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tabloids = df2_tabloids[[\n",
    "                                         'AWL',\n",
    "                                         'FPP1',\n",
    "                                         'GER',\n",
    "                                         'JJ',\n",
    "                                         'NN',\n",
    "                                         'NOMZ',\n",
    "                                         'PHC',\n",
    "                                         'PIN',\n",
    "                                         'PIT',\n",
    "                                         'SYNE',\n",
    "                                         'TIME',\n",
    "                                         'TOBJ',\n",
    "                                         'TPP3',\n",
    "                                         'Tokens',\n",
    "                                         'VB',\n",
    "                                         'XX0',\n",
    "                                         'Closest_Text_Type']]\n",
    "\n",
    "df2_broadsheets = df2_broadsheets[[\n",
    "                                         'AWL',\n",
    "                                         'FPP1',\n",
    "                                         'GER',\n",
    "                                         'JJ',\n",
    "                                         'NN',\n",
    "                                         'NOMZ',\n",
    "                                         'PHC',\n",
    "                                         'PIN',\n",
    "                                         'PIT',\n",
    "                                         'SYNE',\n",
    "                                         'TIME',\n",
    "                                         'TOBJ',\n",
    "                                         'TPP3',\n",
    "                                         'Tokens',\n",
    "                                         'VB',\n",
    "                                         'XX0',\n",
    "                                         'Closest_Text_Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e35e743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1t_train = df1_tabloids[:72]\n",
    "df2t_train = df2_tabloids[:72]\n",
    "df1b_train = df1_broadsheets[:73]\n",
    "df2b_train = df2_broadsheets[:73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50ce004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1t_test = df1_tabloids[72:]\n",
    "df2t_test = df2_tabloids[72:]\n",
    "df1b_test = df1_broadsheets[73:]\n",
    "df2b_test = df2_broadsheets[73:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22823fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_tabloids.to_csv('tabloids_dimensions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22756b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_tabloids.to_csv('tabloids_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0428b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_broadsheets.to_csv('broadsheets_dimensions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b991eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_broadsheets.to_csv('broadsheets_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1aa43c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1_t = df1t_train['Closest_Text_Type']\n",
    "y_test1_t = df1t_test['Closest_Text_Type']\n",
    "\n",
    "x_train1_t = df1t_train.drop(['Closest_Text_Type'], axis=1)\n",
    "x_test1_t = df1t_test.drop(['Closest_Text_Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc128969",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1_b = df1b_train['Closest_Text_Type']\n",
    "y_test1_b = df1b_test['Closest_Text_Type']\n",
    "\n",
    "x_train1_b = df1b_train.drop(['Closest_Text_Type'], axis=1)\n",
    "x_test1_b = df1b_test.drop(['Closest_Text_Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4438ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2_t = df2t_train['Closest_Text_Type']\n",
    "y_test2_t = df2t_test['Closest_Text_Type']\n",
    "\n",
    "x_train2_t = df2t_train.drop(['Closest_Text_Type'], axis=1)\n",
    "x_test2_t = df2t_test.drop(['Closest_Text_Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4345f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2_b = df2b_train['Closest_Text_Type']\n",
    "y_test2_b = df2b_test['Closest_Text_Type']\n",
    "\n",
    "x_train2_b = df2b_train.drop(['Closest_Text_Type'], axis=1)\n",
    "x_test2_b = df2b_test.drop(['Closest_Text_Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "996617bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AWL</th>\n",
       "      <th>FPP1</th>\n",
       "      <th>GER</th>\n",
       "      <th>JJ</th>\n",
       "      <th>NN</th>\n",
       "      <th>NOMZ</th>\n",
       "      <th>PHC</th>\n",
       "      <th>PIN</th>\n",
       "      <th>PIT</th>\n",
       "      <th>SYNE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>TOBJ</th>\n",
       "      <th>TPP3</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>VB</th>\n",
       "      <th>XX0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10.46</td>\n",
       "      <td>23.11</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.73</td>\n",
       "      <td>11.92</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.14</td>\n",
       "      <td>411.0</td>\n",
       "      <td>9.98</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.06</td>\n",
       "      <td>32.12</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>17.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.03</td>\n",
       "      <td>165.0</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.22</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.59</td>\n",
       "      <td>22.99</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.46</td>\n",
       "      <td>6.67</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>5.06</td>\n",
       "      <td>435.0</td>\n",
       "      <td>12.64</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.51</td>\n",
       "      <td>30.66</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.46</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.62</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.91</td>\n",
       "      <td>31.78</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.87</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>343.0</td>\n",
       "      <td>10.79</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4.41</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.87</td>\n",
       "      <td>8.23</td>\n",
       "      <td>30.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.26</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.46</td>\n",
       "      <td>231.0</td>\n",
       "      <td>11.26</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4.31</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>7.17</td>\n",
       "      <td>23.77</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.29</td>\n",
       "      <td>669.0</td>\n",
       "      <td>10.91</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4.37</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.12</td>\n",
       "      <td>23.62</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>10.26</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.42</td>\n",
       "      <td>614.0</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4.81</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10.03</td>\n",
       "      <td>33.01</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.97</td>\n",
       "      <td>12.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.94</td>\n",
       "      <td>309.0</td>\n",
       "      <td>7.12</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4.52</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.43</td>\n",
       "      <td>27.18</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.51</td>\n",
       "      <td>15.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>986.0</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AWL  FPP1   GER     JJ     NN  NOMZ   PHC    PIN   PIT  SYNE  TIME  TOBJ  \\\n",
       "0   4.51  0.49  0.24  10.46  23.11  4.38  0.73  11.92  1.22  0.73  0.24  0.00   \n",
       "1   4.38  0.00  0.00   6.06  32.12  1.82  0.61  17.58  0.00  0.00  1.21  0.00   \n",
       "2   4.22  4.14  0.00   7.59  22.99  2.76  0.46   6.67  1.38  0.23  1.15  0.46   \n",
       "3   4.79  0.85  0.43   9.51  30.66  1.07  1.50  11.00  0.96  0.00  0.53  0.11   \n",
       "4   4.62  2.92  0.00   9.91  31.78  0.29  0.87   9.62  1.75  0.00  0.00  0.00   \n",
       "..   ...   ...   ...    ...    ...   ...   ...    ...   ...   ...   ...   ...   \n",
       "68  4.41  2.16  0.87   8.23  30.30  0.00  0.00  11.26  0.87  0.00  0.43  0.00   \n",
       "69  4.31  2.54  0.60   7.17  23.77  1.79  0.75   8.67  1.20  0.00  0.30  0.00   \n",
       "70  4.37  2.44  0.49   9.12  23.62  2.61  0.81  10.26  0.81  0.49  0.49  0.00   \n",
       "71  4.81  0.97  0.65  10.03  33.01  3.24  0.97  12.30  0.65  0.00  0.32  0.65   \n",
       "72  4.52  0.71  0.10   9.43  27.18  3.35  0.51  15.82  0.61  0.51  0.51  0.20   \n",
       "\n",
       "    TPP3  Tokens     VB   XX0  \n",
       "0   4.14   411.0   9.98  0.49  \n",
       "1   3.03   165.0   9.70  0.00  \n",
       "2   5.06   435.0  12.64  1.38  \n",
       "3   2.46   936.0   7.69  0.75  \n",
       "4   0.58   343.0  10.79  0.58  \n",
       "..   ...     ...    ...   ...  \n",
       "68  3.46   231.0  11.26  0.43  \n",
       "69  3.29   669.0  10.91  1.49  \n",
       "70  3.42   614.0  13.36  0.81  \n",
       "71  1.94   309.0   7.12  0.32  \n",
       "72  0.61   986.0   9.03  0.20  \n",
       "\n",
       "[73 rows x 16 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6fed51",
   "metadata": {},
   "source": [
    "# Нейросеть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b477b8",
   "metadata": {},
   "source": [
    "### Нейросеть: Tabloids (Dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a29d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "algorithms = []\n",
    "datasets = []\n",
    "features = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48285f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 142ms/step - loss: 1.1216 - accuracy: 0.3056 - val_loss: 1.9932 - val_accuracy: 0.1944\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.3780 - accuracy: 0.3056 - val_loss: 1.2150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8510 - accuracy: 0.4444 - val_loss: 0.8657 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1138 - accuracy: 0.4722 - val_loss: 2.3886 - val_accuracy: 0.1389\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0376 - accuracy: 0.2500 - val_loss: 1.4771 - val_accuracy: 0.1389\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2351 - accuracy: 0.3056 - val_loss: 0.9993 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3263 - accuracy: 0.4444 - val_loss: 1.0775 - val_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6499 - accuracy: 0.4444 - val_loss: 1.0606 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5818 - accuracy: 0.4444 - val_loss: 1.0828 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3737 - accuracy: 0.4722 - val_loss: 1.0149 - val_accuracy: 0.1944\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1517 - accuracy: 0.3611 - val_loss: 1.0912 - val_accuracy: 0.1389\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1290 - accuracy: 0.2500 - val_loss: 1.3341 - val_accuracy: 0.1389\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.3002 - accuracy: 0.2500 - val_loss: 1.1476 - val_accuracy: 0.1389\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1576 - accuracy: 0.2500 - val_loss: 0.9638 - val_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0575 - accuracy: 0.4444 - val_loss: 0.9701 - val_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1533 - accuracy: 0.4444 - val_loss: 0.9382 - val_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2358 - accuracy: 0.4444 - val_loss: 0.9068 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3117 - accuracy: 0.4444 - val_loss: 0.8750 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2547 - accuracy: 0.4444 - val_loss: 0.8980 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0837 - accuracy: 0.4444 - val_loss: 1.0066 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0711 - accuracy: 0.4444 - val_loss: 1.1412 - val_accuracy: 0.1389\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1343 - accuracy: 0.2500 - val_loss: 1.2407 - val_accuracy: 0.1389\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1765 - accuracy: 0.2500 - val_loss: 1.1459 - val_accuracy: 0.1389\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1396 - accuracy: 0.2500 - val_loss: 1.0321 - val_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0721 - accuracy: 0.4444 - val_loss: 1.0241 - val_accuracy: 0.2778\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0693 - accuracy: 0.5000 - val_loss: 1.1078 - val_accuracy: 0.1944\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1362 - accuracy: 0.3056 - val_loss: 1.1572 - val_accuracy: 0.1944\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1863 - accuracy: 0.3056 - val_loss: 1.0678 - val_accuracy: 0.1944\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1802 - accuracy: 0.2222 - val_loss: 0.9903 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1270 - accuracy: 0.6389 - val_loss: 0.9705 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0769 - accuracy: 0.4444 - val_loss: 0.9603 - val_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0514 - accuracy: 0.4444 - val_loss: 1.0110 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1095 - accuracy: 0.4444 - val_loss: 1.0613 - val_accuracy: 0.3611\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1884 - accuracy: 0.4444 - val_loss: 1.0147 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1413 - accuracy: 0.4444 - val_loss: 0.9053 - val_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0874 - accuracy: 0.4444 - val_loss: 0.9253 - val_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0814 - accuracy: 0.4444 - val_loss: 0.9345 - val_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0729 - accuracy: 0.4444 - val_loss: 0.9024 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0532 - accuracy: 0.4444 - val_loss: 0.9584 - val_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0785 - accuracy: 0.4444 - val_loss: 1.0893 - val_accuracy: 0.1389\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1336 - accuracy: 0.2500 - val_loss: 1.1324 - val_accuracy: 0.1389\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0963 - accuracy: 0.2500 - val_loss: 1.1962 - val_accuracy: 0.1944\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1422 - accuracy: 0.3056 - val_loss: 1.3145 - val_accuracy: 0.1944\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2173 - accuracy: 0.3056 - val_loss: 1.1147 - val_accuracy: 0.1944\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1130 - accuracy: 0.2778 - val_loss: 0.9360 - val_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0484 - accuracy: 0.4444 - val_loss: 0.9626 - val_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1065 - accuracy: 0.4444 - val_loss: 1.0232 - val_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1364 - accuracy: 0.3889 - val_loss: 1.0309 - val_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1093 - accuracy: 0.4722 - val_loss: 0.9615 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0725 - accuracy: 0.4444 - val_loss: 0.9147 - val_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0493 - accuracy: 0.4444 - val_loss: 0.9563 - val_accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0710 - accuracy: 0.3889 - val_loss: 1.0327 - val_accuracy: 0.1944\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0920 - accuracy: 0.3056 - val_loss: 1.0032 - val_accuracy: 0.2222\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0809 - accuracy: 0.4722 - val_loss: 0.9357 - val_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0716 - accuracy: 0.4444 - val_loss: 0.9119 - val_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0597 - accuracy: 0.4444 - val_loss: 0.9422 - val_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0454 - accuracy: 0.4444 - val_loss: 1.0061 - val_accuracy: 0.6944\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0582 - accuracy: 0.5833 - val_loss: 1.0184 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0477 - accuracy: 0.6944 - val_loss: 0.9077 - val_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0435 - accuracy: 0.4444 - val_loss: 0.8562 - val_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1237 - accuracy: 0.4444 - val_loss: 0.8637 - val_accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2026 - accuracy: 0.4444 - val_loss: 0.8611 - val_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1666 - accuracy: 0.4444 - val_loss: 0.8803 - val_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0617 - accuracy: 0.4444 - val_loss: 0.9895 - val_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0503 - accuracy: 0.3889 - val_loss: 1.1479 - val_accuracy: 0.1944\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0916 - accuracy: 0.3056 - val_loss: 1.0854 - val_accuracy: 0.1944\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0594 - accuracy: 0.4722 - val_loss: 0.9384 - val_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0538 - accuracy: 0.4444 - val_loss: 0.8982 - val_accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0865 - accuracy: 0.4444 - val_loss: 0.9136 - val_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0602 - accuracy: 0.4444 - val_loss: 0.9731 - val_accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0366 - accuracy: 0.4444 - val_loss: 1.0644 - val_accuracy: 0.1944\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0549 - accuracy: 0.3056 - val_loss: 1.1574 - val_accuracy: 0.1944\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0980 - accuracy: 0.3056 - val_loss: 1.2356 - val_accuracy: 0.1944\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1397 - accuracy: 0.3056 - val_loss: 1.1781 - val_accuracy: 0.1944\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1082 - accuracy: 0.3056 - val_loss: 1.0697 - val_accuracy: 0.7222\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0711 - accuracy: 0.5833 - val_loss: 1.0721 - val_accuracy: 0.4167\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0575 - accuracy: 0.6111 - val_loss: 1.0660 - val_accuracy: 0.6389\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0486 - accuracy: 0.6667 - val_loss: 0.9659 - val_accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0210 - accuracy: 0.4444 - val_loss: 0.8697 - val_accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0703 - accuracy: 0.4444 - val_loss: 0.8528 - val_accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1042 - accuracy: 0.4444 - val_loss: 0.8694 - val_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0516 - accuracy: 0.4444 - val_loss: 0.9735 - val_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0211 - accuracy: 0.5000 - val_loss: 1.1721 - val_accuracy: 0.1944\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1051 - accuracy: 0.3333 - val_loss: 1.1982 - val_accuracy: 0.1944\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0860 - accuracy: 0.3056 - val_loss: 0.9837 - val_accuracy: 0.6667\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0369 - accuracy: 0.4722 - val_loss: 0.8708 - val_accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0502 - accuracy: 0.4444 - val_loss: 0.8579 - val_accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0680 - accuracy: 0.4444 - val_loss: 0.8846 - val_accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0440 - accuracy: 0.4444 - val_loss: 0.9434 - val_accuracy: 0.6667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0277 - accuracy: 0.4444 - val_loss: 0.9765 - val_accuracy: 0.6667\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0155 - accuracy: 0.4722 - val_loss: 0.9939 - val_accuracy: 0.6667\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0231 - accuracy: 0.4444 - val_loss: 1.0365 - val_accuracy: 0.3333\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0623 - accuracy: 0.4444 - val_loss: 1.0335 - val_accuracy: 0.4167\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1003 - accuracy: 0.5278 - val_loss: 0.9488 - val_accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0699 - accuracy: 0.4444 - val_loss: 0.8669 - val_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0489 - accuracy: 0.4444 - val_loss: 0.8612 - val_accuracy: 0.6667\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0526 - accuracy: 0.4444 - val_loss: 0.9401 - val_accuracy: 0.6944\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0758 - accuracy: 0.5556 - val_loss: 1.0873 - val_accuracy: 0.1944\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1335 - accuracy: 0.3056 - val_loss: 1.1948 - val_accuracy: 0.1944\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1577 - accuracy: 0.3056 - val_loss: 1.1907 - val_accuracy: 0.1944\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "0.19444444444444445\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(x_train1_t)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(X_scale,\n",
    "    y_train1_t, test_size=0.5, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(6,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = testY.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Tabloids (обучающая выборка)')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd4976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd27226d",
   "metadata": {},
   "source": [
    "### Нейросеть: Tabloids (основные параметры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa6d0d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 1.3761 - accuracy: 0.2778 - val_loss: 1.0736 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6016 - accuracy: 0.5000 - val_loss: 1.9946 - val_accuracy: 0.1944\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.7427 - accuracy: 0.3056 - val_loss: 1.3516 - val_accuracy: 0.1389\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1938 - accuracy: 0.2500 - val_loss: 1.0131 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5234 - accuracy: 0.4444 - val_loss: 1.0601 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.6290 - accuracy: 0.4444 - val_loss: 0.9263 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1796 - accuracy: 0.3889 - val_loss: 1.6106 - val_accuracy: 0.1944\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.4339 - accuracy: 0.3056 - val_loss: 1.3642 - val_accuracy: 0.1944\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1853 - accuracy: 0.3056 - val_loss: 0.9861 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1109 - accuracy: 0.4444 - val_loss: 0.9729 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3659 - accuracy: 0.4444 - val_loss: 0.9927 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.4645 - accuracy: 0.4444 - val_loss: 0.8835 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2183 - accuracy: 0.4444 - val_loss: 0.9990 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0630 - accuracy: 0.4167 - val_loss: 1.3442 - val_accuracy: 0.1944\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2066 - accuracy: 0.3056 - val_loss: 1.4088 - val_accuracy: 0.1944\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2265 - accuracy: 0.3333 - val_loss: 1.2722 - val_accuracy: 0.1944\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1430 - accuracy: 0.4444 - val_loss: 0.9769 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0406 - accuracy: 0.4444 - val_loss: 0.8629 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1219 - accuracy: 0.4444 - val_loss: 0.8537 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1620 - accuracy: 0.4444 - val_loss: 0.8483 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1068 - accuracy: 0.4444 - val_loss: 0.9028 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0580 - accuracy: 0.4444 - val_loss: 0.9306 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0253 - accuracy: 0.4444 - val_loss: 0.9118 - val_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0577 - accuracy: 0.4444 - val_loss: 0.8775 - val_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0939 - accuracy: 0.4444 - val_loss: 0.8455 - val_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0635 - accuracy: 0.4444 - val_loss: 1.0008 - val_accuracy: 0.6944\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1220 - accuracy: 0.4167 - val_loss: 1.2208 - val_accuracy: 0.1389\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2139 - accuracy: 0.2500 - val_loss: 1.0464 - val_accuracy: 0.1944\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0338 - accuracy: 0.3889 - val_loss: 1.0123 - val_accuracy: 0.1944\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0844 - accuracy: 0.3056 - val_loss: 1.1366 - val_accuracy: 0.1944\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2569 - accuracy: 0.3056 - val_loss: 1.0104 - val_accuracy: 0.3611\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1808 - accuracy: 0.4444 - val_loss: 0.8474 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0567 - accuracy: 0.4444 - val_loss: 0.9389 - val_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0830 - accuracy: 0.4167 - val_loss: 1.1047 - val_accuracy: 0.1389\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2085 - accuracy: 0.2500 - val_loss: 1.1416 - val_accuracy: 0.1389\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2165 - accuracy: 0.2500 - val_loss: 1.0242 - val_accuracy: 0.3611\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0646 - accuracy: 0.5000 - val_loss: 0.9497 - val_accuracy: 0.6944\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9983 - accuracy: 0.5556 - val_loss: 1.1030 - val_accuracy: 0.1944\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1641 - accuracy: 0.3056 - val_loss: 1.1719 - val_accuracy: 0.1944\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2503 - accuracy: 0.3056 - val_loss: 1.0068 - val_accuracy: 0.2222\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1156 - accuracy: 0.3333 - val_loss: 0.8558 - val_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0268 - accuracy: 0.4444 - val_loss: 0.8838 - val_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0490 - accuracy: 0.4444 - val_loss: 0.9355 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0240 - accuracy: 0.4444 - val_loss: 1.0445 - val_accuracy: 0.3889\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0062 - accuracy: 0.5833 - val_loss: 1.3014 - val_accuracy: 0.3056\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1304 - accuracy: 0.5000 - val_loss: 1.4295 - val_accuracy: 0.1944\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1903 - accuracy: 0.3056 - val_loss: 1.2201 - val_accuracy: 0.1944\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0659 - accuracy: 0.3056 - val_loss: 0.8898 - val_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0252 - accuracy: 0.4444 - val_loss: 0.8302 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1636 - accuracy: 0.4444 - val_loss: 0.8316 - val_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1596 - accuracy: 0.4444 - val_loss: 0.8278 - val_accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0191 - accuracy: 0.4444 - val_loss: 0.9414 - val_accuracy: 0.7222\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9997 - accuracy: 0.5833 - val_loss: 1.0678 - val_accuracy: 0.3333\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.9935 - accuracy: 0.5556 - val_loss: 1.0698 - val_accuracy: 0.1944\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0051 - accuracy: 0.4722 - val_loss: 1.0463 - val_accuracy: 0.1389\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0021 - accuracy: 0.3611 - val_loss: 1.0068 - val_accuracy: 0.3611\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9815 - accuracy: 0.4722 - val_loss: 0.9456 - val_accuracy: 0.7222\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9536 - accuracy: 0.5833 - val_loss: 0.8559 - val_accuracy: 0.6667\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9448 - accuracy: 0.4444 - val_loss: 0.8192 - val_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9478 - accuracy: 0.4444 - val_loss: 0.8357 - val_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9258 - accuracy: 0.4444 - val_loss: 0.9048 - val_accuracy: 0.6944\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9189 - accuracy: 0.5556 - val_loss: 1.0101 - val_accuracy: 0.2222\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9702 - accuracy: 0.3611 - val_loss: 1.0756 - val_accuracy: 0.1389\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0085 - accuracy: 0.2500 - val_loss: 0.9514 - val_accuracy: 0.5556\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9216 - accuracy: 0.5556 - val_loss: 0.8393 - val_accuracy: 0.6944\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8885 - accuracy: 0.5833 - val_loss: 0.8600 - val_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9407 - accuracy: 0.6944 - val_loss: 0.8464 - val_accuracy: 0.7222\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9389 - accuracy: 0.6667 - val_loss: 0.7964 - val_accuracy: 0.6944\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8865 - accuracy: 0.5556 - val_loss: 0.8076 - val_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8588 - accuracy: 0.5278 - val_loss: 0.8553 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8462 - accuracy: 0.6389 - val_loss: 0.8302 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8273 - accuracy: 0.6667 - val_loss: 0.8126 - val_accuracy: 0.7222\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8256 - accuracy: 0.6667 - val_loss: 0.7927 - val_accuracy: 0.7222\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8089 - accuracy: 0.6111 - val_loss: 0.7826 - val_accuracy: 0.6944\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8111 - accuracy: 0.5278 - val_loss: 0.7610 - val_accuracy: 0.6944\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8157 - accuracy: 0.4722 - val_loss: 0.7658 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7675 - accuracy: 0.6944 - val_loss: 0.9108 - val_accuracy: 0.4722\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8201 - accuracy: 0.5833 - val_loss: 1.0099 - val_accuracy: 0.3611\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 0.9628 - val_accuracy: 0.3333\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7887 - accuracy: 0.5556 - val_loss: 0.9230 - val_accuracy: 0.4444\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7890 - accuracy: 0.6389 - val_loss: 0.8283 - val_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7631 - accuracy: 0.6944 - val_loss: 0.7125 - val_accuracy: 0.6944\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7607 - accuracy: 0.5000 - val_loss: 0.6862 - val_accuracy: 0.6667\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8425 - accuracy: 0.4444 - val_loss: 0.6738 - val_accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7749 - accuracy: 0.4722 - val_loss: 0.7740 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6936 - accuracy: 0.7778 - val_loss: 1.1914 - val_accuracy: 0.2222\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9099 - accuracy: 0.4722 - val_loss: 1.1916 - val_accuracy: 0.2500\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8631 - accuracy: 0.5278 - val_loss: 0.7998 - val_accuracy: 0.7222\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6817 - accuracy: 0.7778 - val_loss: 0.6547 - val_accuracy: 0.7778\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6569 - accuracy: 0.7222 - val_loss: 0.6247 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6537 - accuracy: 0.6667 - val_loss: 0.6393 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6234 - accuracy: 0.7500 - val_loss: 0.7374 - val_accuracy: 0.7222\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6352 - accuracy: 0.7778 - val_loss: 0.8418 - val_accuracy: 0.5278\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6513 - accuracy: 0.7778 - val_loss: 0.8353 - val_accuracy: 0.5556\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6655 - accuracy: 0.6667 - val_loss: 0.7645 - val_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6278 - accuracy: 0.7500 - val_loss: 0.6666 - val_accuracy: 0.8056\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5811 - accuracy: 0.8333 - val_loss: 0.6278 - val_accuracy: 0.8056\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5746 - accuracy: 0.7500 - val_loss: 0.6296 - val_accuracy: 0.8056\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5561 - accuracy: 0.8611 - val_loss: 0.6864 - val_accuracy: 0.7778\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5729 - accuracy: 0.8333 - val_loss: 0.7545 - val_accuracy: 0.6389\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "0.6388888888888888\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(x_train2_t)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(X_scale,\n",
    "    y_train2_t, test_size=0.5, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(16,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = testY.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Tabloids (обучающая выборка)')\n",
    "features.append('Features')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb970805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 66ms/step - loss: 1.5877 - accuracy: 0.5417 - val_loss: 1.1395 - val_accuracy: 0.1746\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.3083 - accuracy: 0.2639 - val_loss: 0.7974 - val_accuracy: 0.7937\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9522 - accuracy: 0.6389 - val_loss: 1.1613 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1278 - accuracy: 0.5556 - val_loss: 0.6398 - val_accuracy: 0.6984\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6466 - accuracy: 0.8194 - val_loss: 0.7235 - val_accuracy: 0.5397\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7412 - accuracy: 0.5694 - val_loss: 0.5379 - val_accuracy: 0.9683\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5699 - accuracy: 0.8750 - val_loss: 0.4931 - val_accuracy: 0.7937\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5279 - accuracy: 0.7361 - val_loss: 0.4387 - val_accuracy: 0.8889\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4794 - accuracy: 0.8750 - val_loss: 0.4060 - val_accuracy: 0.9206\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4384 - accuracy: 0.8333 - val_loss: 0.4170 - val_accuracy: 0.7937\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4530 - accuracy: 0.7917 - val_loss: 0.3531 - val_accuracy: 0.9206\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3840 - accuracy: 0.8889 - val_loss: 0.3918 - val_accuracy: 0.8413\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4103 - accuracy: 0.8750 - val_loss: 0.3007 - val_accuracy: 0.9524\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3507 - accuracy: 0.9028 - val_loss: 0.3932 - val_accuracy: 0.7619\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4125 - accuracy: 0.7917 - val_loss: 0.2856 - val_accuracy: 0.9206\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2891 - accuracy: 0.9167 - val_loss: 0.2788 - val_accuracy: 0.9365\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3103 - accuracy: 0.9028 - val_loss: 0.2645 - val_accuracy: 0.9365\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2602 - accuracy: 0.9722 - val_loss: 0.2675 - val_accuracy: 0.8730\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2986 - accuracy: 0.8333 - val_loss: 0.2537 - val_accuracy: 0.9365\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2450 - accuracy: 0.9306 - val_loss: 0.2684 - val_accuracy: 0.9365\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2756 - accuracy: 0.9167 - val_loss: 0.2448 - val_accuracy: 0.9365\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2402 - accuracy: 0.9583 - val_loss: 0.2250 - val_accuracy: 0.9524\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2310 - accuracy: 0.9167 - val_loss: 0.2109 - val_accuracy: 0.9524\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2161 - accuracy: 0.9722 - val_loss: 0.2342 - val_accuracy: 0.9206\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2085 - accuracy: 0.9861 - val_loss: 0.2048 - val_accuracy: 0.9841\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1907 - accuracy: 0.9861 - val_loss: 0.1927 - val_accuracy: 0.9683\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1906 - accuracy: 0.9722 - val_loss: 0.1897 - val_accuracy: 0.9683\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1817 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9683\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1832 - accuracy: 0.9861 - val_loss: 0.2061 - val_accuracy: 0.9524\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1679 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9524\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1702 - accuracy: 0.9861 - val_loss: 0.1783 - val_accuracy: 0.9524\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1655 - accuracy: 0.9722 - val_loss: 0.1711 - val_accuracy: 0.9683\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1585 - accuracy: 0.9861 - val_loss: 0.1707 - val_accuracy: 0.9524\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1453 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9524\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1485 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9206\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1525 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9365\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1342 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9524\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1271 - accuracy: 0.9861 - val_loss: 0.1579 - val_accuracy: 0.9683\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1238 - accuracy: 0.9861 - val_loss: 0.1561 - val_accuracy: 0.9683\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1256 - accuracy: 0.9861 - val_loss: 0.1544 - val_accuracy: 0.9683\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1175 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9524\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1272 - accuracy: 0.9861 - val_loss: 0.1742 - val_accuracy: 0.9524\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1209 - accuracy: 0.9861 - val_loss: 0.1560 - val_accuracy: 0.9683\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1167 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9683\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1151 - accuracy: 0.9861 - val_loss: 0.1440 - val_accuracy: 0.9524\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1230 - accuracy: 0.9861 - val_loss: 0.1723 - val_accuracy: 0.9524\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1269 - accuracy: 0.9861 - val_loss: 0.1524 - val_accuracy: 0.9524\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9524\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1023 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9683\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9524\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9524\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1011 - accuracy: 0.9861 - val_loss: 0.1305 - val_accuracy: 0.9524\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0977 - accuracy: 0.9861 - val_loss: 0.1257 - val_accuracy: 0.9524\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9683\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9365\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9841\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9524\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0852 - accuracy: 0.9861 - val_loss: 0.1150 - val_accuracy: 0.9683\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9683\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9206\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9524\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9683\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9524\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9683\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9683\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9683\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9683\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9683\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9365\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9524\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0665 - accuracy: 0.9861 - val_loss: 0.1160 - val_accuracy: 0.9524\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9524\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9524\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9683\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9524\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0635 - accuracy: 0.9861 - val_loss: 0.1119 - val_accuracy: 0.9524\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9524\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9524\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9524\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9524\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9683\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9524\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9524\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9683\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9683\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9524\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9524\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9683\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9683\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9524\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9524\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9524\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9524\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9683\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9524\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9683\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9683\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9683\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9683\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9524\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train1_t)\n",
    "y_test = lb.transform(y_test1_t)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(6,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(x_train1_t, y_train, validation_data=(x_test1_t, y_test),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(x_test1_t, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = y_test.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Tabloids (тестовая выборка)')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8742b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 69ms/step - loss: 1.1895 - accuracy: 0.4167 - val_loss: 1.4878 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.5762 - accuracy: 0.5556 - val_loss: 1.0588 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.0349 - accuracy: 0.5139 - val_loss: 1.2246 - val_accuracy: 0.1746\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1581 - accuracy: 0.2917 - val_loss: 1.0180 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1113 - accuracy: 0.5556 - val_loss: 1.0644 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.0455 - accuracy: 0.5694 - val_loss: 1.0429 - val_accuracy: 0.5397\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1233 - accuracy: 0.3611 - val_loss: 1.0530 - val_accuracy: 0.4603\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9589 - accuracy: 0.5694 - val_loss: 1.0584 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0794 - accuracy: 0.5694 - val_loss: 1.0946 - val_accuracy: 0.5238\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.0784 - accuracy: 0.5972 - val_loss: 1.0278 - val_accuracy: 0.5397\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9686 - accuracy: 0.5139 - val_loss: 0.9804 - val_accuracy: 0.5397\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0083 - accuracy: 0.5694 - val_loss: 1.0158 - val_accuracy: 0.5556\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9801 - accuracy: 0.5556 - val_loss: 0.9359 - val_accuracy: 0.5397\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9056 - accuracy: 0.5833 - val_loss: 0.9773 - val_accuracy: 0.5397\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9624 - accuracy: 0.5833 - val_loss: 0.9400 - val_accuracy: 0.5556\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9086 - accuracy: 0.5694 - val_loss: 0.9514 - val_accuracy: 0.5556\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9212 - accuracy: 0.5417 - val_loss: 0.9419 - val_accuracy: 0.5556\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9894 - accuracy: 0.5694 - val_loss: 0.9848 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9422 - accuracy: 0.5833 - val_loss: 0.9619 - val_accuracy: 0.5873\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9602 - accuracy: 0.5278 - val_loss: 0.9417 - val_accuracy: 0.5556\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9566 - accuracy: 0.5833 - val_loss: 0.9879 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9299 - accuracy: 0.5694 - val_loss: 0.9065 - val_accuracy: 0.6032\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8939 - accuracy: 0.5556 - val_loss: 0.9019 - val_accuracy: 0.6032\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8485 - accuracy: 0.6250 - val_loss: 0.9235 - val_accuracy: 0.5714\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9408 - accuracy: 0.5694 - val_loss: 0.9150 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8719 - accuracy: 0.5833 - val_loss: 0.8995 - val_accuracy: 0.6508\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8564 - accuracy: 0.5833 - val_loss: 0.8795 - val_accuracy: 0.5397\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8412 - accuracy: 0.5972 - val_loss: 0.9094 - val_accuracy: 0.5556\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8386 - accuracy: 0.5694 - val_loss: 0.9197 - val_accuracy: 0.6349\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8892 - accuracy: 0.5278 - val_loss: 0.9509 - val_accuracy: 0.5714\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8300 - accuracy: 0.5694 - val_loss: 0.8877 - val_accuracy: 0.5556\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8550 - accuracy: 0.5833 - val_loss: 0.9174 - val_accuracy: 0.5556\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8560 - accuracy: 0.5833 - val_loss: 0.8374 - val_accuracy: 0.6190\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7968 - accuracy: 0.6250 - val_loss: 0.8376 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8125 - accuracy: 0.6250 - val_loss: 0.8300 - val_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7626 - accuracy: 0.6389 - val_loss: 0.8669 - val_accuracy: 0.6508\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7687 - accuracy: 0.6250 - val_loss: 0.8099 - val_accuracy: 0.5556\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7284 - accuracy: 0.6528 - val_loss: 0.8017 - val_accuracy: 0.7302\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7431 - accuracy: 0.6806 - val_loss: 0.8199 - val_accuracy: 0.6349\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7301 - accuracy: 0.7083 - val_loss: 0.7732 - val_accuracy: 0.5556\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7296 - accuracy: 0.5833 - val_loss: 0.7667 - val_accuracy: 0.5714\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6955 - accuracy: 0.6111 - val_loss: 0.7398 - val_accuracy: 0.6032\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6875 - accuracy: 0.6806 - val_loss: 0.7222 - val_accuracy: 0.6032\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6356 - accuracy: 0.6667 - val_loss: 0.6864 - val_accuracy: 0.6984\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6502 - accuracy: 0.7500 - val_loss: 0.6780 - val_accuracy: 0.7302\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6040 - accuracy: 0.7222 - val_loss: 0.8049 - val_accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7200 - accuracy: 0.6944 - val_loss: 0.7389 - val_accuracy: 0.6349\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7413 - accuracy: 0.6806 - val_loss: 0.7991 - val_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7035 - accuracy: 0.6806 - val_loss: 0.7367 - val_accuracy: 0.6825\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6254 - accuracy: 0.7083 - val_loss: 0.7177 - val_accuracy: 0.6349\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5367 - accuracy: 0.7222 - val_loss: 0.7603 - val_accuracy: 0.6508\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6749 - accuracy: 0.6667 - val_loss: 0.6655 - val_accuracy: 0.7143\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5545 - accuracy: 0.7778 - val_loss: 0.6160 - val_accuracy: 0.7302\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5078 - accuracy: 0.7639 - val_loss: 0.6139 - val_accuracy: 0.7143\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5076 - accuracy: 0.7500 - val_loss: 0.6737 - val_accuracy: 0.6508\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5288 - accuracy: 0.7778 - val_loss: 0.6422 - val_accuracy: 0.7460\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4928 - accuracy: 0.8194 - val_loss: 0.5991 - val_accuracy: 0.7619\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4552 - accuracy: 0.8056 - val_loss: 0.5944 - val_accuracy: 0.7619\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4502 - accuracy: 0.7917 - val_loss: 0.5909 - val_accuracy: 0.7619\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4800 - accuracy: 0.7639 - val_loss: 0.6107 - val_accuracy: 0.7143\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4300 - accuracy: 0.8056 - val_loss: 0.6722 - val_accuracy: 0.7143\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4250 - accuracy: 0.7778 - val_loss: 0.6590 - val_accuracy: 0.7460\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4818 - accuracy: 0.7778 - val_loss: 0.6757 - val_accuracy: 0.6825\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.6007 - val_accuracy: 0.7302\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4088 - accuracy: 0.8056 - val_loss: 0.6487 - val_accuracy: 0.7619\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4531 - accuracy: 0.8056 - val_loss: 0.6128 - val_accuracy: 0.7143\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4277 - accuracy: 0.8056 - val_loss: 0.5724 - val_accuracy: 0.7460\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5897 - val_accuracy: 0.7460\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3912 - accuracy: 0.8194 - val_loss: 0.5785 - val_accuracy: 0.7143\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3706 - accuracy: 0.8333 - val_loss: 0.5818 - val_accuracy: 0.7302\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4285 - accuracy: 0.7917 - val_loss: 0.5971 - val_accuracy: 0.7302\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4321 - accuracy: 0.8056 - val_loss: 0.7109 - val_accuracy: 0.6984\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4987 - accuracy: 0.7639 - val_loss: 0.5919 - val_accuracy: 0.7619\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3953 - accuracy: 0.8194 - val_loss: 0.6307 - val_accuracy: 0.6984\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3994 - accuracy: 0.8194 - val_loss: 0.7202 - val_accuracy: 0.7143\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4581 - accuracy: 0.7639 - val_loss: 0.6934 - val_accuracy: 0.7143\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6223 - accuracy: 0.6944 - val_loss: 0.6431 - val_accuracy: 0.6667\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5488 - accuracy: 0.7083 - val_loss: 0.7339 - val_accuracy: 0.6349\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4393 - accuracy: 0.8056 - val_loss: 0.8305 - val_accuracy: 0.5873\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5386 - accuracy: 0.7500 - val_loss: 0.6679 - val_accuracy: 0.6984\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4505 - accuracy: 0.7917 - val_loss: 0.6358 - val_accuracy: 0.6825\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3924 - accuracy: 0.7917 - val_loss: 0.6082 - val_accuracy: 0.6825\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3647 - accuracy: 0.8889 - val_loss: 0.7000 - val_accuracy: 0.6825\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4721 - accuracy: 0.7500 - val_loss: 0.5667 - val_accuracy: 0.7302\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3943 - accuracy: 0.7917 - val_loss: 0.5951 - val_accuracy: 0.7619\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3493 - accuracy: 0.8611 - val_loss: 0.7909 - val_accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4687 - accuracy: 0.7778 - val_loss: 0.6195 - val_accuracy: 0.6825\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4278 - accuracy: 0.8333 - val_loss: 0.6489 - val_accuracy: 0.7143\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4271 - accuracy: 0.8056 - val_loss: 0.6877 - val_accuracy: 0.6667\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3780 - accuracy: 0.8056 - val_loss: 0.6115 - val_accuracy: 0.7619\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4124 - accuracy: 0.8333 - val_loss: 0.5628 - val_accuracy: 0.7302\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3971 - accuracy: 0.7917 - val_loss: 0.5974 - val_accuracy: 0.6984\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3442 - accuracy: 0.8333 - val_loss: 0.5214 - val_accuracy: 0.7937\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3560 - accuracy: 0.8611 - val_loss: 0.5230 - val_accuracy: 0.7778\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3064 - accuracy: 0.8750 - val_loss: 0.7285 - val_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4144 - accuracy: 0.7778 - val_loss: 0.5561 - val_accuracy: 0.7619\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3052 - accuracy: 0.8333 - val_loss: 0.5343 - val_accuracy: 0.7302\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3082 - accuracy: 0.8750 - val_loss: 0.5493 - val_accuracy: 0.7460\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3429 - accuracy: 0.8056 - val_loss: 0.5271 - val_accuracy: 0.7619\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2949 - accuracy: 0.8472 - val_loss: 0.5837 - val_accuracy: 0.7460\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "0.746031746031746\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train2_t)\n",
    "y_test = lb.transform(y_test2_t)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(16,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(x_train2_t, y_train, validation_data=(x_test2_t, y_test),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(x_test2_t, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = y_test.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Tabloids (тестовая выборка)')\n",
    "features.append('Features')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da35249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9c08229",
   "metadata": {},
   "source": [
    "### Нейросеть: Broadsheets (Dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79dc8b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 1.2747 - accuracy: 0.3056 - val_loss: 1.1310 - val_accuracy: 0.5405\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0221 - accuracy: 0.5833 - val_loss: 1.0758 - val_accuracy: 0.4054\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1209 - accuracy: 0.3611 - val_loss: 1.1450 - val_accuracy: 0.5405\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0678 - accuracy: 0.6389 - val_loss: 1.3316 - val_accuracy: 0.5405\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1799 - accuracy: 0.6389 - val_loss: 1.0408 - val_accuracy: 0.5405\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0651 - accuracy: 0.5278 - val_loss: 1.0243 - val_accuracy: 0.4054\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0600 - accuracy: 0.3056 - val_loss: 1.0127 - val_accuracy: 0.5405\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9543 - accuracy: 0.6389 - val_loss: 1.0500 - val_accuracy: 0.5405\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9422 - accuracy: 0.6389 - val_loss: 0.9545 - val_accuracy: 0.5405\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8708 - accuracy: 0.6389 - val_loss: 0.8645 - val_accuracy: 0.5405\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8364 - accuracy: 0.6389 - val_loss: 1.0259 - val_accuracy: 0.5405\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9985 - accuracy: 0.6389 - val_loss: 0.9966 - val_accuracy: 0.5405\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9357 - accuracy: 0.6389 - val_loss: 0.8951 - val_accuracy: 0.5405\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8114 - accuracy: 0.6389 - val_loss: 0.8396 - val_accuracy: 0.5405\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8587 - accuracy: 0.6389 - val_loss: 0.9183 - val_accuracy: 0.4054\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9709 - accuracy: 0.3056 - val_loss: 0.8625 - val_accuracy: 0.5405\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.8430 - accuracy: 0.6389 - val_loss: 1.0580 - val_accuracy: 0.5405\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9488 - accuracy: 0.6389 - val_loss: 1.1448 - val_accuracy: 0.5405\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0142 - accuracy: 0.6389 - val_loss: 1.0473 - val_accuracy: 0.5405\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9374 - accuracy: 0.6389 - val_loss: 0.9182 - val_accuracy: 0.5405\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8515 - accuracy: 0.6389 - val_loss: 0.8678 - val_accuracy: 0.5405\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8776 - accuracy: 0.6944 - val_loss: 0.9631 - val_accuracy: 0.4054\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0428 - accuracy: 0.3056 - val_loss: 0.8646 - val_accuracy: 0.4054\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.9264 - accuracy: 0.2500 - val_loss: 0.8635 - val_accuracy: 0.5405\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8180 - accuracy: 0.6389 - val_loss: 0.8518 - val_accuracy: 0.5405\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8005 - accuracy: 0.6389 - val_loss: 0.8243 - val_accuracy: 0.5405\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8318 - accuracy: 0.6389 - val_loss: 0.8675 - val_accuracy: 0.4054\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9113 - accuracy: 0.3056 - val_loss: 0.8313 - val_accuracy: 0.5405\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8387 - accuracy: 0.6389 - val_loss: 0.8821 - val_accuracy: 0.5405\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8260 - accuracy: 0.6389 - val_loss: 0.8648 - val_accuracy: 0.5405\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8093 - accuracy: 0.6389 - val_loss: 0.8238 - val_accuracy: 0.5405\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8092 - accuracy: 0.6389 - val_loss: 0.8299 - val_accuracy: 0.5405\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8447 - accuracy: 0.6389 - val_loss: 0.8423 - val_accuracy: 0.5405\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8637 - accuracy: 0.4722 - val_loss: 0.8346 - val_accuracy: 0.5405\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8030 - accuracy: 0.6389 - val_loss: 1.0289 - val_accuracy: 0.5405\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9300 - accuracy: 0.6389 - val_loss: 1.0211 - val_accuracy: 0.5405\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9013 - accuracy: 0.6389 - val_loss: 0.8567 - val_accuracy: 0.5405\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8274 - accuracy: 0.6389 - val_loss: 0.8378 - val_accuracy: 0.5946\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8603 - accuracy: 0.6389 - val_loss: 0.8220 - val_accuracy: 0.5405\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8178 - accuracy: 0.6389 - val_loss: 0.8632 - val_accuracy: 0.5405\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8330 - accuracy: 0.6389 - val_loss: 0.9406 - val_accuracy: 0.5405\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8512 - accuracy: 0.6389 - val_loss: 0.8944 - val_accuracy: 0.5405\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8193 - accuracy: 0.6389 - val_loss: 0.8696 - val_accuracy: 0.5405\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8067 - accuracy: 0.6389 - val_loss: 0.8326 - val_accuracy: 0.5405\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8106 - accuracy: 0.6389 - val_loss: 0.8302 - val_accuracy: 0.5405\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8324 - accuracy: 0.6389 - val_loss: 0.8265 - val_accuracy: 0.5405\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8078 - accuracy: 0.6389 - val_loss: 0.8494 - val_accuracy: 0.5405\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8074 - accuracy: 0.6389 - val_loss: 0.8955 - val_accuracy: 0.5405\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8189 - accuracy: 0.6389 - val_loss: 0.8790 - val_accuracy: 0.5405\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8135 - accuracy: 0.6389 - val_loss: 0.8552 - val_accuracy: 0.5405\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8032 - accuracy: 0.6389 - val_loss: 0.8255 - val_accuracy: 0.5405\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8039 - accuracy: 0.6389 - val_loss: 0.8168 - val_accuracy: 0.5405\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8156 - accuracy: 0.6389 - val_loss: 0.8157 - val_accuracy: 0.5405\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8196 - accuracy: 0.6389 - val_loss: 0.8135 - val_accuracy: 0.5405\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7958 - accuracy: 0.6389 - val_loss: 0.8598 - val_accuracy: 0.5405\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7984 - accuracy: 0.6389 - val_loss: 0.9836 - val_accuracy: 0.5405\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8753 - accuracy: 0.6389 - val_loss: 0.9864 - val_accuracy: 0.5405\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8717 - accuracy: 0.6389 - val_loss: 0.8818 - val_accuracy: 0.5405\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8014 - accuracy: 0.6389 - val_loss: 0.8140 - val_accuracy: 0.5405\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8079 - accuracy: 0.6389 - val_loss: 0.8266 - val_accuracy: 0.7838\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8550 - accuracy: 0.6944 - val_loss: 0.8189 - val_accuracy: 0.6757\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8368 - accuracy: 0.7222 - val_loss: 0.8095 - val_accuracy: 0.5405\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8104 - accuracy: 0.6389 - val_loss: 0.8110 - val_accuracy: 0.5405\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7910 - accuracy: 0.6389 - val_loss: 0.8152 - val_accuracy: 0.5405\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7863 - accuracy: 0.6389 - val_loss: 0.8210 - val_accuracy: 0.5405\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7984 - accuracy: 0.6389 - val_loss: 0.8107 - val_accuracy: 0.5405\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8233 - accuracy: 0.5833 - val_loss: 0.8228 - val_accuracy: 0.7027\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8413 - accuracy: 0.7500 - val_loss: 0.8183 - val_accuracy: 0.5405\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7989 - accuracy: 0.6389 - val_loss: 0.8601 - val_accuracy: 0.5405\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8103 - accuracy: 0.6389 - val_loss: 0.8997 - val_accuracy: 0.5405\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8176 - accuracy: 0.6389 - val_loss: 0.8396 - val_accuracy: 0.5405\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7901 - accuracy: 0.6389 - val_loss: 0.8034 - val_accuracy: 0.5405\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7927 - accuracy: 0.6389 - val_loss: 0.8020 - val_accuracy: 0.5405\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7912 - accuracy: 0.6389 - val_loss: 0.8283 - val_accuracy: 0.5405\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7902 - accuracy: 0.6389 - val_loss: 0.8982 - val_accuracy: 0.5405\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8146 - accuracy: 0.6389 - val_loss: 0.8894 - val_accuracy: 0.5405\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8053 - accuracy: 0.6389 - val_loss: 0.8059 - val_accuracy: 0.5405\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8138 - accuracy: 0.5833 - val_loss: 0.8358 - val_accuracy: 0.4054\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8721 - accuracy: 0.3056 - val_loss: 0.8078 - val_accuracy: 0.5676\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8068 - accuracy: 0.6389 - val_loss: 0.8509 - val_accuracy: 0.5405\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7833 - accuracy: 0.6389 - val_loss: 1.0166 - val_accuracy: 0.5405\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8918 - accuracy: 0.6389 - val_loss: 1.1450 - val_accuracy: 0.5405\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9872 - accuracy: 0.6389 - val_loss: 1.1576 - val_accuracy: 0.5405\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9902 - accuracy: 0.6389 - val_loss: 1.0039 - val_accuracy: 0.5405\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8712 - accuracy: 0.6389 - val_loss: 0.8454 - val_accuracy: 0.5405\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8119 - accuracy: 0.6389 - val_loss: 0.8961 - val_accuracy: 0.4054\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9434 - accuracy: 0.3056 - val_loss: 0.9255 - val_accuracy: 0.4054\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9923 - accuracy: 0.3056 - val_loss: 0.8202 - val_accuracy: 0.7297\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8215 - accuracy: 0.7222 - val_loss: 0.8586 - val_accuracy: 0.5405\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8243 - accuracy: 0.6389 - val_loss: 1.0297 - val_accuracy: 0.5405\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.9079 - accuracy: 0.6389 - val_loss: 1.0622 - val_accuracy: 0.5405\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.9302 - accuracy: 0.6389 - val_loss: 1.0045 - val_accuracy: 0.5405\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8834 - accuracy: 0.6389 - val_loss: 0.8940 - val_accuracy: 0.5405\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8195 - accuracy: 0.6389 - val_loss: 0.8204 - val_accuracy: 0.5405\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7974 - accuracy: 0.6389 - val_loss: 0.8146 - val_accuracy: 0.5405\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8247 - accuracy: 0.6389 - val_loss: 0.8136 - val_accuracy: 0.5405\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8185 - accuracy: 0.6389 - val_loss: 0.8146 - val_accuracy: 0.5405\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7982 - accuracy: 0.6389 - val_loss: 0.8231 - val_accuracy: 0.5405\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7903 - accuracy: 0.6389 - val_loss: 0.8398 - val_accuracy: 0.5405\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7982 - accuracy: 0.6389 - val_loss: 0.8541 - val_accuracy: 0.5405\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020DD5937E20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "0.5405405405405406\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(x_train1_b)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(X_scale,\n",
    "    y_train1_b, test_size=0.5, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(6,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = testY.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Broadsheets (обучающая выборка)')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76e32f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 65ms/step - loss: 1.0571 - accuracy: 0.5890 - val_loss: 1.3272 - val_accuracy: 0.5469\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.0584 - accuracy: 0.6164 - val_loss: 1.0497 - val_accuracy: 0.8438\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8296 - accuracy: 0.7808 - val_loss: 0.9017 - val_accuracy: 0.5938\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6803 - accuracy: 0.7123 - val_loss: 0.8056 - val_accuracy: 0.6562\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6430 - accuracy: 0.8493 - val_loss: 0.6878 - val_accuracy: 0.6562\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5452 - accuracy: 0.7671 - val_loss: 0.6839 - val_accuracy: 0.6562\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5180 - accuracy: 0.7534 - val_loss: 0.6376 - val_accuracy: 0.8438\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4724 - accuracy: 0.8767 - val_loss: 0.5929 - val_accuracy: 0.8438\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4324 - accuracy: 0.8493 - val_loss: 0.5309 - val_accuracy: 0.7969\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3824 - accuracy: 0.9041 - val_loss: 0.5115 - val_accuracy: 0.8438\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3527 - accuracy: 0.9041 - val_loss: 0.4835 - val_accuracy: 0.7812\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3286 - accuracy: 0.8630 - val_loss: 0.4730 - val_accuracy: 0.8594\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3105 - accuracy: 0.9315 - val_loss: 0.4848 - val_accuracy: 0.8281\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3026 - accuracy: 0.9315 - val_loss: 0.4133 - val_accuracy: 0.8125\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2582 - accuracy: 0.9315 - val_loss: 0.4199 - val_accuracy: 0.8906\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2625 - accuracy: 0.9726 - val_loss: 0.4035 - val_accuracy: 0.8906\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2248 - accuracy: 0.9589 - val_loss: 0.3937 - val_accuracy: 0.7969\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2401 - accuracy: 0.9178 - val_loss: 0.4284 - val_accuracy: 0.7969\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2224 - accuracy: 0.9452 - val_loss: 0.4216 - val_accuracy: 0.8125\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2153 - accuracy: 0.9452 - val_loss: 0.3952 - val_accuracy: 0.8906\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1843 - accuracy: 0.9589 - val_loss: 0.3684 - val_accuracy: 0.8750\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1999 - accuracy: 0.9726 - val_loss: 0.3446 - val_accuracy: 0.8906\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1713 - accuracy: 0.9452 - val_loss: 0.3976 - val_accuracy: 0.8438\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1708 - accuracy: 0.9452 - val_loss: 0.4064 - val_accuracy: 0.8125\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1966 - accuracy: 0.9315 - val_loss: 0.3603 - val_accuracy: 0.8594\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1516 - accuracy: 0.9589 - val_loss: 0.3742 - val_accuracy: 0.8594\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1533 - accuracy: 0.9452 - val_loss: 0.3342 - val_accuracy: 0.8906\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1240 - accuracy: 0.9726 - val_loss: 0.3369 - val_accuracy: 0.8438\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1316 - accuracy: 0.9726 - val_loss: 0.3299 - val_accuracy: 0.8594\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1256 - accuracy: 0.9726 - val_loss: 0.3470 - val_accuracy: 0.8750\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1236 - accuracy: 0.9589 - val_loss: 0.3195 - val_accuracy: 0.8906\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1238 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1096 - accuracy: 0.9726 - val_loss: 0.3205 - val_accuracy: 0.8906\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1031 - accuracy: 0.9589 - val_loss: 0.3205 - val_accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1016 - accuracy: 0.9589 - val_loss: 0.3165 - val_accuracy: 0.8594\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0911 - accuracy: 0.9863 - val_loss: 0.3087 - val_accuracy: 0.8906\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.8750\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1011 - accuracy: 0.9726 - val_loss: 0.3024 - val_accuracy: 0.8906\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.8438\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0901 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0848 - accuracy: 0.9726 - val_loss: 0.3163 - val_accuracy: 0.8750\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0818 - accuracy: 0.9726 - val_loss: 0.3082 - val_accuracy: 0.8750\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0757 - accuracy: 0.9863 - val_loss: 0.3125 - val_accuracy: 0.8594\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9062\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9062\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0685 - accuracy: 0.9863 - val_loss: 0.2922 - val_accuracy: 0.9062\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0659 - accuracy: 0.9863 - val_loss: 0.2868 - val_accuracy: 0.8906\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.8594\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.8750\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9219\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9062\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9219\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9062\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9062\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9062\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9062\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0499 - accuracy: 0.9863 - val_loss: 0.2755 - val_accuracy: 0.8906\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.8750\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9062\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9062\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9062\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.8906\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.8906\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.8906\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.8906\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9062\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9062\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.8281\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.8594\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9062\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9062\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9062\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9062\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9062\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0395 - accuracy: 0.9863 - val_loss: 0.2942 - val_accuracy: 0.8594\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.8594\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9062\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9062\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9062\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.8594\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9062\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9062\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9062\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9062\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9062\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9062\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9062\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9062\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9062\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9062\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9062\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9219\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9062\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9062\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.8906\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.8750\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.8906\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9219\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9219\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9062\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020DD7E137F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "0.90625\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train1_b)\n",
    "y_test = lb.transform(y_test1_b)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(6,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(x_train1_b, y_train, validation_data=(x_test1_b, y_test),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(x_test1_b, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = y_test.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Broadsheets (тестовая выборка)')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7971d",
   "metadata": {},
   "source": [
    "### Нейросеть: Broadsheets (основные параметры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3157037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 1.3670 - accuracy: 0.3056 - val_loss: 1.5043 - val_accuracy: 0.5405\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3055 - accuracy: 0.6389 - val_loss: 0.9079 - val_accuracy: 0.5405\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8903 - accuracy: 0.6389 - val_loss: 0.9104 - val_accuracy: 0.5405\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8898 - accuracy: 0.6389 - val_loss: 1.0038 - val_accuracy: 0.5405\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9118 - accuracy: 0.6389 - val_loss: 0.9957 - val_accuracy: 0.5405\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8948 - accuracy: 0.6389 - val_loss: 0.8737 - val_accuracy: 0.5405\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8110 - accuracy: 0.6389 - val_loss: 0.8785 - val_accuracy: 0.7297\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.9064 - accuracy: 0.8889 - val_loss: 0.8608 - val_accuracy: 0.5405\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8806 - accuracy: 0.6389 - val_loss: 0.8571 - val_accuracy: 0.5405\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7999 - accuracy: 0.6389 - val_loss: 0.9715 - val_accuracy: 0.5405\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8659 - accuracy: 0.6389 - val_loss: 1.0395 - val_accuracy: 0.5405\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9037 - accuracy: 0.6389 - val_loss: 0.8465 - val_accuracy: 0.5405\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8504 - accuracy: 0.5833 - val_loss: 0.9034 - val_accuracy: 0.4054\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.9251 - accuracy: 0.4167 - val_loss: 0.9666 - val_accuracy: 0.5405\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.9122 - accuracy: 0.6389 - val_loss: 1.2189 - val_accuracy: 0.5405\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0405 - accuracy: 0.6389 - val_loss: 0.8897 - val_accuracy: 0.5405\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8085 - accuracy: 0.6667 - val_loss: 0.9724 - val_accuracy: 0.4054\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0630 - accuracy: 0.3056 - val_loss: 0.9041 - val_accuracy: 0.4054\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.9273 - accuracy: 0.4167 - val_loss: 0.9447 - val_accuracy: 0.5405\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8520 - accuracy: 0.6389 - val_loss: 1.4116 - val_accuracy: 0.5405\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1898 - accuracy: 0.6389 - val_loss: 1.4207 - val_accuracy: 0.5405\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1835 - accuracy: 0.6389 - val_loss: 1.0704 - val_accuracy: 0.5405\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8991 - accuracy: 0.6389 - val_loss: 0.8156 - val_accuracy: 0.5676\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8606 - accuracy: 0.5556 - val_loss: 0.8773 - val_accuracy: 0.4054\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9293 - accuracy: 0.3333 - val_loss: 0.8071 - val_accuracy: 0.5405\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7987 - accuracy: 0.6389 - val_loss: 0.8945 - val_accuracy: 0.5405\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8215 - accuracy: 0.6389 - val_loss: 0.8897 - val_accuracy: 0.5405\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8104 - accuracy: 0.6389 - val_loss: 0.8166 - val_accuracy: 0.5405\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7860 - accuracy: 0.6389 - val_loss: 0.8078 - val_accuracy: 0.5405\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7655 - accuracy: 0.6389 - val_loss: 0.8845 - val_accuracy: 0.5405\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8006 - accuracy: 0.6389 - val_loss: 0.9854 - val_accuracy: 0.5405\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8654 - accuracy: 0.6389 - val_loss: 0.9879 - val_accuracy: 0.5405\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8611 - accuracy: 0.6389 - val_loss: 0.8688 - val_accuracy: 0.5405\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7857 - accuracy: 0.6389 - val_loss: 0.7828 - val_accuracy: 0.5676\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7753 - accuracy: 0.6667 - val_loss: 0.7902 - val_accuracy: 0.7297\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7933 - accuracy: 0.8056 - val_loss: 0.7871 - val_accuracy: 0.5405\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7510 - accuracy: 0.6389 - val_loss: 0.8668 - val_accuracy: 0.5405\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7831 - accuracy: 0.6389 - val_loss: 0.9199 - val_accuracy: 0.5405\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8143 - accuracy: 0.6389 - val_loss: 0.8362 - val_accuracy: 0.5405\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7749 - accuracy: 0.6389 - val_loss: 0.7753 - val_accuracy: 0.5676\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7540 - accuracy: 0.6389 - val_loss: 0.7716 - val_accuracy: 0.6486\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7644 - accuracy: 0.7500 - val_loss: 0.7735 - val_accuracy: 0.5405\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7417 - accuracy: 0.6389 - val_loss: 0.8543 - val_accuracy: 0.5405\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7624 - accuracy: 0.6389 - val_loss: 0.9860 - val_accuracy: 0.5405\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8478 - accuracy: 0.6389 - val_loss: 1.1000 - val_accuracy: 0.5405\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9328 - accuracy: 0.6389 - val_loss: 1.1076 - val_accuracy: 0.5405\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.9304 - accuracy: 0.6389 - val_loss: 0.9067 - val_accuracy: 0.5405\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7834 - accuracy: 0.6389 - val_loss: 0.7564 - val_accuracy: 0.6757\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7479 - accuracy: 0.7500 - val_loss: 0.8636 - val_accuracy: 0.4054\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9190 - accuracy: 0.3056 - val_loss: 0.8045 - val_accuracy: 0.4324\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8218 - accuracy: 0.5000 - val_loss: 0.7726 - val_accuracy: 0.5405\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7586 - accuracy: 0.6389 - val_loss: 0.8795 - val_accuracy: 0.5405\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7677 - accuracy: 0.6389 - val_loss: 0.7989 - val_accuracy: 0.5405\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7225 - accuracy: 0.6389 - val_loss: 0.7605 - val_accuracy: 0.5676\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7171 - accuracy: 0.6667 - val_loss: 0.7440 - val_accuracy: 0.5946\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7034 - accuracy: 0.6667 - val_loss: 0.7493 - val_accuracy: 0.5405\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6853 - accuracy: 0.6389 - val_loss: 0.8280 - val_accuracy: 0.5405\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7315 - accuracy: 0.6389 - val_loss: 0.9090 - val_accuracy: 0.5405\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7869 - accuracy: 0.6389 - val_loss: 0.8547 - val_accuracy: 0.5405\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7434 - accuracy: 0.6389 - val_loss: 0.7319 - val_accuracy: 0.6216\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6911 - accuracy: 0.6944 - val_loss: 0.7799 - val_accuracy: 0.5676\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8187 - accuracy: 0.4167 - val_loss: 0.7286 - val_accuracy: 0.7568\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7542 - accuracy: 0.7500 - val_loss: 0.7224 - val_accuracy: 0.5676\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6714 - accuracy: 0.6667 - val_loss: 0.7111 - val_accuracy: 0.5946\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6499 - accuracy: 0.6944 - val_loss: 0.7059 - val_accuracy: 0.7838\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7094 - accuracy: 0.8333 - val_loss: 0.7030 - val_accuracy: 0.7568\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6900 - accuracy: 0.8889 - val_loss: 0.7114 - val_accuracy: 0.5946\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6409 - accuracy: 0.6667 - val_loss: 0.7696 - val_accuracy: 0.5405\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6659 - accuracy: 0.6389 - val_loss: 0.8289 - val_accuracy: 0.5405\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7082 - accuracy: 0.6389 - val_loss: 0.8014 - val_accuracy: 0.5405\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6912 - accuracy: 0.6389 - val_loss: 0.7184 - val_accuracy: 0.5676\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6313 - accuracy: 0.6667 - val_loss: 0.6891 - val_accuracy: 0.5946\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6130 - accuracy: 0.6944 - val_loss: 0.6641 - val_accuracy: 0.6486\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6083 - accuracy: 0.7500 - val_loss: 0.6533 - val_accuracy: 0.7568\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6155 - accuracy: 0.8611 - val_loss: 0.6655 - val_accuracy: 0.7568\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6554 - accuracy: 0.8333 - val_loss: 0.6418 - val_accuracy: 0.7297\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6052 - accuracy: 0.8611 - val_loss: 0.6924 - val_accuracy: 0.5946\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5973 - accuracy: 0.6667 - val_loss: 0.7585 - val_accuracy: 0.5676\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6363 - accuracy: 0.6667 - val_loss: 0.7112 - val_accuracy: 0.5946\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6127 - accuracy: 0.6667 - val_loss: 0.6625 - val_accuracy: 0.6216\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5763 - accuracy: 0.7222 - val_loss: 0.6286 - val_accuracy: 0.7297\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5661 - accuracy: 0.8056 - val_loss: 0.6165 - val_accuracy: 0.7297\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5722 - accuracy: 0.8889 - val_loss: 0.6101 - val_accuracy: 0.7568\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5482 - accuracy: 0.8056 - val_loss: 0.6396 - val_accuracy: 0.6216\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5485 - accuracy: 0.7500 - val_loss: 0.6220 - val_accuracy: 0.6216\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5169 - accuracy: 0.7500 - val_loss: 0.5954 - val_accuracy: 0.7297\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5274 - accuracy: 0.8889 - val_loss: 0.7469 - val_accuracy: 0.7568\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7286 - accuracy: 0.7778 - val_loss: 0.6571 - val_accuracy: 0.7568\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5786 - accuracy: 0.8611 - val_loss: 0.7671 - val_accuracy: 0.5946\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6115 - accuracy: 0.6667 - val_loss: 0.8615 - val_accuracy: 0.5676\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6699 - accuracy: 0.6667 - val_loss: 0.6506 - val_accuracy: 0.6216\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5300 - accuracy: 0.7500 - val_loss: 0.5735 - val_accuracy: 0.7568\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5486 - accuracy: 0.8333 - val_loss: 0.5637 - val_accuracy: 0.7568\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5021 - accuracy: 0.8611 - val_loss: 0.6237 - val_accuracy: 0.6216\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4954 - accuracy: 0.7222 - val_loss: 0.8541 - val_accuracy: 0.5676\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6697 - accuracy: 0.6667 - val_loss: 0.7667 - val_accuracy: 0.5946\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5587 - accuracy: 0.6667 - val_loss: 0.5482 - val_accuracy: 0.7568\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4947 - accuracy: 0.8889 - val_loss: 0.7855 - val_accuracy: 0.6216\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7900 - accuracy: 0.5833 - val_loss: 0.6527 - val_accuracy: 0.7838\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6104 - accuracy: 0.7500 - val_loss: 0.5360 - val_accuracy: 0.7568\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "0.7567567567567568\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(x_train2_b)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(X_scale,\n",
    "    y_train2_b, test_size=0.5, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(16,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = testY.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Broadsheets (обучающая выборка)')\n",
    "features.append('Features')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5862c319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 68ms/step - loss: 1.1852 - accuracy: 0.5890 - val_loss: 1.2867 - val_accuracy: 0.5469\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1274 - accuracy: 0.5342 - val_loss: 1.2307 - val_accuracy: 0.4531\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.0455 - accuracy: 0.5890 - val_loss: 1.1443 - val_accuracy: 0.5469\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9513 - accuracy: 0.5890 - val_loss: 1.0937 - val_accuracy: 0.3906\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0571 - accuracy: 0.4795 - val_loss: 1.0391 - val_accuracy: 0.5469\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9538 - accuracy: 0.5890 - val_loss: 1.0841 - val_accuracy: 0.5469\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9588 - accuracy: 0.5616 - val_loss: 1.1071 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9706 - accuracy: 0.5890 - val_loss: 1.0832 - val_accuracy: 0.5469\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9455 - accuracy: 0.5616 - val_loss: 1.0451 - val_accuracy: 0.5469\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9201 - accuracy: 0.5890 - val_loss: 0.9944 - val_accuracy: 0.5469\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8805 - accuracy: 0.5616 - val_loss: 0.9569 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8604 - accuracy: 0.6301 - val_loss: 1.0292 - val_accuracy: 0.5469\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9535 - accuracy: 0.5890 - val_loss: 0.9694 - val_accuracy: 0.5469\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8277 - accuracy: 0.5890 - val_loss: 1.0834 - val_accuracy: 0.4062\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9725 - accuracy: 0.4521 - val_loss: 0.9776 - val_accuracy: 0.5469\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.9412 - accuracy: 0.5890 - val_loss: 1.1713 - val_accuracy: 0.5469\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9660 - accuracy: 0.5890 - val_loss: 0.9521 - val_accuracy: 0.5469\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8696 - accuracy: 0.5890 - val_loss: 0.9782 - val_accuracy: 0.4688\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8934 - accuracy: 0.5616 - val_loss: 0.9377 - val_accuracy: 0.5469\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8357 - accuracy: 0.5890 - val_loss: 0.9420 - val_accuracy: 0.5469\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8311 - accuracy: 0.5890 - val_loss: 0.9507 - val_accuracy: 0.5469\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8294 - accuracy: 0.5890 - val_loss: 0.9610 - val_accuracy: 0.5469\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8331 - accuracy: 0.5890 - val_loss: 0.9370 - val_accuracy: 0.5781\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8097 - accuracy: 0.6712 - val_loss: 0.9115 - val_accuracy: 0.5625\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8025 - accuracy: 0.6575 - val_loss: 0.9207 - val_accuracy: 0.5469\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8078 - accuracy: 0.5890 - val_loss: 0.9056 - val_accuracy: 0.5469\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7988 - accuracy: 0.6712 - val_loss: 0.8895 - val_accuracy: 0.6250\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7725 - accuracy: 0.7123 - val_loss: 0.8765 - val_accuracy: 0.5938\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7522 - accuracy: 0.6575 - val_loss: 0.8595 - val_accuracy: 0.6406\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7671 - accuracy: 0.6301 - val_loss: 0.8484 - val_accuracy: 0.6406\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7170 - accuracy: 0.7534 - val_loss: 0.8578 - val_accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7107 - accuracy: 0.6849 - val_loss: 0.8433 - val_accuracy: 0.6562\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7073 - accuracy: 0.7123 - val_loss: 0.8248 - val_accuracy: 0.6406\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6790 - accuracy: 0.6849 - val_loss: 0.7930 - val_accuracy: 0.6562\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6600 - accuracy: 0.7945 - val_loss: 0.8194 - val_accuracy: 0.6250\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6957 - accuracy: 0.6986 - val_loss: 0.8019 - val_accuracy: 0.7188\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6660 - accuracy: 0.7671 - val_loss: 0.7960 - val_accuracy: 0.7344\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6927 - accuracy: 0.7123 - val_loss: 0.7780 - val_accuracy: 0.6875\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6570 - accuracy: 0.7123 - val_loss: 0.7870 - val_accuracy: 0.6875\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6251 - accuracy: 0.7671 - val_loss: 0.7843 - val_accuracy: 0.6719\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5724 - accuracy: 0.7397 - val_loss: 0.7734 - val_accuracy: 0.6875\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5962 - accuracy: 0.7808 - val_loss: 0.7523 - val_accuracy: 0.6875\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5507 - accuracy: 0.8356 - val_loss: 0.7467 - val_accuracy: 0.6562\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5547 - accuracy: 0.7808 - val_loss: 0.8754 - val_accuracy: 0.6094\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7054 - accuracy: 0.6575 - val_loss: 0.7261 - val_accuracy: 0.7344\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6065 - accuracy: 0.7671 - val_loss: 0.7126 - val_accuracy: 0.7188\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5356 - accuracy: 0.7808 - val_loss: 0.7793 - val_accuracy: 0.6875\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5572 - accuracy: 0.8356 - val_loss: 0.7416 - val_accuracy: 0.7188\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5367 - accuracy: 0.8356 - val_loss: 0.7439 - val_accuracy: 0.7031\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5039 - accuracy: 0.8356 - val_loss: 0.7619 - val_accuracy: 0.6875\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5559 - accuracy: 0.7808 - val_loss: 0.8425 - val_accuracy: 0.6875\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6298 - accuracy: 0.7123 - val_loss: 0.7062 - val_accuracy: 0.6406\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5758 - accuracy: 0.7808 - val_loss: 0.6710 - val_accuracy: 0.6875\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4934 - accuracy: 0.8082 - val_loss: 0.7511 - val_accuracy: 0.7031\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4768 - accuracy: 0.7945 - val_loss: 0.6840 - val_accuracy: 0.7188\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4763 - accuracy: 0.7808 - val_loss: 0.7532 - val_accuracy: 0.7031\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4995 - accuracy: 0.7945 - val_loss: 0.6681 - val_accuracy: 0.7188\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5058 - accuracy: 0.8219 - val_loss: 0.7221 - val_accuracy: 0.7031\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5085 - accuracy: 0.7808 - val_loss: 0.6636 - val_accuracy: 0.7656\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7073 - accuracy: 0.6986 - val_loss: 0.6960 - val_accuracy: 0.7344\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5376 - accuracy: 0.7671 - val_loss: 0.6660 - val_accuracy: 0.7031\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5184 - accuracy: 0.7534 - val_loss: 0.7212 - val_accuracy: 0.6719\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5025 - accuracy: 0.7671 - val_loss: 0.7407 - val_accuracy: 0.7031\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4997 - accuracy: 0.7671 - val_loss: 0.6554 - val_accuracy: 0.7188\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4653 - accuracy: 0.8219 - val_loss: 0.6869 - val_accuracy: 0.7031\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4380 - accuracy: 0.8219 - val_loss: 0.6885 - val_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4655 - accuracy: 0.7945 - val_loss: 0.6994 - val_accuracy: 0.7656\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4417 - accuracy: 0.8356 - val_loss: 0.6562 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3994 - accuracy: 0.8493 - val_loss: 0.6787 - val_accuracy: 0.7188\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4538 - accuracy: 0.7808 - val_loss: 0.6804 - val_accuracy: 0.7031\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4266 - accuracy: 0.7945 - val_loss: 0.6622 - val_accuracy: 0.7031\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4205 - accuracy: 0.8493 - val_loss: 0.6896 - val_accuracy: 0.7188\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4589 - accuracy: 0.7945 - val_loss: 0.6708 - val_accuracy: 0.7344\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3910 - accuracy: 0.8493 - val_loss: 0.6388 - val_accuracy: 0.7188\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4052 - accuracy: 0.8356 - val_loss: 0.6882 - val_accuracy: 0.7188\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3999 - accuracy: 0.8082 - val_loss: 0.6491 - val_accuracy: 0.7031\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3888 - accuracy: 0.8356 - val_loss: 0.6531 - val_accuracy: 0.7812\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4036 - accuracy: 0.7945 - val_loss: 0.6526 - val_accuracy: 0.7344\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4063 - accuracy: 0.7945 - val_loss: 0.6929 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4161 - accuracy: 0.8219 - val_loss: 0.6990 - val_accuracy: 0.7344\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3937 - accuracy: 0.8219 - val_loss: 0.6604 - val_accuracy: 0.7188\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3843 - accuracy: 0.8082 - val_loss: 0.6987 - val_accuracy: 0.7188\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4465 - accuracy: 0.7534 - val_loss: 0.7171 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4059 - accuracy: 0.8219 - val_loss: 0.7175 - val_accuracy: 0.7188\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3681 - accuracy: 0.8493 - val_loss: 0.7196 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4789 - accuracy: 0.7534 - val_loss: 0.8126 - val_accuracy: 0.7031\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4630 - accuracy: 0.8493 - val_loss: 0.6861 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5565 - accuracy: 0.7534 - val_loss: 0.8384 - val_accuracy: 0.7031\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5886 - accuracy: 0.7671 - val_loss: 0.8034 - val_accuracy: 0.7344\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3642 - accuracy: 0.8493 - val_loss: 0.9033 - val_accuracy: 0.6406\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5394 - accuracy: 0.7534 - val_loss: 0.9171 - val_accuracy: 0.6875\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5825 - accuracy: 0.7260 - val_loss: 0.6592 - val_accuracy: 0.7031\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4120 - accuracy: 0.7671 - val_loss: 0.7513 - val_accuracy: 0.7031\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4466 - accuracy: 0.8082 - val_loss: 0.8524 - val_accuracy: 0.7031\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4549 - accuracy: 0.8082 - val_loss: 0.6532 - val_accuracy: 0.7031\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4142 - accuracy: 0.8493 - val_loss: 0.6458 - val_accuracy: 0.7344\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3530 - accuracy: 0.8493 - val_loss: 0.6891 - val_accuracy: 0.7812\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3705 - accuracy: 0.8356 - val_loss: 0.6534 - val_accuracy: 0.7188\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3403 - accuracy: 0.8356 - val_loss: 0.7058 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3592 - accuracy: 0.8219 - val_loss: 0.6342 - val_accuracy: 0.7344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "0.734375\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train2_b)\n",
    "y_test = lb.transform(y_test2_b)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(16,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(x_train2_b, y_train, validation_data=(x_test2_b, y_test),\n",
    "    epochs=100, batch_size=32)\n",
    "\n",
    "predictions = model.predict(x_test2_b, batch_size=32)\n",
    "predictions2 = predictions.argmax(axis=1)\n",
    "\n",
    "testY_arg = y_test.argmax(axis=1)\n",
    "print(accuracy_score(testY_arg, predictions2))\n",
    "\n",
    "algorithms.append('Нейросеть')\n",
    "datasets.append('Broadsheets (тестовая выборка)')\n",
    "features.append('Features')\n",
    "accuracies.append(accuracy_score(testY_arg, predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a6b6f8",
   "metadata": {},
   "source": [
    "# Пайплайн"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eff1a9",
   "metadata": {},
   "source": [
    "### Пайплайн: Tabloids (Dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a066d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9365079365079365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), \n",
    "                 ('classifier', RandomForestClassifier(random_state = 42, n_estimators = 1500)),\n",
    "             ]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "print(pipe.fit(x_train1_t, y_train1_t).score(x_test1_t, y_test1_t))\n",
    "\n",
    "algorithms.append('Пайплайн')\n",
    "datasets.append('Tabloids')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(pipe.fit(x_train1_t, y_train1_t).score(x_test1_t, y_test1_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f1a02",
   "metadata": {},
   "source": [
    "### Пайплайн: Tabloids (Основные параметры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922dc69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e4ed7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), \n",
    "                 ('classifier', RandomForestClassifier(random_state = 42, n_estimators = 1500)),\n",
    "             ]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "print(pipe.fit(x_train2_t, y_train2_t).score(x_test2_t, y_test2_t))\n",
    "\n",
    "algorithms.append('Пайплайн')\n",
    "datasets.append('Tabloids')\n",
    "features.append('Features')\n",
    "accuracies.append(pipe.fit(x_train2_t, y_train2_t).score(x_test2_t, y_test2_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "999b4c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     AWL  FPP1   GER     JJ     NN  NOMZ   PHC    PIN   PIT  SYNE  TIME  TOBJ  \\\n",
       " 64  4.61  0.00  0.00   7.00  28.01  1.68  1.12  11.20  1.12  0.00  1.40  0.00   \n",
       " 3   4.16  2.22  0.00  10.16  31.11  0.63  0.00  12.06  0.00  0.00  0.32  0.00   \n",
       " 17  4.51  1.87  0.75   7.12  23.97  1.87  0.19  10.11  2.25  0.37  0.75  0.19   \n",
       " 38  4.53  0.00  2.51   6.53  36.18  2.01  1.51  13.57  0.00  0.50  0.00  0.00   \n",
       " 8   4.87  0.59  1.07   9.24  26.90  3.79  0.59  10.66  0.95  0.00  1.18  0.00   \n",
       " 57  4.43  2.37  0.64   6.03  26.38  1.45  0.97  10.74  0.97  0.36  1.77  0.08   \n",
       " 6   4.89  0.00  0.64   9.13  38.85  2.12  1.06  12.53  0.21  0.00  0.21  0.00   \n",
       " 36  4.45  1.07  0.64   4.51  32.62  1.29  0.64  11.16  1.93  0.00  0.64  0.43   \n",
       " 66  4.23  2.66  0.42   5.88  21.71  3.78  0.00   9.52  2.10  0.00  1.26  0.00   \n",
       " 53  4.42  1.18  0.77   6.59  28.68  1.47  1.12  11.65  1.18  0.25  0.73  0.00   \n",
       " 70  4.09  2.53  0.42   4.21  27.37  1.26  1.05   8.21  1.26  0.21  0.63  0.21   \n",
       " 15  4.30  3.10  0.00   4.28  25.66  1.47  0.88  11.95  1.33  0.15  0.88  0.15   \n",
       " 27  4.88  0.00  0.45   8.54  33.03  2.70  2.02  11.69  1.57  0.00  1.12  0.45   \n",
       " 41  4.15  3.63  0.67   5.06  24.64  1.34  1.05   9.74  0.96  0.10  0.57  0.19   \n",
       " 26  4.47  1.39  0.00   5.54  32.96  3.88  0.28  11.91  0.00  0.00  0.55  0.00   \n",
       " 48  4.43  2.79  0.19   5.88  22.25  2.02  0.48   9.06  1.54  0.00  0.48  0.00   \n",
       " 24  4.65  1.92  0.58   5.58  30.19  1.73  0.38  11.35  0.77  0.00  1.35  0.19   \n",
       " 61  4.36  1.50  0.09   6.19  26.28  1.42  0.80   9.38  0.88  0.18  0.53  0.09   \n",
       " 65  4.43  0.00  0.00   8.70  26.00  2.35  1.08  10.85  0.10  0.10  0.49  0.10   \n",
       " 11  4.13  2.13  0.11   4.36  22.42  2.02  0.74   9.14  0.53  0.11  0.21  0.32   \n",
       " 32  4.05  1.52  0.38   5.50  29.79  2.47  1.14  13.09  0.57  0.19  0.76  0.19   \n",
       " 68  4.63  0.18  1.60   6.41  25.62  4.27  0.53  10.85  1.78  0.18  0.71  0.18   \n",
       " 63  4.79  0.84  1.12   9.52  36.13  1.12  2.52  12.61  0.00  0.00  0.00  0.00   \n",
       " 37  4.45  0.00  0.17   5.69  34.31  1.90  0.17  11.72  0.69  0.17  0.34  0.00   \n",
       " 29  4.56  0.00  0.00   8.89  28.33  2.96  0.74  12.59  0.74  0.00  0.19  0.00   \n",
       " 43  4.74  0.78  0.50   8.53  35.28  1.71  1.64  11.74  0.78  0.07  0.43  0.00   \n",
       " 67  4.54  0.62  0.11   7.89  26.58  2.73  1.02  11.30  0.85  0.62  0.68  0.23   \n",
       " 1   4.15  2.50  0.18   4.47  27.37  1.25  0.36   9.30  1.25  0.00  0.72  0.00   \n",
       " 52  4.18  2.32  0.46   7.88  22.72  3.71  1.39   8.96  0.62  0.15  1.39  0.62   \n",
       " 21  4.08  2.71  0.29   6.02  23.11  0.88  1.10   9.17  1.61  0.00  1.39  0.15   \n",
       " 2   3.91  0.42  0.63   5.04  25.00  0.63  0.21  10.50  2.31  0.00  0.21  0.21   \n",
       " 23  4.14  4.51  1.73   4.68  17.50  1.73  0.52   9.53  0.69  0.00  0.35  0.17   \n",
       " 20  3.92  5.49  0.42   4.64  21.10  0.84  0.21   8.02  1.27  0.21  0.63  0.21   \n",
       " 60  4.92  1.21  0.17  10.36  28.32  4.32  1.38  11.40  0.86  0.00  0.00  0.17   \n",
       " 14  4.47  0.00  2.01   7.02  30.08  0.75  1.75  13.78  0.25  0.00  0.25  0.25   \n",
       " 51  4.00  3.86  1.13   6.11  19.94  0.32  0.48   8.36  2.41  0.32  0.00  0.16   \n",
       " \n",
       "     TPP3  Tokens     VB   XX0  \n",
       " 64  0.84   357.0  14.57  0.56  \n",
       " 3   5.71   315.0   6.35  0.00  \n",
       " 17  3.00   534.0   9.74  0.75  \n",
       " 38  0.50   199.0   6.53  0.00  \n",
       " 8   1.30   844.0   9.48  0.12  \n",
       " 57  2.25  2487.0  13.91  0.72  \n",
       " 6   0.42   471.0   6.58  0.21  \n",
       " 36  4.08   466.0  10.30  0.43  \n",
       " 66  1.96   714.0  10.36  1.82  \n",
       " 53  1.43  4825.0  10.94  0.39  \n",
       " 70  6.32   475.0  11.16  1.26  \n",
       " 15  5.01   678.0  12.54  0.59  \n",
       " 27  1.12   445.0   8.99  0.22  \n",
       " 41  4.49  1047.0  12.61  1.43  \n",
       " 26  2.77   361.0  10.53  0.00  \n",
       " 48  4.34  1038.0  13.87  1.16  \n",
       " 24  4.04   520.0   8.46  0.38  \n",
       " 61  7.08  1130.0  11.50  0.44  \n",
       " 65  6.45  1023.0  10.75  0.00  \n",
       " 11  7.44   941.0  12.86  1.91  \n",
       " 32  6.64   527.0   8.35  0.38  \n",
       " 68  1.42   562.0  10.68  0.36  \n",
       " 63  0.00   357.0   9.52  0.28  \n",
       " 37  3.62   580.0  10.17  0.34  \n",
       " 29  0.37   540.0  11.67  0.56  \n",
       " 43  1.64  1406.0   7.61  0.50  \n",
       " 67  3.07  1761.0   9.48  0.80  \n",
       " 1   4.11   559.0  13.60  0.54  \n",
       " 52  3.09   647.0  10.97  0.46  \n",
       " 21  6.02  1363.0  10.64  0.73  \n",
       " 2   3.78   476.0  10.29  0.42  \n",
       " 23  8.49   577.0  11.61  1.21  \n",
       " 20  4.85   474.0  11.60  0.84  \n",
       " 60  0.52   579.0  10.02  0.69  \n",
       " 14  0.25   399.0  12.03  0.00  \n",
       " 51  6.43   622.0  11.58  0.32  ,\n",
       "      AWL  FPP1   GER     JJ     NN  NOMZ   PHC    PIN   PIT  SYNE  TIME  TOBJ  \\\n",
       " 4   4.47  1.13  1.58   8.13  30.02  1.35  1.35  12.87  2.26  0.00  0.45  0.68   \n",
       " 62  4.19  2.75  0.22   4.30  20.37  2.86  0.33   8.37  2.31  0.00  0.22  0.11   \n",
       " 18  4.10  2.67  0.16   5.50  25.00  0.47  0.94   8.49  5.03  0.00  0.00  0.31   \n",
       " 0   4.15  0.87  0.38   4.71  27.02  0.38  0.19  10.38  0.67  0.29  0.38  0.29   \n",
       " 28  4.47  1.77  0.10   5.90  23.40  1.87  0.79   9.83  0.88  0.00  1.08  0.49   \n",
       " 50  4.64  0.73  0.28   7.49  25.86  2.11  0.64   9.74  1.01  0.23  0.60  0.18   \n",
       " 10  4.40  0.00  0.68   7.69  26.24  0.68  0.90   9.05  0.45  0.23  0.23  0.00   \n",
       " 34  4.81  0.00  0.84  10.32  34.74  1.68  2.53   7.16  0.00  0.00  0.63  0.00   \n",
       " 12  4.44  1.68  0.37   5.42  28.22  2.43  1.12  12.90  0.93  0.00  0.19  0.00   \n",
       " 54  4.05  4.81  0.00  10.98  20.14  0.46  1.37  10.76  3.43  0.00  0.00  0.23   \n",
       " 47  4.39  2.38  0.10   7.10  25.70  1.76  1.40   9.84  1.40  0.10  0.47  0.00   \n",
       " 31  4.02  5.07  0.00   9.01  23.26  0.75  0.94  10.51  0.75  0.00  1.31  0.00   \n",
       " 9   4.65  0.95  0.38   6.43  30.43  1.70  1.13   9.07  1.70  0.19  0.95  0.19   \n",
       " 45  4.46  0.88  0.00   3.52  32.39  1.58  2.11  10.39  0.70  0.53  0.18  0.35   \n",
       " 5   4.52  1.23  0.14  10.11  27.87  2.46  0.82  11.75  1.37  0.14  0.68  0.14   \n",
       " 22  4.01  3.70  0.00   8.83  26.78  2.56  0.28  12.25  2.85  0.00  0.00  0.28   \n",
       " 56  4.21  1.31  0.00   5.91  23.48  2.30  0.49  10.67  1.48  0.00  0.99  0.49   \n",
       " 49  4.18  3.02  0.14   6.80  24.95  3.02  1.51  10.65  1.86  0.07  0.62  0.21   \n",
       " 33  4.31  2.57  0.59   7.52  31.29  0.99  0.20   9.11  0.59  0.20  0.79  0.00   \n",
       " 39  4.39  1.04  0.50   6.86  28.75  1.51  0.93  12.13  1.62  0.18  0.68  0.07   \n",
       " 59  4.51  0.97  0.49   9.00  27.49  1.70  0.97   8.27  0.97  0.00  2.43  0.49   \n",
       " 16  4.18  2.71  0.24   7.54  21.79  1.06  0.94   8.48  2.94  0.12  0.71  0.00   \n",
       " 35  4.35  1.04  0.15   8.63  25.15  0.89  0.60  11.90  1.93  0.15  0.15  0.00   \n",
       " 44  3.96  1.25  0.00   3.58  23.79  0.72  1.25  10.91  0.00  0.00  1.25  0.00   \n",
       " 69  4.37  0.00  0.56   3.63  32.68  0.56  0.00   9.22  0.84  0.56  0.56  0.56   \n",
       " 7   4.17  2.70  0.21   6.44  30.98  1.66  1.04  10.19  0.62  0.00  1.04  0.21   \n",
       " 55  4.28  0.86  1.18   6.66  29.97  0.86  1.18  13.86  1.07  0.00  0.32  0.11   \n",
       " 42  4.28  2.06  0.06   7.07  25.39  1.75  1.19  10.07  1.44  0.13  0.44  0.00   \n",
       " 30  4.33  1.42  0.24   8.53  29.86  1.18  0.95  12.32  0.95  0.24  0.95  0.00   \n",
       " 46  4.53  1.83  1.16   6.18  26.83  1.83  1.64   9.75  1.25  0.00  0.39  0.00   \n",
       " 71  4.30  2.17  0.35   5.90  26.97  1.56  0.87  11.19  1.47  0.17  0.52  0.09   \n",
       " 19  4.48  0.25  0.25  11.70  28.24  0.51  0.51   6.87  1.78  0.25  1.27  0.25   \n",
       " 58  4.73  0.00  0.81   8.53  33.69  1.35  0.81  12.99  1.62  0.00  0.68  0.14   \n",
       " 25  4.40  0.36  0.36   9.55  31.89  0.72  1.26  11.35  1.62  0.36  0.00  0.00   \n",
       " 40  4.37  1.88  0.27   6.97  30.83  1.61  1.61   9.65  1.34  0.00  0.00  0.00   \n",
       " 13  4.23  3.41  0.00   5.12  25.37  1.71  0.24   9.51  0.98  0.00  0.49  0.00   \n",
       " \n",
       "     TPP3  Tokens     VB   XX0  \n",
       " 4   2.26   443.0   7.45  0.90  \n",
       " 62  4.96   908.0  14.21  2.20  \n",
       " 18  2.20   636.0  13.36  0.47  \n",
       " 0   6.06  1040.0  14.52  0.48  \n",
       " 28  5.31  1017.0  14.95  0.49  \n",
       " 50  5.51  2177.0  10.52  0.37  \n",
       " 10  6.33   442.0  11.54  0.90  \n",
       " 34  1.89   475.0  10.95  0.21  \n",
       " 12  2.06   535.0  10.84  0.37  \n",
       " 54  0.69   437.0   9.84  2.06  \n",
       " 47  2.28  1930.0  10.73  1.19  \n",
       " 31  3.00   533.0   8.63  0.75  \n",
       " 9   2.27   529.0   9.45  0.57  \n",
       " 45  4.40   568.0  10.39  0.53  \n",
       " 5   0.68   732.0  10.52  0.41  \n",
       " 22  1.99   351.0   7.69  0.00  \n",
       " 56  9.20   609.0   8.21  0.16  \n",
       " 49  2.96  1455.0  10.45  0.41  \n",
       " 33  5.94   505.0   7.72  0.40  \n",
       " 39  1.69  2786.0  10.19  0.47  \n",
       " 59  1.70   411.0   7.06  0.97  \n",
       " 16  2.00   849.0  10.60  1.18  \n",
       " 35  0.30   672.0  11.16  1.34  \n",
       " 44  5.72   559.0  13.77  1.07  \n",
       " 69  6.98   358.0  11.73  0.84  \n",
       " 7   2.29   481.0   7.07  0.42  \n",
       " 55  0.43   931.0  10.74  0.00  \n",
       " 42  2.38  1599.0  10.82  1.13  \n",
       " 30  5.21   422.0   9.72  0.47  \n",
       " 46  5.98  1036.0   8.30  0.58  \n",
       " 71  5.29  1153.0   9.19  0.95  \n",
       " 19  1.02   393.0  11.70  1.78  \n",
       " 58  0.95   739.0   6.90  0.00  \n",
       " 25  0.36   555.0   8.11  0.72  \n",
       " 40  0.80   373.0   8.58  0.00  \n",
       " 13  5.37   410.0  10.49  0.73  ]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(x_train2_t, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbe2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe118a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c96443a1",
   "metadata": {},
   "source": [
    "### Пайплайн: Broadsheets (Dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69b19645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), \n",
    "                 ('classifier', RandomForestClassifier(random_state = 42, n_estimators = 1500)),\n",
    "             ]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "print(pipe.fit(x_train1_b, y_train1_b).score(x_test1_b, y_test1_b))\n",
    "\n",
    "algorithms.append('Пайплайн')\n",
    "datasets.append('Broadsheets')\n",
    "features.append('Dimensions')\n",
    "accuracies.append(pipe.fit(x_train1_b, y_train1_b).score(x_test1_b, y_test1_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295236ec",
   "metadata": {},
   "source": [
    "### Пайплайн: Broadsheets (основные параметры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8812cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = [('scaler', StandardScaler()), \n",
    "                 ('classifier', RandomForestClassifier(random_state = 42, n_estimators = 1500)),\n",
    "             ]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "print(pipe.fit(x_train2_b, y_train2_b).score(x_test2_b, y_test2_b))\n",
    "\n",
    "algorithms.append('Пайплайн')\n",
    "datasets.append('Broadsheets')\n",
    "features.append('Features')\n",
    "accuracies.append(pipe.fit(x_train2_b, y_train2_b).score(x_test2_b, y_test2_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da94bbd",
   "metadata": {},
   "source": [
    "### Таблица сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2d68ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame()\n",
    "comparison['Алгоритм'] = algorithms\n",
    "comparison['Датасет'] = datasets\n",
    "comparison['Параметры'] = features\n",
    "comparison['Точность'] = accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e4a8363",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Алгоритм</th>\n",
       "      <th>Датасет</th>\n",
       "      <th>Параметры</th>\n",
       "      <th>Точность</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Tabloids (обучающая выборка)</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.194444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Tabloids (обучающая выборка)</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Tabloids (тестовая выборка)</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Tabloids (тестовая выборка)</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Broadsheets (обучающая выборка)</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Broadsheets (тестовая выборка)</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Broadsheets (обучающая выборка)</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Нейросеть</td>\n",
       "      <td>Broadsheets (тестовая выборка)</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Пайплайн</td>\n",
       "      <td>Tabloids</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.936508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Пайплайн</td>\n",
       "      <td>Tabloids</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Пайплайн</td>\n",
       "      <td>Broadsheets</td>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Пайплайн</td>\n",
       "      <td>Broadsheets</td>\n",
       "      <td>Features</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Алгоритм                          Датасет   Параметры  Точность\n",
       "0   Нейросеть     Tabloids (обучающая выборка)  Dimensions  0.194444\n",
       "1   Нейросеть     Tabloids (обучающая выборка)    Features  0.638889\n",
       "2   Нейросеть      Tabloids (тестовая выборка)  Dimensions  0.952381\n",
       "3   Нейросеть      Tabloids (тестовая выборка)    Features  0.746032\n",
       "4   Нейросеть  Broadsheets (обучающая выборка)  Dimensions  0.540541\n",
       "5   Нейросеть   Broadsheets (тестовая выборка)  Dimensions  0.906250\n",
       "6   Нейросеть  Broadsheets (обучающая выборка)    Features  0.756757\n",
       "7   Нейросеть   Broadsheets (тестовая выборка)    Features  0.734375\n",
       "8    Пайплайн                         Tabloids  Dimensions  0.936508\n",
       "9    Пайплайн                         Tabloids    Features  0.777778\n",
       "10   Пайплайн                      Broadsheets  Dimensions  0.843750\n",
       "11   Пайплайн                      Broadsheets    Features  0.734375"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb79a2",
   "metadata": {},
   "source": [
    "### Можно сделать следующие выводы:\n",
    "* Нейросеть даёт высокую точность как на Tabloids, так и на Broadsheets, и в целом справляется с этой задачей лучше, чем пайплайн.\n",
    "* Пайплайн лучше обрабатывает датасеты Tabloids, чем Broadsheets, и при этом даёт более высокий результат на параметрах Dimensions. То же самое можно сказать и о нейросети.\n",
    "* При обработке датасетов через нейросеть можно проследить одну особенность: обработка Tabloids через Dimensions на обучающей выборке даёт меньшую точность, чем при обработке тестовой выборки, однако при обработке тех же данных через Features даёт совершенно противоположную картину: точность на обучающей выборке получилась выше, чем на тестовой. Это можно объяснить тем, что в одной выборке могут быть типы текстов по Байберу, которых нет в другой. Также есть вероятность, что большое количество документов и характеристик по ним может значительно повлиять на качество работы модели, если прослеживается преобладание какого-то одного типа текстов, установленных Байбером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328fbee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
